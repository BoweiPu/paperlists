[
    {
        "id": "0UK8c2kg7c",
        "title": "InstructAV: Instruction Fine-tuning Large Language Models for Authorship Verification",
        "track": "main",
        "status": "Accept",
        "keywords": "Authorship Verification;Parameter-Efficient Fine-Tuning (PEFT);InstructAV",
        "primary_area": "",
        "author": "Yujia Hu;Zhiqiang Hu;Chun Wei Seah;Roy Ka-Wei Lee",
        "authorids": "~Yujia_Hu1;~Zhiqiang_Hu3;~Chun_Wei_Seah2;~Roy_Ka-Wei_Lee1",
        "aff": "University of Saskatchewan;DSO;KU Leuven;Singapore University of Technology and Design",
        "aff_domain": "sutd.edu.sg;kuleuven.be;dso.org.sg;usask.ca",
        "position": "Researcher;Assistant Professor;MS student;PhD student",
        "rating": "",
        "confidence": "3;3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0VLBwQGWpA",
        "title": "ReAct Meets ActRe: Autonomous Annotation of Agent Trajectories for Contrastive Self-Training",
        "track": "main",
        "status": "Accept",
        "keywords": "autonomous annotation;language agent;self-training;contrastive",
        "primary_area": "",
        "author": "Zonghan Yang;Peng Li;Ming Yan;Ji Zhang;Fei Huang;Yang Liu",
        "authorids": "~Zonghan_Yang1;~Peng_Li2;~Ming_Yan2;~Ji_Zhang3;~Fei_Huang1;~Yang_Liu19",
        "aff": "Department of Computer Science and Technology, Tsinghua University;Tsinghua University;Alibaba Group",
        "aff_domain": "alibaba-inc.com;tsinghua.edu.cn;cs.tsinghua.edu.cn",
        "position": "Senior Staff Engineer;Instructor;Associate Professor;Professor;PhD student;Senior Research Director",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0o95CVdNuz",
        "title": "Effective Prompt Extraction from Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "prompt extraction;safety",
        "primary_area": "",
        "author": "Yiming Zhang;Nicholas Carlini;Daphne Ippolito",
        "authorids": "~Yiming_Zhang5;~Nicholas_Carlini1;~Daphne_Ippolito1",
        "aff": "School of Computer Science, Carnegie Mellon University;Google",
        "aff_domain": "cs.cmu.edu;google.com",
        "position": "Researcher;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0oiG1KigYN",
        "title": "SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval",
        "track": "main",
        "status": "Accept",
        "keywords": "guided summarization;clinical text;retrieval-augmented generation;faithfulness",
        "primary_area": "",
        "author": "Griffin Thomas Adams;Jason Zucker;No\u00e9mie Elhadad",
        "authorids": "~Griffin_Thomas_Adams1;~Jason_Zucker1;~No\u00e9mie_Elhadad1",
        "aff": "Columbia University;Biomedical Informatics, Columbia University",
        "aff_domain": "dbmi.columbia.edu;columbia.edu",
        "position": "PhD student;Assistant Professor;Associate Professor",
        "rating": "",
        "confidence": "5;3;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "18iNTRPx8c",
        "title": "See What LLMs Cannot Answer: A Self-Challenge Framework for Uncovering LLM Weaknesses",
        "track": "main",
        "status": "Accept",
        "keywords": "self-challenging;human-in-the-loop;evaluation",
        "primary_area": "",
        "author": "Yulong Chen;Yang Liu;Jianhao Yan;Xuefeng Bai;Ming Zhong;Yinghao Yang;Ziyi Yang;Chenguang Zhu;Yue Zhang",
        "authorids": "~Yulong_Chen2;~Yang_Liu50;~Jianhao_Yan1;~Xuefeng_Bai1;~Ming_Zhong2;~Yinghao_Yang2;~Ziyi_Yang1;~Chenguang_Zhu1;~Yue_Zhang7",
        "aff": "University of Illinois Urbana Champaign;Microsoft;Zoom;Westlake University;Zhejiang University",
        "aff_domain": "illinois.edu;microsoft.com;zoom.us;westlake.edu.cn;zju.edu.cn",
        "position": "Principal Researcher;PhD student;PhD student;PhD student;Researcher;Undergrad student;Full Professor;PhD student;Researcher",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1Tny4KgGO2",
        "title": "From Strategic Narratives to Code-Like Cognitive Models: An LLM-Based Approach in A Sorting Task",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Models; Introspections; Cognitive Models; Programming Codes",
        "primary_area": "",
        "author": "Hanbo Xie;Hua-Dong Xiong;Robert Wilson",
        "authorids": "~Hanbo_Xie1;~Hua-Dong_Xiong1;~Robert_Wilson2",
        "aff": "University of Arizona",
        "aff_domain": "arizona.edu",
        "position": "MS student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "5;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1ba209BACA",
        "title": "Agent-DocEdit: Language-Instructed LLM Agent for Content-Rich Document Editing",
        "track": "main",
        "status": "Accept",
        "keywords": "document editing;multimodal;visual programming",
        "primary_area": "",
        "author": "Te-Lin Wu;Rajiv Jain;Yufan Zhou;Puneet Mathur;Vlad I Morariu",
        "authorids": "~Te-Lin_Wu1;~Rajiv_Jain1;~Yufan_Zhou1;~Puneet_Mathur2;~Vlad_I_Morariu1",
        "aff": "University of California, Los Angeles;State University of New York, Buffalo;University of Maryland, College Park;Adobe Systems;Adobe",
        "aff_domain": "umd.edu;cs.ucla.edu;buffalo.edu;adobe.com",
        "position": "PhD student;Senior Research Scientist;PhD student;Senior Research Scientist;PhD",
        "rating": "",
        "confidence": "5;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1eg6UnpYu7",
        "title": "Prompt Public Large Language Models to Synthesize Data for Private On-device Applications",
        "track": "main",
        "status": "Accept",
        "keywords": "large languange model;synthetic data;federated learning;production mobile keyboard application",
        "primary_area": "",
        "author": "Shanshan Wu;Zheng Xu;Yanxiang Zhang;Yuanbo Zhang;Daniel Ramage",
        "authorids": "~Shanshan_Wu1;~Zheng_Xu2;~Yanxiang_Zhang1;~Yuanbo_Zhang2;~Daniel_Ramage1",
        "aff": "Google;Research, Google",
        "aff_domain": "research.google.com;google.com",
        "position": "Researcher;Researcher;Researcher;Research Scientist",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1pgfvZj0Rx",
        "title": "Risks from Language Models for Automated Mental Healthcare: Ethics and Structure for Implementation",
        "track": "main",
        "status": "Accept",
        "keywords": "mental healthcare;automated healthcare;risks;safety evaluation;task-autonomous AI",
        "primary_area": "",
        "author": "Declan Grabb;Max Lamparth;Nina Vasan",
        "authorids": "~Declan_Grabb1;~Max_Lamparth1;~Nina_Vasan1",
        "aff": "Stanford University;Technische Universit\u00e4t M\u00fcnchen",
        "aff_domain": "tum.de;stanford.edu",
        "position": "PhD student;Assistant Professor",
        "rating": "",
        "confidence": "2;4;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2cop2jmQVL",
        "title": "Stream of Search (SoS): Learning to Search in Language",
        "track": "main",
        "status": "Accept",
        "keywords": "search;planning;reasoning;backtracking;self-improvement;bootstrapping",
        "primary_area": "",
        "author": "Kanishk Gandhi;Denise H J Lee;Gabriel Grand;Muxin Liu;Winson Cheng;Archit Sharma;Noah Goodman",
        "authorids": "~Kanishk_Gandhi1;~Denise_H_J_Lee1;~Gabriel_Grand1;~Muxin_Liu1;~Winson_Cheng1;~Archit_Sharma1;~Noah_Goodman1",
        "aff": "Stanford University;Harvey Mudd College;Massachusetts Institute of Technology",
        "aff_domain": "cs.stanford.edu;hmc.edu;mit.edu;stanford.edu",
        "position": "Graduate Student;Undergrad student;PhD student;Undergrad student;Associate Professor;Undergrad student;PhD student",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2nTzomzjjb",
        "title": "ProLLM: Protein Chain-of-Thoughts Enhanced LLM for Protein-Protein Interaction Prediction",
        "track": "main",
        "status": "Accept",
        "keywords": "Protein-Protein-Interaction(PPI);Large Language Model(LLM);Chain of Thought",
        "primary_area": "",
        "author": "Mingyu Jin;Haochen Xue;Zhenting Wang;Boming Kang;Ruosong Ye;Kaixiong Zhou;Mengnan Du;Yongfeng Zhang",
        "authorids": "~Mingyu_Jin1;~Haochen_Xue1;~Zhenting_Wang1;~Boming_Kang1;~Ruosong_Ye1;~Kaixiong_Zhou1;~Mengnan_Du1;~Yongfeng_Zhang1",
        "aff": "Rutgers University;New Jersey Institute of Technology;Beijing Medical University;Sony AI;Rice University",
        "aff_domain": "njit.edu;sony.com;rice.edu;bjmu.edu.cn;rutgers.edu",
        "position": "PhD student;PhD student;Assistant Professor;PhD student;Intern",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2oHnsM9M9D",
        "title": "ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation",
        "track": "main",
        "status": "Accept",
        "keywords": "commonsense reasoning;free-text explanations;LLM-as-a-judge;human alignment",
        "primary_area": "",
        "author": "Ana Brassard;Benjamin Heinzerling;Keito Kudo;Keisuke Sakaguchi;Kentaro Inui",
        "authorids": "~Ana_Brassard1;~Benjamin_Heinzerling1;~Keito_Kudo1;~Keisuke_Sakaguchi2;~Kentaro_Inui1",
        "aff": "Tohoku University;RIKEN AIP",
        "aff_domain": "riken.jp;tohoku.ac.jp",
        "position": "Technical Staff I;Postdoc;Associate Professor;MS student;Full Professor",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2wtj0up8rv",
        "title": "Enhancing Language Models with Idiomatic Reasoning",
        "track": "main",
        "status": "Accept",
        "keywords": "idiomatic expressions;multi-view data augmentation;parameter-efficient fine-tuning;meta-pretraining",
        "primary_area": "",
        "author": "Jianing Zhou;Ziheng Zeng;Hongyu Gong;Suma Bhat",
        "authorids": "~Jianing_Zhou1;~Ziheng_Zeng1;~Hongyu_Gong1;~Suma_Bhat1",
        "aff": "FAIR at Meta;University of Illinois, Urbana Champaign",
        "aff_domain": "illinois.edu;meta.com",
        "position": "Researcher;PhD student;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3GhOWfSLrD",
        "title": "Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "Psychology;Representativeness Heuristic;Language Models",
        "primary_area": "",
        "author": "Pengda Wang;Zilin Xiao;Hanjie Chen;Frederick L. Oswald",
        "authorids": "~Pengda_Wang1;~Zilin_Xiao1;~Hanjie_Chen1;~Frederick_L._Oswald1",
        "aff": "Microsoft;Rice University",
        "aff_domain": "microsoft.com;rice.edu",
        "position": "Full Professor;PhD student;Intern",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3HTVP34WWE",
        "title": "Bot or Human? Detecting ChatGPT Imposters with A Single Question",
        "track": "main",
        "status": "Accept",
        "keywords": "ChatGPT imposter detection; large language models",
        "primary_area": "",
        "author": "Hong Wang;Xuan Luo;Weizhi Wang;Melody Yu;Xifeng Yan",
        "authorids": "~Hong_Wang1;~Xuan_Luo2;~Weizhi_Wang1;~Melody_Yu1;~Xifeng_Yan1",
        "aff": "University of California, Santa Barbara;UC Santa Barbara;Sage Hill School;Xi'an Jiaotong University",
        "aff_domain": "sagehillschool.org;xjtu.edu.cn;ucsb.edu",
        "position": "PhD student;Researcher;PhD student;Full Professor;Undergrad student",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3TzGD95Jw1",
        "title": "Timo: Towards Better Temporal Reasoning for Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Temporal Reasoning; Reinforcement Learning from AI Feedback; Supervised Fine-tuning",
        "primary_area": "",
        "author": "Zhaochen Su;Jun Zhang;Tong Zhu;Xiaoye Qu;Juntao Li;Min zhang;Yu Cheng",
        "authorids": "~Zhaochen_Su1;~Jun_Zhang39;~Tong_Zhu2;~Xiaoye_Qu1;~Juntao_Li2;~Min_zhang14;~Yu_Cheng1",
        "aff": "Shanghai Artificial Intelligence Laboratory;Soochow University, China;Harbin Institute of Technology;Soochow University;Microsoft Research",
        "aff_domain": "pjlab.org.cn;suda.edu.cn;hit.edu.cn;microsoft.com",
        "position": "Undergrad student;Associate Professor;Full Professor;PhD student;Researcher;Principal Researcher;MS student",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3X2L2TFr0f",
        "title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies",
        "track": "main",
        "status": "Accept",
        "keywords": "Scaling Law;Small Language Model;Training Dynamics;Training Strategy",
        "primary_area": "",
        "author": "Shengding Hu;Yuge Tu;Xu Han;Ganqu Cui;Chaoqun He;Weilin Zhao;Xiang Long;Zhi Zheng;Yewei Fang;Yuxiang Huang;Xinrong Zhang;Zhen Leng Thai;Chongyi Wang;Yuan Yao;Chenyang Zhao;Jie Zhou;Jie Cai;Zhongwu Zhai;Ning Ding;Chao Jia;Guoyang Zeng;dahai li;Zhiyuan Liu;Maosong Sun",
        "authorids": "~Shengding_Hu2;~Yuge_Tu3;~Xu_Han2;~Ganqu_Cui1;~Chaoqun_He1;~Weilin_Zhao1;~Xiang_Long2;~Zhi_Zheng4;~Yewei_Fang1;~Yuxiang_Huang3;~Xinrong_Zhang1;~Zhen_Leng_Thai1;~Chongyi_Wang1;~Yuan_Yao12;~Chenyang_Zhao6;~Jie_Zhou10;~Jie_Cai2;~Zhongwu_Zhai1;~Ning_Ding5;~Chao_Jia2;~Guoyang_Zeng1;~dahai_li1;~Zhiyuan_Liu1;~Maosong_Sun1",
        "aff": "modelbest;Tsinghua University, Tsinghua University;Modelbest Inc.;Tsinghua University;Beijing Foreign Studies University;Baidu;Alibaba Group;The Department of Computer Science and Technology, Tsinghua University",
        "aff_domain": "bfsu.edu.cn;cs.tsinghua.edu.cn;tsinghua.edu.cn;mails.tsinghua.edu.cn;modelbest.cn;alibaba-inc.com;mail.tsinghua.edu.cn;baidu.com",
        "position": "Researcher;MS student;Undergrad student;PhD student;Researcher;PhD student;Undergrad student;Researcher;PhD student;Researcher;PhD student;MS student;Undergrad student;Undergrad student;Researcher;Associate Professor;Principal Researcher;PhD student",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3nTbuygoop",
        "title": "StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows",
        "track": "main",
        "status": "Accept",
        "keywords": "workflows;state machines;LLM;prompt engineering",
        "primary_area": "",
        "author": "Yiran Wu;Tianwei Yue;Shaokun Zhang;Chi Wang;Qingyun Wu",
        "authorids": "~Yiran_Wu2;~Tianwei_Yue1;~Shaokun_Zhang2;~Chi_Wang3;~Qingyun_Wu2",
        "aff": "Pennsylvania State University;Microsoft Research;MathGPTPro",
        "aff_domain": "mathgptpro.com;psu.edu;microsoft.com",
        "position": "Principal Researcher;Principal Researcher;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "5;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3ypWPhMGhV",
        "title": "Cohesive Conversations: Enhancing Authenticity in Multi-Agent Simulated Dialogues",
        "track": "main",
        "status": "Accept",
        "keywords": "multi-agent dialogues;multi-agent communication;multi-session dialogues;machine-generated dialogues;inconsistencies and repetition in dialogues;discourse-level error detection;longitudinal dialogue analysis;generative agents;llm agents",
        "primary_area": "",
        "author": "KuanChao Chu;Yi-Pei Chen;Hideki Nakayama",
        "authorids": "~KuanChao_Chu1;~Yi-Pei_Chen1;~Hideki_Nakayama1",
        "aff": "The University of Tokyo, Graduate School of  Information Science and Technology;The University of Tokyo",
        "aff_domain": "u-tokyo.ac.jp;nlab.ci.i.u-tokyo.ac.jp",
        "position": "Associate Professor;PhD student;PhD student",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "46Zgqo4QIU",
        "title": "Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "reasoning;language models;self-improvement;code generation",
        "primary_area": "",
        "author": "Eric Zelikman;Eliana Lorch;Lester Mackey;Adam Tauman Kalai",
        "authorids": "~Eric_Zelikman1;~Eliana_Lorch1;~Lester_Mackey1;~Adam_Tauman_Kalai1",
        "aff": "Microsoft Research New England;Google",
        "aff_domain": "microsoft.com;google.com",
        "position": "Research Intern;Principal Researcher",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4HNAwZFDcH",
        "title": "WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace Setting",
        "track": "main",
        "status": "Accept",
        "keywords": "evaluation;work;LLMs;simulation",
        "primary_area": "",
        "author": "Olly Styles;Sam Miller;Patricio Cerda-Mardini;Tanaya Guha;Victor Sanchez;Bertie Vidgen",
        "authorids": "~Olly_Styles1;~Sam_Miller1;~Patricio_Cerda-Mardini1;~Tanaya_Guha1;~Victor_Sanchez1;~Bertie_Vidgen1",
        "aff": "University of Oxford;MindsDB;University of Glasgow;MindsDB Inc.;The university of Warwick",
        "aff_domain": "glasgow.ac.uk;warwick.ac.uk;ox.ac.uk;mindsdb.com",
        "position": "Visiting researcher;Machine Learning Engineer;Researcher;Researcher;Associate Professor;Associate Professor",
        "rating": "",
        "confidence": "3;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4aqq9xTtih",
        "title": "Prompt-prompted Adaptive Structured Pruning for Efficient LLM Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "adaptive pruning;structured pruning;mixture of experts;sparsity;efficiency;generation;structured sparsity;pruning;LLM;feedforward;activation function",
        "primary_area": "",
        "author": "Harry Dong;Beidi Chen;Yuejie Chi",
        "authorids": "~Harry_Dong1;~Beidi_Chen1;~Yuejie_Chi1",
        "aff": "Carnegie Mellon University;Facebook",
        "aff_domain": "cmu.edu;fb.com",
        "position": "Researcher;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5B2K4LRgmz",
        "title": "Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data",
        "track": "main",
        "status": "Accept",
        "keywords": "model collapse;curse of recursion;generative models;model-data feedback loops",
        "primary_area": "",
        "author": "Matthias Gerstgrasser;Rylan Schaeffer;Apratim Dey;Rafael Rafailov;Tomasz Korbak;Henry Sleight;Rajashree Agrawal;John Hughes;Dhruv Bhandarkar Pai;Andrey Gromov;Dan Roberts;Diyi Yang;David L. Donoho;Sanmi Koyejo",
        "authorids": "~Matthias_Gerstgrasser1;~Rylan_Schaeffer2;~Apratim_Dey1;~Rafael_Rafailov1;~Tomasz_Korbak1;~Henry_Sleight1;~Rajashree_Agrawal1;~John_Hughes4;~Dhruv_Bhandarkar_Pai1;~Andrey_Gromov1;~Dan_Roberts1;~Diyi_Yang2;~David_L._Donoho1;~Sanmi_Koyejo1",
        "aff": "Stanford University;Speechmatics;Computer Science Department, Stanford University;Harvard University;Reed College;University of Sussex;Google;SalesForce.com;University of Maryland, College Park;Massachusetts Institute of Technology",
        "aff_domain": "reed.edu;mit.edu;google.com;harvard.edu;salesforce.com;cs.stanford.edu;umd.edu;sussex.ac.uk;speechmatics.com;stanford.edu",
        "position": "Assistant Professor;PhD student;Principal Researcher;Full Professor;Undergrad student;Assistant Professor;Researcher;Postdoc;PhD student;Undergrad student;Researcher;PhD student;Research Scientist",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5Evv4tIjUI",
        "title": "Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners",
        "track": "main",
        "status": "Accept",
        "keywords": "Encoder-Decoder Model;In-context Learning;Few-shot Learning",
        "primary_area": "",
        "author": "Jihyeon Lee;Dain Kim;Doohae Jung;Boseop Kim;Kyoung-Woon On",
        "authorids": "~Jihyeon_Lee1;~Dain_Kim1;~Doohae_Jung1;~Boseop_Kim1;~Kyoung-Woon_On1",
        "aff": "Sogang University;KakaoBrain;Kakaobrain;kakaobrain",
        "aff_domain": "kakaobrain.com;sogang.ac.kr",
        "position": "Researcher;Researcher;Undergrad student;Researcher;Researcher",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5Nsl0nlStc",
        "title": "Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Models;Model Fusion",
        "primary_area": "",
        "author": "Costas Mavromatis;Petros Karypis;George Karypis",
        "authorids": "~Costas_Mavromatis1;~Petros_Karypis1;~George_Karypis1",
        "aff": "University of California, San Diego;University of Minnesota - Twin Cities;University of Minnesota, Minneapolis",
        "aff_domain": "umn.edu;ucsd.edu",
        "position": "PhD student;Full Professor;MS student",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5RdIMlGLXL",
        "title": "LLM-Datasets: An Open Framework for Pretraining Datasets of Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Demo paper;Dataset collection;Data preprocessing;European languages;Multilingual",
        "primary_area": "",
        "author": "Malte Ostendorff;Pedro Ortiz Suarez;Lucas Fonseca Lage;Georg Rehm",
        "authorids": "~Malte_Ostendorff1;~Pedro_Ortiz_Suarez1;~Lucas_Fonseca_Lage1;~Georg_Rehm1",
        "aff": "Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz;German Research Center for AI;Universit\u00e4t des Saarlandes;DFKI GmbH",
        "aff_domain": "uni-saarland.de;dfki.de",
        "position": "Principal Researcher;MS student;Researcher;Researcher",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5fg0VtRxgi",
        "title": "SteP: Stacked LLM Policies for Web Actions",
        "track": "main",
        "status": "Accept",
        "keywords": "LLMs;web actions;policy composition",
        "primary_area": "",
        "author": "Paloma Sodhi;S.R.K Branavan;Yoav Artzi;Ryan McDonald",
        "authorids": "~Paloma_Sodhi1;~S.R.K_Branavan1;~Yoav_Artzi1;~Ryan_McDonald2",
        "aff": "ASAPP",
        "aff_domain": "asapp.com",
        "position": "Researcher;Researcher",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5u1GpUkKtG",
        "title": "Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate Reward Hacking",
        "track": "main",
        "status": "Accept",
        "keywords": "RLHF;reward models;underspecification;reward hacking",
        "primary_area": "",
        "author": "Jacob Eisenstein;Chirag Nagpal;Alekh Agarwal;Ahmad Beirami;Alexander Nicholas D'Amour;Krishnamurthy Dj Dvijotham;Adam Fisch;Katherine A Heller;Stephen Robert Pfohl;Deepak Ramachandran;Peter Shaw;Jonathan Berant",
        "authorids": "~Jacob_Eisenstein1;~Chirag_Nagpal1;~Alekh_Agarwal2;~Ahmad_Beirami1;~Alexander_D'Amour1;~Krishnamurthy_Dj_Dvijotham1;~Adam_Fisch2;~Katherine_A_Heller1;~Stephen_Robert_Pfohl1;~Deepak_Ramachandran2;~Peter_Shaw1;~Jonathan_Berant1",
        "aff": "Tel Aviv University;Google DeepMind;Google;Duke University;Google Brain;Massachusetts Institute of Technology",
        "aff_domain": "tau.ac.il;duke.edu;mit.edu;google.com",
        "position": "Research Affiliate;Researcher;Research Scientist;Staff Researcher;Research Scientist;Associate Professor;Assistant Professor;Research Scientist;Researcher;PhD student;research scientist ",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "60a1SAtH4e",
        "title": "Measuring and Controlling Instruction (In)Stability in Language Model Dialogs",
        "track": "main",
        "status": "Accept",
        "keywords": "Dialog system; System prompt",
        "primary_area": "",
        "author": "Kenneth Li;Tianle Liu;Naomi Bashkansky;David Bau;Fernanda Vi\u00e9gas;Hanspeter Pfister;Martin Wattenberg",
        "authorids": "~Kenneth_Li1;~Tianle_Liu1;~Naomi_Bashkansky1;~David_Bau1;~Fernanda_Vi\u00e9gas1;~Hanspeter_Pfister1;~Martin_Wattenberg1",
        "aff": "Google;Harvard University;Northeastern University",
        "aff_domain": "northeastern.edu;google.com;harvard.edu",
        "position": "Assistant Professor;Full Professor;PhD student;Principal Researcher;Undergrad student;PhD student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6U1FEKP7Ar",
        "title": "ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning",
        "track": "main",
        "status": "Accept",
        "keywords": "Compositional Methods;Verification;Muiltimodal Agent;Compositional Visua Reasoning",
        "primary_area": "",
        "author": "Yuxuan Wang;Alan Yuille;Zhuowan Li;Zilong Zheng",
        "authorids": "~Yuxuan_Wang4;~Alan_Yuille1;~Zhuowan_Li1;~Zilong_Zheng1",
        "aff": "Amazon;Peking University;Johns Hopkins University;Beijing Institute for General Artificial Intelligence",
        "aff_domain": "pku.edu.cn;bigai.ai;amazon.com;jhu.edu",
        "position": "Full Professor;MS student;Intern;Researcher",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6vEfyp0o68",
        "title": "MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "large language models;robotics;mapping;navigation;textgame",
        "primary_area": "",
        "author": "Peng Ding;Jiading Fang;Peng Li;Kangrui Wang;Xiaochen Zhou;Mo Yu;Jing Li;Hongyuan Mei;Matthew Walter",
        "authorids": "~Peng_Ding2;~Jiading_Fang1;~Peng_Li13;~Kangrui_Wang2;~Xiaochen_Zhou1;~Mo_Yu1;~Jing_Li21;~Hongyuan_Mei1;~Matthew_Walter1",
        "aff": "WeChat AI, Tencent;Syracuse University;Fudan University;Toyota Technological Institute at Chicago",
        "aff_domain": "syr.edu;tencent.com;fudan.edu;ttic.edu",
        "position": "Research Assistant Professor;PhD student;Associate Professor;Principal Researcher;MS student;MS student",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7BCmIWVT0V",
        "title": "Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration",
        "track": "main",
        "status": "Accept",
        "keywords": "Model Collaborations; Complex Reasoning; Large Language Models",
        "primary_area": "",
        "author": "Qiushi Sun;Zhangyue Yin;Xiang Li;Zhiyong Wu;Xipeng Qiu;Lingpeng Kong",
        "authorids": "~Qiushi_Sun1;~Zhangyue_Yin1;~Xiang_Li24;~Zhiyong_Wu3;~Xipeng_Qiu1;~Lingpeng_Kong1",
        "aff": "Institute of infocomm research, A*STAR;Fudan University;Department of Computer Science, The University of Hong Kong;East China Normal University",
        "aff_domain": "i2r.a-star.edu.sg;cs.hku.hk;ecnu.edu.cn;fudan.edu.cn",
        "position": "Assistant Professor;Intern;Full Professor;Full Professor;PhD student",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7QaEO9WYMa",
        "title": "Poly-Visual-Expert Vision-Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Vision-Language Models;Multi-modal Models",
        "primary_area": "",
        "author": "Xiaoran Fan;Tao Ji;\u6c5f\u5e38\u7693;Shuo Li;Senjie Jin;Sirui Song;Junke Wang;Boyang Hong;Lu Chen;Guodong Zheng;Ming Zhang;Huangcaishuang;Rui Zheng;Zhiheng Xi;Yuhao Zhou;Shihan Dou;Junjie Ye;Hang Yan;Tao Gui;Qi Zhang;Xipeng Qiu;Xuanjing Huang;Zuxuan Wu;Yu-Gang Jiang",
        "authorids": "~Xiaoran_Fan3;~Tao_Ji1;~\u6c5f\u5e38\u76931;~Shuo_Li12;~Senjie_Jin1;~Sirui_Song2;~Junke_Wang1;~Boyang_Hong1;~Lu_Chen15;~Guodong_Zheng1;~Ming_Zhang15;~Huangcaishuang1;~Rui_Zheng1;~Zhiheng_Xi1;~Yuhao_Zhou3;~Shihan_Dou1;~Junjie_Ye4;~Hang_Yan2;~Tao_Gui1;~Qi_Zhang8;~Xipeng_Qiu1;~Xuanjing_Huang1;~Zuxuan_Wu1;~Yu-Gang_Jiang1",
        "aff": "Fuzhou University;East China Normal University;Fudan University;Shandong University;University of Science and Technology Beijing",
        "aff_domain": "fudan.edu;fzu.edu.cn;ecnu.edu.cn;sdu.edu.cn;ustb.edu.cn;fudan.edu.cn",
        "position": "Undergrad student;Undergrad student;MS student;PhD student;PhD student;MS student;Undergrad student;Full Professor;PhD student;MS student;MS student;Assistant Professor;PhD student;PhD student;Full Professor;Full Professor;Full Professor;MS student;MS student;Associate Professor;MS student;MS student;Undergrad student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7VPKtz8CHN",
        "title": "Beyond Relevance: Evaluate and Improve Retrievers on Perspective Awareness",
        "track": "main",
        "status": "Accept",
        "keywords": "retrieval;perspective;text embedding;retrieval-augmented generation",
        "primary_area": "",
        "author": "Xinran Zhao;Tong Chen;Sihao Chen;Hongming Zhang;Tongshuang Wu",
        "authorids": "~Xinran_Zhao1;~Tong_Chen3;~Sihao_Chen1;~Hongming_Zhang2;~Tongshuang_Wu1",
        "aff": "Stanford University;University of Washington, Seattle;Tencent AI Lab Seattle;Tencent AI Lab;School of Computer Science, Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;cs.washington.edu;tencent.com;stanford.edu",
        "position": "Researcher;Intern;PhD student;Assistant Professor;MS student",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7iaAlIlV2H",
        "title": "Pairwise Proximal Policy Optimization: Language Model Alignment with Comparative RL",
        "track": "main",
        "status": "Accept",
        "keywords": "RLHF;Alignment;Comparative RL;LLM",
        "primary_area": "",
        "author": "Tianhao Wu;Banghua Zhu;Ruoyu Zhang;Zhaojin Wen;Kannan Ramchandran;Jiantao Jiao",
        "authorids": "~Tianhao_Wu1;~Banghua_Zhu1;~Ruoyu_Zhang1;~Zhaojin_Wen1;~Kannan_Ramchandran1;~Jiantao_Jiao1",
        "aff": "University of California, Berkeley;University of California Berkeley;Peking University",
        "aff_domain": "pku.edu.cn;berkeley.edu",
        "position": "PhD student;Assistant Professor;MS student;PhD student",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7jSMMvXLri",
        "title": "Measuring Taiwanese Mandarin Language Understanding",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Models;Taiwanese Mandarin;Traditional Chinese;Benchmark",
        "primary_area": "",
        "author": "Po-Heng Chen;Sijia Cheng;Wei-Lin Chen;Yen-Ting Lin;Yun-Nung Chen",
        "authorids": "~Po-Heng_Chen2;~Sijia_Cheng1;~Wei-Lin_Chen1;~Yen-Ting_Lin2;~Yun-Nung_Chen1",
        "aff": "National Taiwan University;Department of Computer Science and Informational Engineering, National Taiwan University",
        "aff_domain": "ntu.edu.tw;csie.ntu.edu.tw",
        "position": "MS student;MS student;MS student;PhD student;Associate Professor",
        "rating": "",
        "confidence": "3;5;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7xUtka9ck9",
        "title": "Yes, no, maybe? Revisiting language models' response stability under paraphrasing for the assessment of political leaning",
        "track": "main",
        "status": "Accept",
        "keywords": "interpretability;social sciences;bias;robustness",
        "primary_area": "",
        "author": "Patrick Haller;Jannis Vamvas;Lena Ann J\u00e4ger",
        "authorids": "~Patrick_Haller1;~Jannis_Vamvas1;~Lena_Ann_J\u00e4ger1",
        "aff": "Universit\u00e4t Potsdam;University of Zurich",
        "aff_domain": "uni-potsdam.de;uzh.ch",
        "position": "Principal Researcher;PhD student",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7ysaJGs7zY",
        "title": "IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Vision Language Model;Optical Illusions;Dataset;Benchmark;Hallucination",
        "primary_area": "",
        "author": "Haz Sameen Shahgir;Khondker Salman Sayeed;Abhik Bhattacharjee;Wasi Uddin Ahmad;Yue Dong;Rifat Shahriyar",
        "authorids": "~Haz_Sameen_Shahgir1;~Khondker_Salman_Sayeed1;~Abhik_Bhattacharjee1;~Wasi_Uddin_Ahmad1;~Yue_Dong2;~Rifat_Shahriyar1",
        "aff": "Amazon;Bangladesh University of Engineering and Technology;McGill University",
        "aff_domain": "mcgill.ca;buet.ac.bd;amazon.com",
        "position": "MS student;Undergrad student;Undergrad student;Professor;Applied Scientist;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8TdcXwfNRB",
        "title": "PAPERCLIP: Associating Astronomical Observations and Natural Language with Multi-Modal Models",
        "track": "main",
        "status": "Accept",
        "keywords": "CLIP;astronomy;astrophysics;physics;science;space;telescopes;vision;language;scientific discovery;contrastive learning;guided generation;data curation;fine tuning;foundation models",
        "primary_area": "",
        "author": "Siddharth Mishra-Sharma;YIDING SONG;Jesse Thaler",
        "authorids": "~Siddharth_Mishra-Sharma1;~YIDING_SONG1;~Jesse_Thaler1",
        "aff": "Harvard University;Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;harvard.edu",
        "position": "Full Professor;Postdoc;Intern",
        "rating": "",
        "confidence": "4;4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8tKjqqMM5z",
        "title": "Keep the Cost Down: A Review on Methods to Optimize LLM\u2019s KV-Cache Consumption",
        "track": "main",
        "status": "Accept",
        "keywords": "efficient;KV-Cache;LLM;inference",
        "primary_area": "",
        "author": "Shi Luohe;Hongyi Zhang;Yao Yao;Zuchao Li;hai zhao",
        "authorids": "~Shi_Luohe1;~Hongyi_Zhang5;~Yao_Yao8;~Zuchao_Li1;~hai_zhao1",
        "aff": "Shanghai Jiaotong University;Wuhan University;Shanghai Jiao Tong University",
        "aff_domain": "whu.edu.cn;sjtu.edu.cn",
        "position": "Undergrad student;Undergrad student;PhD student;Researcher;Full Professor",
        "rating": "",
        "confidence": "4;3;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.2,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8w0RApM5yG",
        "title": "BumbleBee: Dynamic KV-Cache Streaming Submodular Summarization for Infinite-Context Transformers",
        "track": "main",
        "status": "Accept",
        "keywords": "transformers;KV cache selection;online summarization;Submodular Optimization;context summarization",
        "primary_area": "",
        "author": "Lilly Kumari;Shengjie Wang;Tianyi Zhou;Nikhil Sarda;Anthony Rowe;Jeff Bilmes",
        "authorids": "~Lilly_Kumari1;~Shengjie_Wang1;~Tianyi_Zhou1;~Nikhil_Sarda1;~Anthony_Rowe1;~Jeff_Bilmes1",
        "aff": "University of Washington, Seattle;New York University, Shanghai;University of Maryland, College Park;Carnegie Mellon University;Research, Google",
        "aff_domain": "nyu.edu;cmu.edu;research.google.com;umd.edu;uw.edu",
        "position": "Full Professor;Full Professor;PhD student;Researcher;Assistant Professor;Assistant Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "95TayIeqJ4",
        "title": "TMMLU+: An Improved Traditional Chinese Evaluation Suite for Foundation Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Traditional Chinese evaluation;multi-choice question answering",
        "primary_area": "",
        "author": "Zhi Rui Tam;Ya Ting Pai;Yen-Wei Lee;Hong-Han Shuai;Jun-Da Chen;Wei Min Chu;Sega Cheng",
        "authorids": "~Zhi_Rui_Tam1;~Ya_Ting_Pai1;~Yen-Wei_Lee1;~Hong-Han_Shuai1;~Jun-Da_Chen1;~Wei_Min_Chu2;~Sega_Cheng1",
        "aff": "National Taiwan University;iKala Interactive Media Inc.;Computer Science Department, Stanford University;National Yang Ming Chiao Tung University",
        "aff_domain": "cs.stanford.edu;ikala.ai;nycu.edu.tw;ntu.edu.tw",
        "position": "Associate Professor;Researcher;MS student;MS student;Researcher;Researcher",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "98ekcwQqb7",
        "title": "Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data",
        "track": "main",
        "status": "Accept",
        "keywords": "probing;causality;interpretability;understanding;world models",
        "primary_area": "",
        "author": "Charles Jin",
        "authorids": "~Charles_Jin1",
        "aff": "Massachusetts Institute of Technology",
        "aff_domain": "mit.edu",
        "position": "PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9Ik05cycLq",
        "title": "Certifying LLM Safety against Adversarial Prompting",
        "track": "main",
        "status": "Accept",
        "keywords": "Certified Defense;Adversarial Attacks;Safety",
        "primary_area": "",
        "author": "Aounon Kumar;Chirag Agarwal;Suraj Srinivas;Aaron Jiaxun Li;Soheil Feizi;Himabindu Lakkaraju",
        "authorids": "~Aounon_Kumar1;~Chirag_Agarwal1;~Suraj_Srinivas1;~Aaron_Jiaxun_Li1;~Soheil_Feizi2;~Himabindu_Lakkaraju1",
        "aff": "University of California, Berkeley;Harvard University;University of Maryland, College Park;Adobe Systems;School of Engineering and Applied Sciences, Harvard University",
        "aff_domain": "berkeley.edu;seas.harvard.edu;adobe.com;umd.edu;harvard.edu",
        "position": "Undergrad student;PhD student;Researcher;Assistant Professor;Postdoc;Assistant Professor",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9JY1QLVFPZ",
        "title": "Forcing Diffuse Distributions out of Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "diversity;synthetic dataset generation;parameter-efficient fine-tuning",
        "primary_area": "",
        "author": "Yiming Zhang;Avi Schwarzschild;Nicholas Carlini;J Zico Kolter;Daphne Ippolito",
        "authorids": "~Yiming_Zhang5;~Avi_Schwarzschild1;~Nicholas_Carlini1;~J_Zico_Kolter1;~Daphne_Ippolito1",
        "aff": "Bosch;University of Maryland, College Park;School of Computer Science, Carnegie Mellon University;Google",
        "aff_domain": "umd.edu;cs.cmu.edu;bosch.com;google.com",
        "position": "PhD student;Researcher;PhD student;Chief Scientist of AI Research",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9Wmdk94oKF",
        "title": "CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM for Customer Service;LLM agents;benchmark",
        "primary_area": "",
        "author": "Jingzhe Shi;Jialuo Li;Qinwei Ma;Zaiwen Yang;Huan Ma;Lei Li",
        "authorids": "~Jingzhe_Shi1;~Jialuo_Li1;~Qinwei_Ma1;~Zaiwen_Yang1;~Huan_Ma2;~Lei_Li29",
        "aff": "University of Copenhagen;Tsinghua University;Tsinghua University, Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn;diku.dk;tsinghua.edu.cn;mail.tsinghua.edu.cn",
        "position": "Researcher;Researcher;Undergrad student;Researcher;Researcher;Researcher",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9gdZI7c6yr",
        "title": "Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM evaluator; pairwise comparison; human alignment",
        "primary_area": "",
        "author": "Yinhong Liu;Han Zhou;Zhijiang Guo;Ehsan Shareghi;Ivan Vuli\u0107;Anna Korhonen;Nigel Collier",
        "authorids": "~Yinhong_Liu1;~Han_Zhou4;~Zhijiang_Guo2;~Ehsan_Shareghi1;~Ivan_Vuli\u01071;~Anna_Korhonen1;~Nigel_Collier1",
        "aff": "Google;University of Cambridge;PolyAI Limited",
        "aff_domain": "poly-ai.com;cam.ac.uk;google.com",
        "position": "Professor;Affiliaed Lecturer;Student Researcher;Senior Scientist;Full Professor;PhD student;Postdoc",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ADtL6fgNRv",
        "title": "Inspecting and Editing Knowledge Representations in Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "representation editing;knowledge;factuality;interpretability;world models",
        "primary_area": "",
        "author": "Evan Hernandez;Belinda Z. Li;Jacob Andreas",
        "authorids": "~Evan_Hernandez1;~Belinda_Z._Li1;~Jacob_Andreas1",
        "aff": "Microsoft;Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;microsoft.com",
        "position": "PhD student;Researcher;PhD student",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Aaz6R4Tlwv",
        "title": "SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design",
        "track": "main",
        "status": "Accept",
        "keywords": "in-context learning;drug synergy prediction;inverse drug design;precision medicine",
        "primary_area": "",
        "author": "Carl Edwards;Aakanksha Naik;Tushar Khot;Martin D. Burke;Heng Ji;Tom Hope",
        "authorids": "~Carl_Edwards1;~Aakanksha_Naik1;~Tushar_Khot1;~Martin_D._Burke1;~Heng_Ji3;~Tom_Hope2",
        "aff": "National Institutes of Health;Allen Institute for Artificial Intelligence;University of Illinois, Urbana-Champaign;Hebrew University, Hebrew University of Jerusalem;University of Illinois at Urbana-Champaign",
        "aff_domain": "illinois.edu;allenai.org;cs.huji.ac.il;nih.gov;uiuc.edu",
        "position": "Researcher;PhD student;Full Professor;Full Professor;Assistant Professor;Lead Research Scientist",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "B41hNBoWLo",
        "title": "TOFU: A Task of Fictitious Unlearning for LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "Machine unlearning",
        "primary_area": "",
        "author": "Pratyush Maini;Zhili Feng;Avi Schwarzschild;Zachary Chase Lipton;J Zico Kolter",
        "authorids": "~Pratyush_Maini1;~Zhili_Feng1;~Avi_Schwarzschild1;~Zachary_Chase_Lipton1;~J_Zico_Kolter1",
        "aff": "Bosch;University of Maryland, College Park;CMU, Carnegie Mellon University;Carnegie Mellon University",
        "aff_domain": "umd.edu;cmu.edu;andrew.cmu.edu;bosch.com",
        "position": "PhD student;PhD student;Assistant Professor;PhD student;Chief Scientist of AI Research",
        "rating": "",
        "confidence": "5;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BAakY1hNKS",
        "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversations",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model;Multi-Agent Conversation Framework;Open-Source Library",
        "primary_area": "",
        "author": "Qingyun Wu;Gagan Bansal;Jieyu Zhang;Yiran Wu;Beibin Li;Erkang Zhu;Li Jiang;Xiaoyun Zhang;Shaokun Zhang;Jiale Liu;Ahmed Hassan Awadallah;Ryen W White;Doug Burger;Chi Wang",
        "authorids": "~Qingyun_Wu2;~Gagan_Bansal1;~Jieyu_Zhang1;~Yiran_Wu2;~Beibin_Li1;~Erkang_Zhu1;~Li_Jiang7;~Xiaoyun_Zhang2;~Shaokun_Zhang2;~Jiale_Liu2;~Ahmed_Hassan_Awadallah1;~Ryen_W_White1;~Doug_Burger2;~Chi_Wang3",
        "aff": "University of Washington;Microsoft;Microsoft Research;Pennsylvania State University",
        "aff_domain": "psu.edu;research.microsoft.com;cs.washington.edu;microsoft.com",
        "position": "Principal Researcher;Researcher;Principal Researcher;Technical Fellow;Researcher;Researcher;PhD student;Research Manager;sde;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BDBdblmyzY",
        "title": "Automata-based constraints for language model decoding",
        "track": "main",
        "status": "Accept",
        "keywords": "finite state automaton;finite state transducer;pushdown automaton;language model;constrained decoding",
        "primary_area": "",
        "author": "Terry Koo;Frederick Liu;Luheng He",
        "authorids": "~Terry_Koo2;~Frederick_Liu1;~Luheng_He1",
        "aff": "Google",
        "aff_domain": "google.com",
        "position": "Software Engineer;Research Scientist;Research Scientist",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BaOAvPUyBO",
        "title": "Do Language Models Plan Ahead for Future Tokens?",
        "track": "main",
        "status": "Accept",
        "keywords": "probing;mechanistic interpretability;future tokens;transformers",
        "primary_area": "",
        "author": "Wilson Wu;John Xavier Morris;Lionel Levine",
        "authorids": "~Wilson_Wu1;~John_Xavier_Morris1;~Lionel_Levine1",
        "aff": "Cornell University;University of Colorado at Boulder",
        "aff_domain": "colorado.edu;cornell.edu",
        "position": "PhD student;Professor;PhD student",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BgvgMxY8s5",
        "title": "Handling Open-Vocabulary Constructs in Formalizing Specifications: Retrieval Augmented Parsing with Expert Knowledge",
        "track": "main",
        "status": "Accept",
        "keywords": "Open Vocabulary Constructs;Retrieval Augmented Parsing;",
        "primary_area": "",
        "author": "Mohammad Saqib Hasan;Sayontan Ghosh;Dhruv Verma;Geoff Kuenning;Erez Zadok;Scott Smolka;Niranjan Balasubramanian",
        "authorids": "~Mohammad_Saqib_Hasan1;~Sayontan_Ghosh1;~Dhruv_Verma3;~Geoff_Kuenning1;~Erez_Zadok2;~Scott_Smolka1;~Niranjan_Balasubramanian2",
        "aff": ", State University of New York, Stony Brook;State University of New York, Stony Brook;SUNY at Stony Brook;Harvey Mudd College;, State University of New York at Stony Brook;State University of New York at Stony Brook",
        "aff_domain": "stonybrook.edu;cs.stonybrook.edu;cs.hmc.edu",
        "position": "MS student;PhD student;Assistant Professor;PhD student;Full Professor",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "C0j44uRPcl",
        "title": "On Robustness-Accuracy Characterization of Language Models using Synthetic Datasets",
        "track": "main",
        "status": "Accept",
        "keywords": "synthetic data; evaluation",
        "primary_area": "",
        "author": "Ching-Yun Ko;Pin-Yu Chen;Payel Das;Yung-Sung Chuang;Luca Daniel",
        "authorids": "~Ching-Yun_Ko1;~Pin-Yu_Chen1;~Payel_Das1;~Yung-Sung_Chuang1;~Luca_Daniel1",
        "aff": "International Business Machines;Massachusetts Institute of Technology",
        "aff_domain": "ibm.com;mit.edu",
        "position": "PhD student;Principal Researcher;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CI7D2kiih1",
        "title": "Should We Attend More or Less? Modulating Attention for Fairness",
        "track": "main",
        "status": "Accept",
        "keywords": "attention modulation;bias;fairness;intra-processing;language models;attention;gender;race;religion;sexual orientation",
        "primary_area": "",
        "author": "Abdelrahman Zayed;Goncalo Mordido;Samira Shabanian;Sarath Chandar",
        "authorids": "~Abdelrahman_Zayed1;~Goncalo_Mordido1;~Samira_Shabanian1;~Sarath_Chandar1",
        "aff": "Microsoft;Polytechnique Montreal;Montreal Institute for Learning Algorithms, University of Montreal, Universit\u00e9 de Montr\u00e9al",
        "aff_domain": "polymtl.ca;mila.umontreal.ca;microsoft.com",
        "position": "PhD student;Researcher;Assistant Professor",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CrzAj0kZjR",
        "title": "STaR-GATE: Teaching Language Models to Ask Clarifying Questions",
        "track": "main",
        "status": "Accept",
        "keywords": "question asking;preference elicitation;expert iteration;self-improvement",
        "primary_area": "",
        "author": "Chinmaya Andukuri;Jan-Philipp Fr\u00e4nken;Tobias Gerstenberg;Noah Goodman",
        "authorids": "~Chinmaya_Andukuri1;~Jan-Philipp_Fr\u00e4nken1;~Tobias_Gerstenberg1;~Noah_Goodman1",
        "aff": "Stanford University",
        "aff_domain": "stanford.edu",
        "position": "Undergrad student;Postdoc;Associate Professor;Assistant Professor",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CybBmzWBX0",
        "title": "Length-Controlled AlpacaEval: A Simple Debiasing of Automatic Evaluators",
        "track": "main",
        "status": "Accept",
        "keywords": "evaluation;llm;bias",
        "primary_area": "",
        "author": "Yann Dubois;Percy Liang;Tatsunori Hashimoto",
        "authorids": "~Yann_Dubois1;~Percy_Liang1;~Tatsunori_Hashimoto1",
        "aff": "Stanford University",
        "aff_domain": "stanford.edu",
        "position": "Associate Professor;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "D06yk3DBas",
        "title": "Can It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions",
        "track": "main",
        "status": "Accept",
        "keywords": "benchmark;programming;llm;code editing",
        "primary_area": "",
        "author": "Federico Cassano;Luisa Li;Akul Sethi;Noah Shinn;Abby Brennan-Jones;Jacob Ginesin;Edward Berman;George Chakhnashvili;Anton Lozhkov;Carolyn Jane Anderson;Arjun Guha",
        "authorids": "~Federico_Cassano1;~Luisa_Li1;~Akul_Sethi1;~Noah_Shinn1;~Abby_Brennan-Jones1;~Jacob_Ginesin1;~Edward_Berman1;~George_Chakhnashvili1;~Anton_Lozhkov1;~Carolyn_Jane_Anderson1;~Arjun_Guha3",
        "aff": "Wellesley College;Northeastern University;Hugging Face",
        "aff_domain": "wellesley.edu;neu.edu;northeastern.edu;huggingface.co",
        "position": "Undergrad student;Undergrad student;Machine Learning Engineer;Associate Professor;Assistant Professor;Undergrad student;Undergrad student;Undergrad student;Undergrad student;Undergrad student;Undergrad student",
        "rating": "",
        "confidence": "5;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DMUGTMWrKZ",
        "title": "Enhancing Adversarial Robustness of LLMs with Analytic Hierarchy Process",
        "track": "main",
        "status": "Accept",
        "keywords": "Adversarial Robustness;Analytic Hierarchy Process;AI Feedback",
        "primary_area": "",
        "author": "Jiahao Zhao;Minzheng Wang;Nan Xu;YinLuo;Wenji Mao",
        "authorids": "~Jiahao_Zhao1;~Minzheng_Wang2;~Nan_Xu1;~YinLuo1;~Wenji_Mao1",
        "aff": "Institute of Automation\uff0cChinese Academy of Sciences;Institute of Automation, Chinese Academy of Sciences;Institute of automation, Chinese academy of science, Chinese Academy of Sciences",
        "aff_domain": "ia.ac.cn",
        "position": "PhD student;Assistant Professor;Full Professor",
        "rating": "",
        "confidence": "3;3;3;2",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 2.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DOMP5AgwQz",
        "title": "CTIKG: LLM-Powered Knowledge Graph Construction from Cyber Threat Intelligence",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model;Machine Learning and Security;Knowledge Graph;Information Extraction",
        "primary_area": "",
        "author": "Liangyi Huang;Xusheng Xiao",
        "authorids": "~Liangyi_Huang1;~Xusheng_Xiao2",
        "aff": "Arizona State University",
        "aff_domain": "asu.edu",
        "position": "PhD student;Associate Professor",
        "rating": "",
        "confidence": "4;4;2;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DRffhKBVlE",
        "title": "LITE: Modeling Environmental Ecosystems with Multimodal Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Environmental Ecosystems;Foundation Models;Spatio-temporal Data;Multimodal Learning",
        "primary_area": "",
        "author": "Haoran Li;Junqi Liu;Zexian Wang;Shiyuan Luo;Xiaowei Jia;Huaxiu Yao",
        "authorids": "~Haoran_Li16;~Junqi_Liu2;~Zexian_Wang1;~Shiyuan_Luo1;~Xiaowei_Jia1;~Huaxiu_Yao1",
        "aff": "University of Pittsburgh;University of Michigan - Ann Arbor;Computer Science Department, Stanford University;Sichuan University",
        "aff_domain": "cs.stanford.edu;umich.edu;scu.edu.cn;pitt.edu",
        "position": "Undergrad student;Postdoc;Assistant Professor;MS student",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DbsLm2KAqP",
        "title": "CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting",
        "track": "main",
        "status": "Accept",
        "keywords": "culture;bias;nationality;prompting;knowledge",
        "primary_area": "",
        "author": "Huihan Li;Liwei Jiang;Nouha Dziri;Xiang Ren;Yejin Choi",
        "authorids": "~Huihan_Li1;~Liwei_Jiang2;~Nouha_Dziri2;~Xiang_Ren1;~Yejin_Choi1",
        "aff": "University of Washington;University of Southern California;Department of Computer Science, University of Washington",
        "aff_domain": "usc.edu;washington.edu;cs.washington.edu",
        "position": "PhD student;PhD student;Associate Professor;Professor",
        "rating": "",
        "confidence": "5;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DomBynQsqt",
        "title": "3M-Diffusion: Latent Multi-Modal Diffusion for Language-Guided Molecular Structure Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "Multi-modal;Molecule Generation;Diffusion Model",
        "primary_area": "",
        "author": "Huaisheng Zhu;Teng Xiao;Vasant G Honavar",
        "authorids": "~Huaisheng_Zhu1;~Teng_Xiao2;~Vasant_G_Honavar1",
        "aff": "Pennsylvania State University",
        "aff_domain": "psu.edu;ist.psu.edu",
        "position": "PhD student;Full Professor",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Dt6qXZsgaU",
        "title": "Self-Guide: Better Task-Specific Instruction Following via Self-Synthetic Finetuning",
        "track": "main",
        "status": "Accept",
        "keywords": "instruction following;synthetic data;self-training",
        "primary_area": "",
        "author": "Chenyang Zhao;Xueying Jia;Vijay Viswanathan;Graham Neubig;Tongshuang Wu",
        "authorids": "~Chenyang_Zhao6;~Xueying_Jia1;~Vijay_Viswanathan1;~Graham_Neubig1;~Tongshuang_Wu1",
        "aff": "The Department of Computer Science and Technology, Tsinghua University;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University",
        "aff_domain": "cmu.edu;cs.cmu.edu;cs.tsinghua.edu.cn",
        "position": "Undergrad student;Associate Professor;Assistant Professor;PhD student;MS student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EEPBOB2Xww",
        "title": "Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Multimodal Large Language Model;Referring;Grounding",
        "primary_area": "",
        "author": "Haotian Zhang;Haoxuan You;Philipp Dufter;Bowen Zhang;Chen Chen;Hong-You Chen;Tsu-Jui Fu;William Yang Wang;Shih-Fu Chang;Zhe Gan;Yinfei Yang",
        "authorids": "~Haotian_Zhang3;~Haoxuan_You1;~Philipp_Dufter1;~Bowen_Zhang2;~Chen_Chen41;~Hong-You_Chen1;~Tsu-Jui_Fu2;~William_Yang_Wang2;~Shih-Fu_Chang3;~Zhe_Gan1;~Yinfei_Yang1",
        "aff": "Apple;UC Santa Barbara;Apple AI/ML;Columbia University",
        "aff_domain": "ucsb.edu;columbia.edu;apple.com",
        "position": "Research Scientist;Researcher;PhD student;Machine Learning Engineer;professor;PhD student;Researcher;Staff Research Scientist;Researcher;Full Professor",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EHPns3hVkj",
        "title": "Tower: An Open Multilingual Large Language Model for Translation-Related Tasks",
        "track": "main",
        "status": "Accept",
        "keywords": "Machine Translation;Multilinguality;Adaptation;Continual Pretraining",
        "primary_area": "",
        "author": "Duarte Miguel Alves;Jos\u00e9 Pombal;Nuno M Guerreiro;Pedro Henrique Martins;Jo\u00e3o Alves;Amin Farajian;Ben Peters;Ricardo Rei;Patrick Fernandes;Sweta Agrawal;Pierre Colombo;Jos\u00e9 G. C. de Souza;Andre Martins",
        "authorids": "~Duarte_Miguel_Alves1;~Jos\u00e9_Pombal1;~Nuno_M_Guerreiro1;~Pedro_Henrique_Martins1;~Jo\u00e3o_Alves2;~Amin_Farajian1;~Ben_Peters1;~Ricardo_Rei1;~Patrick_Fernandes1;~Sweta_Agrawal1;~Pierre_Colombo2;~Jos\u00e9_G._C._de_Souza1;~Andre_Martins1",
        "aff": "Unbabel;Feedzai;INESC-ID;Instituto Superior T\u00e9cnico;University of Maryland, College Park;CentraleSupelec",
        "aff_domain": "feedzai.com;unbabel.com;inesc-id.pt;centralesupelec.fr;umd.edu;tecnico.ulisboa.pt",
        "position": "Researcher;Research Scientist;PhD student;PhD student;Intern;PhD student;PhD student;Researcher;Assistant Professor;PhD student;Researcher;Researcher",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EIjJ6ykPnh",
        "title": "D2PO: Discriminator-Guided DPO with Response Evaluation Models",
        "track": "main",
        "status": "Accept",
        "keywords": "RLHF;Reward Models;Data Efficiency",
        "primary_area": "",
        "author": "Prasann Singhal;Nathan Lambert;Scott Niekum;Tanya Goyal;Greg Durrett",
        "authorids": "~Prasann_Singhal1;~Nathan_Lambert1;~Scott_Niekum1;~Tanya_Goyal1;~Greg_Durrett1",
        "aff": "University of Texas, Austin;University of Massachusetts at Amherst;, University of Texas at Austin;HuggingFace",
        "aff_domain": "cs.utexas.edu;huggingface.co;umass.edu;utexas.edu",
        "position": "Assistant Professor;Researcher;Undergrad student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EKBPn7no4y",
        "title": "StructLM: Towards Building Generalist Models for Structured Knowledge Grounding",
        "track": "main",
        "status": "Accept",
        "keywords": "Structured Data\uff1bInstruction Tuning Dataset\uff1bModel Scalability Analysis",
        "primary_area": "",
        "author": "Alex Zhuang;Ge Zhang;Tianyu Zheng;Xinrun Du;Junjie Wang;Weiming Ren;Wenhao Huang;Jie Fu;Xiang Yue;Wenhu Chen",
        "authorids": "~Alex_Zhuang1;~Ge_Zhang5;~Tianyu_Zheng1;~Xinrun_Du1;~Junjie_Wang2;~Weiming_Ren1;~Wenhao_Huang1;~Jie_Fu2;~Xiang_Yue1;~Wenhu_Chen3",
        "aff": "Beijing Academy of Artificial Intelligence;Google;University of Toronto;Waseda University;, University of Waterloo",
        "aff_domain": "baai.ac.cn;cs.toronto.edu;waseda.jp;cs.uwaterloo.ca;google.com",
        "position": "Undergrad student;Intern;PhD student;MS student;Researcher;Researcher",
        "rating": "",
        "confidence": "4;4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ecgev5ZZpq",
        "title": "Evaluating the Adversarial Robustness of Retrieval-Based In-Context Learning for Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Adversarial Robustness;Adversarial Attack and Defences;Retrieval-based LLM;In-context Learning;Evaluation",
        "primary_area": "",
        "author": "Simon Chi Lok Yu;Jie He;Pasquale Minervini;Jeff Z. Pan",
        "authorids": "~Simon_Chi_Lok_Yu1;~Jie_He3;~Pasquale_Minervini4;~Jeff_Z._Pan1",
        "aff": "University of Edinburgh, University of Edinburgh;University of Edinburgh",
        "aff_domain": "ed.ac.uk",
        "position": "Full Professor;PhD student;Undergrad student;Assistant Professor",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "F2yGbwXJAi",
        "title": "Suspicion Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4",
        "track": "main",
        "status": "Accept",
        "keywords": "Imperfect Information Games;Large Language Models;Theory of Mind",
        "primary_area": "",
        "author": "Jiaxian Guo;Bo Yang;Paul Yoo;Bill Yuchen Lin;Yusuke Iwasawa;Yutaka Matsuo",
        "authorids": "~Jiaxian_Guo2;~Bo_Yang16;~Paul_Yoo1;~Bill_Yuchen_Lin1;~Yusuke_Iwasawa1;~Yutaka_Matsuo1",
        "aff": "Allen Institute for Artificial Intelligence;KDDI Research, Inc.;The University of Tokyo;The University of Tokyo, The University of Tokyo",
        "aff_domain": "u-tokyo.ac.jp;allenai.org;weblab.t.u-tokyo.ac.jp;kddi.com",
        "position": "Researcher;Researcher;Postdoc;Researcher;Lecturer;Associate Professor",
        "rating": "",
        "confidence": "4;5;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "F7aAhfitX6",
        "title": "Massive Activations in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "massive activations;biases;self-attention",
        "primary_area": "",
        "author": "Mingjie Sun;Xinlei Chen;J Zico Kolter;Zhuang Liu",
        "authorids": "~Mingjie_Sun1;~Xinlei_Chen1;~J_Zico_Kolter1;~Zhuang_Liu1",
        "aff": "Bosch;Meta;Computer Science Department, Carnegie Mellon University;FAIR, Meta AI",
        "aff_domain": "meta.com;cs.cmu.edu;fb.com;bosch.com",
        "position": "PhD student;Researcher;Chief Scientist of AI Research;Research Scientist",
        "rating": "",
        "confidence": "4;4;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "F9tqgOPXH5",
        "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents",
        "track": "main",
        "status": "Accept",
        "keywords": "Environment Generation;Large Language Models;Embodied AI;Reinforcement Learning;Game Environments;Adaptive Generation;Skill Learning;Efficiency",
        "primary_area": "",
        "author": "Abhay Zala;Jaemin Cho;Han Lin;Jaehong Yoon;Mohit Bansal",
        "authorids": "~Abhay_Zala1;~Jaemin_Cho1;~Han_Lin1;~Jaehong_Yoon1;~Mohit_Bansal2",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST);Department of Computer Science, University of North Carolina at Chapel Hill;University of North Carolina at Chapel Hill;University of North Carolina, Chapel Hill",
        "aff_domain": "kaist.ac.kr;cs.unc.edu;unc.edu",
        "position": "MS student;PhD student;PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FX4fUThO9H",
        "title": "Model Autophagy Analysis to Explicate Self-consumption within Human-AI Interactions",
        "track": "main",
        "status": "Accept",
        "keywords": "Human-AI Interactions; Communication",
        "primary_area": "",
        "author": "Shu Yang;Muhammad Asif Ali;Lu Yu;Lijie Hu;Di Wang",
        "authorids": "~Shu_Yang10;~Muhammad_Asif_Ali1;~Lu_Yu1;~Lijie_Hu1;~Di_Wang1",
        "aff": "King Abdullah University of Science and Technology;KAUST;University of Macau",
        "aff_domain": "umac.mo;kaust.edu.sa",
        "position": "PhD student;Postdoc;MS student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FbhjirzvJG",
        "title": "Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding",
        "track": "main",
        "status": "Accept",
        "keywords": "Speculative Decoding;Medusa;Draft Heads;Blockwise Parallel Decoding",
        "primary_area": "",
        "author": "Zachary Ankner;Rishab Parthasarathy;Aniruddha Nrusimha;Christopher Rinard;Jonathan Ragan-Kelley;William Brandon",
        "authorids": "~Zachary_Ankner1;~Rishab_Parthasarathy1;~Aniruddha_Nrusimha1;~Christopher_Rinard1;~Jonathan_Ragan-Kelley1;~William_Brandon1",
        "aff": "International Business Machines;MIT;Massachusetts Institute of Technology",
        "aff_domain": "ibm.com;mit.edu",
        "position": "Ph.D. candidate;Undergrad student;Associate Professor;Undergrad student;Intern;Undergrad student",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FgHpT6u7pk",
        "title": "CoCA: Regaining Safety-awareness of Multimodal Large Language Models with Constitutional Calibration",
        "track": "main",
        "status": "Accept",
        "keywords": "Multimodal Large Language Model;Safety",
        "primary_area": "",
        "author": "Jiahui Gao;Renjie Pi;Tianyang Han;Han Wu;Lanqing HONG;Lingpeng Kong;Xin Jiang;Zhenguo Li",
        "authorids": "~Jiahui_Gao2;~Renjie_Pi1;~Tianyang_Han1;~Han_Wu5;~Lanqing_HONG1;~Lingpeng_Kong1;~Xin_Jiang1;~Zhenguo_Li1",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies;Hong Kong University of Science and Technology;City University of Hong Kong;Hong Kong Polytechnic University;Department of Computer Science, The University of Hong Kong;Huawei Technologies Ltd.;Huawei Noah's Ark Lab",
        "aff_domain": "ust.hk;connect.polyu.hk;huawei.com;cityu.edu.hk;cs.hku.hk",
        "position": "PhD student;Researcher;Assistant Professor;PhD student;MS student;Principal Researcher;Principal Researcher",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Fkr1yVUb9G",
        "title": "CoLLEGe: Concept Embedding Generation for Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "meta-learning;few-shot learning;concept learning",
        "primary_area": "",
        "author": "Ryan Teehan;Brenden Lake;Mengye Ren",
        "authorids": "~Ryan_Teehan1;~Brenden_M._Lake1;~Mengye_Ren1",
        "aff": "New York University",
        "aff_domain": "nyu.edu",
        "position": "Assistant Professor;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FmhPg4UJ9K",
        "title": "Counting Like Transformers: Compiling Temporal Counting Logic Into Softmax Transformers",
        "track": "main",
        "status": "Accept",
        "keywords": "Transformer Encoders;Transformer Decoders;Formal Expressivity;Formal Language Theory;RASP;Temporal Logic;Counting Logic;",
        "primary_area": "",
        "author": "Andy Yang;David Chiang",
        "authorids": "~Andy_Yang1;~David_Chiang1",
        "aff": "University of Notre Dame",
        "aff_domain": "nd.edu",
        "position": "Associate Professor",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "G8LaO1P0xv",
        "title": "A Long Way to Go: Investigating Length Correlations in RLHF",
        "track": "main",
        "status": "Accept",
        "keywords": "Natural Language Processing;Large Language Models;RLHF;Reward Hacking",
        "primary_area": "",
        "author": "Prasann Singhal;Tanya Goyal;Jiacheng Xu;Greg Durrett",
        "authorids": "~Prasann_Singhal1;~Tanya_Goyal1;~Jiacheng_Xu2;~Greg_Durrett1",
        "aff": "University of Texas, Austin;SalesForce.com;, University of Texas at Austin",
        "aff_domain": "cs.utexas.edu;salesforce.com;utexas.edu",
        "position": "Assistant Professor;Researcher;Undergrad student;PhD student",
        "rating": "",
        "confidence": "4;4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.8,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GC4mXVfquq",
        "title": "JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks",
        "track": "main",
        "status": "Accept",
        "keywords": "Jailbreak;benchmark;vlm;safety",
        "primary_area": "",
        "author": "Weidi Luo;Siyuan Ma;Xiaogeng Liu;Xiaoyu Guo;Chaowei Xiao",
        "authorids": "~Weidi_Luo1;~Siyuan_Ma4;~Xiaogeng_Liu1;~Xiaoyu_Guo3;~Chaowei_Xiao2",
        "aff": "Ohio State University, Columbus;Huazhong University of Science and Technology;Arizona State University;University of Wisconsin - Madison;Peking University",
        "aff_domain": "wisc.edu;asu.edu;osu.edu;stu.pku.edu.cn;hust.edu.cn",
        "position": "Undergrad student;Undergrad student;MS student;MS student;Assistant Professor",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GMalvQu0XL",
        "title": "RAVEN: In-Context Learning with Retrieval-Augmented Encoder-Decoder Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Retrieval-Augmented Language Models;In-Context Learning;Encoder-Decoder Language Models",
        "primary_area": "",
        "author": "Jie Huang;Wei Ping;Peng Xu;Mohammad Shoeybi;Kevin Chang;Bryan Catanzaro",
        "authorids": "~Jie_Huang3;~Wei_Ping1;~Peng_Xu7;~Mohammad_Shoeybi1;~Kevin_Chang1;~Bryan_Catanzaro1",
        "aff": "University of Illinois, Urbana Champaign;University of Illinois at Urbana-Champaign;NVIDIA",
        "aff_domain": "illinois.edu;nvidia.com",
        "position": "PhD student;Full Professor;Director of Applied Resesrch;Researcher;Principal Researcher",
        "rating": "",
        "confidence": "3;5;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.8,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GqDntYTTbk",
        "title": "Starling-7B: Improving Helpfulness and Harmlessness with RLAIF",
        "track": "main",
        "status": "Accept",
        "keywords": "High quality dataset;Alignment;RLHF",
        "primary_area": "",
        "author": "Banghua Zhu;Evan Frick;Tianhao Wu;Hanlin Zhu;Karthik Ganesan;Wei-Lin Chiang;Jian Zhang;Jiantao Jiao",
        "authorids": "~Banghua_Zhu1;~Evan_Frick1;~Tianhao_Wu1;~Hanlin_Zhu2;~Karthik_Ganesan1;~Wei-Lin_Chiang1;~Jian_Zhang1;~Jiantao_Jiao1",
        "aff": "Sambanova Systems Inc.;University of California, Berkeley;University of California Berkeley;Electrical Engineering & Computer Science Department, University of California Berkeley",
        "aff_domain": "sambanovasystems.com;berkeley.edu;eecs.berkeley.edu",
        "position": "PhD student;Undergrad student;PhD student;Principle software engineer;Assistant Professor;PhD student;PhD student",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "H1Edd5d2JP",
        "title": "LLM4Causal: Democratized Causal Tools for Everyone via Large Language Model",
        "track": "main",
        "status": "Accept",
        "keywords": "Causal Decision-Making;LLM with Tools;Output Interpretation;Domain-specific Dataset",
        "primary_area": "",
        "author": "Haitao Jiang;Lin Ge;Yuhe Gao;Jianian Wang;Rui Song",
        "authorids": "~Haitao_Jiang1;~Lin_Ge1;~Yuhe_Gao1;~Jianian_Wang1;~Rui_Song2",
        "aff": "North Carolina State University",
        "aff_domain": "ncsu.edu",
        "position": "PhD student;PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HDkNbfLQgu",
        "title": "Reverse Training to Nurse the Reversal Curse",
        "track": "main",
        "status": "Accept",
        "keywords": "LLMs;Large Language Models;Question Answering;Generalization;Knowledge Representation;Logical Inference;Relations",
        "primary_area": "",
        "author": "Olga Golovneva;Zeyuan Allen-Zhu;Jason E Weston;Sainbayar Sukhbaatar",
        "authorids": "~Olga_Golovneva1;~Zeyuan_Allen-Zhu1;~Jason_E_Weston1;~Sainbayar_Sukhbaatar1",
        "aff": "Meta AI;Facebook",
        "aff_domain": "meta.com;fb.com",
        "position": "Researcher;Research Scientist",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HLoWN6m4fS",
        "title": "Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Memorization;Few-Shot Learning;Tabular Data",
        "primary_area": "",
        "author": "Sebastian Bordt;Harsha Nori;Vanessa Cristiny Rodrigues Vasconcelos;Besmira Nushi;Rich Caruana",
        "authorids": "~Sebastian_Bordt1;~Harsha_Nori1;~Vanessa_Cristiny_Rodrigues_Vasconcelos1;~Besmira_Nushi1;~Rich_Caruana1",
        "aff": "Microsoft;Max Planck Institute for Intelligent Systems, Max-Planck Institute",
        "aff_domain": "tue.mpg.de;microsoft.com",
        "position": "Researcher;Research Engineer;PhD student;Researcher",
        "rating": "",
        "confidence": "2;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HVK6nl3i97",
        "title": "TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding",
        "track": "main",
        "status": "Accept",
        "keywords": "Long-context model;Speculative decoding;LLM efficiency",
        "primary_area": "",
        "author": "Hanshi Sun;Zhuoming Chen;Xinyu Yang;Yuandong Tian;Beidi Chen",
        "authorids": "~Hanshi_Sun1;~Zhuoming_Chen1;~Xinyu_Yang4;~Yuandong_Tian1;~Beidi_Chen1",
        "aff": "Meta AI (FAIR);Shanghai Jiaotong University;Tsinghua University, Tsinghua University;Facebook;Southeast University",
        "aff_domain": "seu.edu.cn;tsinghua.edu.cn;meta.com;fb.com;sjtu.edu.cn",
        "position": "Researcher;Undergrad student;Undergrad student;Research Scientist;Undergrad student",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Hi8jKh4HE9",
        "title": "What is in Your Safe Data? Identifying Benign Data that Breaks Safety",
        "track": "main",
        "status": "Accept",
        "keywords": "AI Safety;AI Alignment;Data Selection;Data Problems;Fine-tuning Vulnerabilities",
        "primary_area": "",
        "author": "Luxi He;Mengzhou Xia;Peter Henderson",
        "authorids": "~Luxi_He1;~Mengzhou_Xia1;~Peter_Henderson1",
        "aff": "Stanford University;Harvard University;Princeton University",
        "aff_domain": "princeton.edu;stanford.edu;harvard.edu",
        "position": "Undergrad student;PhD student;PhD student",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Hvq9RtSoHG",
        "title": "Chain-of-Symbol Prompting For Spatial Reasoning in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "In-Context Learning;Chain-of-Thought Prompting;Spatial Reasoning",
        "primary_area": "",
        "author": "Hanxu Hu;Hongyuan Lu;Huajian Zhang;Yun-Ze Song;Wai Lam;Yue Zhang",
        "authorids": "~Hanxu_Hu1;~Hongyuan_Lu2;~Huajian_Zhang1;~Yun-Ze_Song1;~Wai_Lam1;~Yue_Zhang7",
        "aff": "The Chinese University of Hong Kong;Westlake University;Xi'an Jiaotong-Liverpool University ;Microsoft Corporation",
        "aff_domain": "cuhk.edu.hk;westlake.edu;microsoft.com;liverpool.ac.uk;westlake.edu.cn",
        "position": "Research Assistant;Intern;Professor;Full Professor;Undergrad student",
        "rating": "",
        "confidence": "4;5;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IA8CWtNkUr",
        "title": "Early Weight Averaging meets High Learning Rates for LLM Pre-training",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM pre-training;High learning rates;Weight Averaging;Model merging",
        "primary_area": "",
        "author": "Sunny Sanyal;Atula Tejaswi Neerkaje;Jean Kaddour;Abhishek Kumar;sujay sanghavi",
        "authorids": "~Sunny_Sanyal1;~Atula_Tejaswi_Neerkaje1;~Jean_Kaddour1;~Abhishek_Kumar1;~sujay_sanghavi1",
        "aff": "University of Texas, Austin;University of Texas at Austin;Google DeepMind;Manipal Institute of Technology;University College London",
        "aff_domain": "utexas.edu;ucl.ac.uk;manipal.edu;google.com",
        "position": "Research Scientist;Undergrad student;PhD student;PhD student;Associate Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IBCBMeAhmC",
        "title": "Evaluating Language Models for Efficient Code Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "Code Generation;Evaluation;Code Efficiency",
        "primary_area": "",
        "author": "Jiawei Liu;Songrun Xie;Junhao Wang;Yuxiang Wei;Yifeng Ding;LINGMING ZHANG",
        "authorids": "~Jiawei_Liu11;~Songrun_Xie1;~Junhao_Wang7;~Yuxiang_Wei2;~Yifeng_Ding2;~LINGMING_ZHANG2",
        "aff": "Tongji University;Department of Computer Science, University of Illinois at Urbana-Champaign;University of Illinois Urbana-Champaign;Department of Computer Science;University of Illinois at Urbana-Champaign",
        "aff_domain": "tongji.edu.cn;cs.illinois.edu;illinois.edu",
        "position": "PhD student;Undergrad student;Associate Professor;Undergrad student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "INivcBeIDK",
        "title": "AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "large language models;adversarial robustness;jailbreak attacks;red-teaming;controllable generation",
        "primary_area": "",
        "author": "Sicheng Zhu;Ruiyi Zhang;Bang An;Gang Wu;Joe Barrow;Zichao Wang;Furong Huang;Ani Nenkova;Tong Sun",
        "authorids": "~Sicheng_Zhu1;~Ruiyi_Zhang3;~Bang_An1;~Gang_Wu4;~Joe_Barrow2;~Zichao_Wang1;~Furong_Huang1;~Ani_Nenkova1;~Tong_Sun1",
        "aff": "Adobe Research;Rice University;University of Maryland;Capital One;University of Maryland, College Park;Adobe Systems",
        "aff_domain": "capitalone.com;rice.edu;adobe.com;umd.edu;cs.umd.edu",
        "position": "Intern;Assistant Professor;Researcher;Researcher;PhD student;Director, Document Intelligence Lab;PhD student;Research Scientist",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IPZ28ZqD4I",
        "title": "Faithful and Unfaithful Error Recovery in Chain of Thought",
        "track": "main",
        "status": "Accept",
        "keywords": "chain of thought;error recovery;reasoning;faithfulness",
        "primary_area": "",
        "author": "Evelyn Yee;Alice Li;Chenyu Tang;Yeon Ho Jung;Ramamohan Paturi;Leon Bergen",
        "authorids": "~Evelyn_Yee1;~Alice_Li3;~Chenyu_Tang1;~Yeon_Ho_Jung1;~Ramamohan_Paturi1;~Leon_Bergen1",
        "aff": "University of California, San Diego",
        "aff_domain": "ucsd.edu",
        "position": "Undergrad student;Undergrad student;Undergrad student;Associate Professor;Full Professor;Intern",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IW1PR7vEBf",
        "title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders",
        "track": "main",
        "status": "Accept",
        "keywords": "text embeddings;large language models;adaptation",
        "primary_area": "",
        "author": "Parishad BehnamGhader;Vaibhav Adlakha;Marius Mosbach;Dzmitry Bahdanau;Nicolas Chapados;Siva Reddy",
        "authorids": "~Parishad_BehnamGhader1;~Vaibhav_Adlakha1;~Marius_Mosbach1;~Dzmitry_Bahdanau1;~Nicolas_Chapados1;~Siva_Reddy1",
        "aff": "Mila, McGill University;ServiceNow Research;McGill University;Saarland University;McGill University - Mila",
        "aff_domain": "uni-saarland.de;mail.mcgill.ca;mcgill.ca;mila.quebec;servicenow.com",
        "position": "Research Scientist;PhD student;VP Research;MS student;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JXcXnJJSuL",
        "title": "Information-Theoretic Distillation for Reference-less Summarization",
        "track": "main",
        "status": "Accept",
        "keywords": "summarization; self-training; distillation; PMI maximization",
        "primary_area": "",
        "author": "Jaehun Jung;Ximing Lu;Liwei Jiang;Faeze Brahman;Peter West;Pang Wei Koh;Yejin Choi",
        "authorids": "~Jaehun_Jung1;~Ximing_Lu1;~Liwei_Jiang2;~Faeze_Brahman1;~Peter_West1;~Pang_Wei_Koh1;~Yejin_Choi1",
        "aff": "Department of Computer Science, University of Washington;University of Washington;Allen Institute for AI;Google;Allen Institute for Artificial Intelligence",
        "aff_domain": "allenai.org;cs.washington.edu;washington.edu;uw.edu;google.com",
        "position": "Postdoc;PhD student;PhD student;Researcher;Intern;Undergrad student;Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Jd0bCD12DS",
        "title": "Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning",
        "track": "main",
        "status": "Accept",
        "keywords": "Privacy;User-level privacy;Differential privacy",
        "primary_area": "",
        "author": "Lynn Chua;Badih Ghazi;Yangsibo Huang;Pritish Kamath;Ravi Kumar;Daogao Liu;Pasin Manurangsi;Amer Sinha;Chiyuan Zhang",
        "authorids": "~Lynn_Chua1;~Badih_Ghazi1;~Yangsibo_Huang2;~Pritish_Kamath2;~Ravi_Kumar1;~Daogao_Liu1;~Pasin_Manurangsi2;~Amer_Sinha1;~Chiyuan_Zhang1",
        "aff": "University of Washington, Seattle;Google Research;Google;Princeton University;Research, Google",
        "aff_domain": "research.google.com;princeton.edu;uw.edu;google.com",
        "position": "Researcher;Researcher;Research Scientist;PhD student;Researcher;Research Scientist;Research Scientist;Research Scientist;PhD student",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "K1M3gLW0MX",
        "title": "On Fairness of Low-Rank Adaptation of Large Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Low-rank adaptation;LoRA;bias;fairness;subgroup fairness;evaluations;LLMs;large models",
        "primary_area": "",
        "author": "Zhoujie Ding;Ken Liu;Pura Peetathawatchai;Berivan Isik;Sanmi Koyejo",
        "authorids": "~Zhoujie_Ding1;~Ken_Liu1;~Pura_Peetathawatchai1;~Berivan_Isik1;~Sanmi_Koyejo1",
        "aff": "Amazon;Google;Computer Science Department, Stanford University;Carnegie Mellon University",
        "aff_domain": "cs.stanford.edu;cs.cmu.edu;amazon.com;google.com",
        "position": "Research Intern;MS student;MS student;MS student;Research Scientist",
        "rating": "",
        "confidence": "5;3;5;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KZd1EErRJ1",
        "title": "IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic Representations",
        "track": "main",
        "status": "Accept",
        "keywords": "large language models;vision language models;evaluation;isomorphism",
        "primary_area": "",
        "author": "Deqing Fu;Ruohao Guo;Ghazal Khalighinejad;Ollie Liu;Bhuwan Dhingra;Dani Yogatama;Robin Jia;Willie Neiswanger",
        "authorids": "~Deqing_Fu1;~Ruohao_Guo2;~Ghazal_Khalighinejad1;~Ollie_Liu1;~Bhuwan_Dhingra1;~Dani_Yogatama2;~Robin_Jia1;~Willie_Neiswanger2",
        "aff": "Stanford University;University of Southern California;DeepMind;Department of Computer Science, Duke University;Georgia Institute of Technology;Duke University",
        "aff_domain": "cs.duke.edu;duke.edu;google.com;usc.edu;stanford.edu;gatech.edu",
        "position": "Assistant Professor;PhD student;PhD student;PhD student;Assistant Professor;PhD student;Postdoc;Research Scientist",
        "rating": "",
        "confidence": "3;5;5;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KidynPuLNW",
        "title": "On Limitations of the Transformer Architecture",
        "track": "main",
        "status": "Accept",
        "keywords": "Transformer;computation complexity;communication complexity",
        "primary_area": "",
        "author": "Binghui Peng;Srini Narayanan;Christos Papadimitriou",
        "authorids": "~Binghui_Peng1;~Srini_Narayanan1;~Christos_Papadimitriou2",
        "aff": "Columbia University;Google DeepMind",
        "aff_domain": "columbia.edu;google.com",
        "position": "PhD student;Full Professor;Distinguished Scientist",
        "rating": "",
        "confidence": "4;3;2;2",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 2.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KqK5XcgEhR",
        "title": "Empowering Large Language Model Agents through Action Learning",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model Agent;Agent;Large Language Model",
        "primary_area": "",
        "author": "Haiteng Zhao;Chang Ma;Guoyin Wang;Jing Su;Lingpeng Kong;Jingjing Xu;Zhi-Hong Deng;Hongxia Yang",
        "authorids": "~Haiteng_Zhao1;~Chang_Ma2;~Guoyin_Wang1;~Jing_Su2;~Lingpeng_Kong1;~Jingjing_Xu1;~Zhi-Hong_Deng1;~Hongxia_Yang2",
        "aff": "Amazon;ByteDance Inc.;Department of Computer Science, The University of Hong Kong;Peking University;University of Hong Kong",
        "aff_domain": "amazon.com;pku.edu.cn;bytedance.com;cs.hku.hk;hku.hk",
        "position": "Researcher;PhD student;Principal Researcher;Assistant Professor;Full Professor;PhD student",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LFfktMPAci",
        "title": "What makes a good metric? Evaluating automatic metrics for text-to-image consistency",
        "track": "main",
        "status": "Accept",
        "keywords": "text-to-image;evaluation;automatic evaluation;multimodal;vision-language",
        "primary_area": "",
        "author": "Candace Ross;Melissa Hall;Adriana Romero-Soriano;Adina Williams",
        "authorids": "~Candace_Ross1;~Melissa_Hall1;~Adriana_Romero-Soriano1;~Adina_Williams1",
        "aff": "FAIR, Meta AI;FAIR (Meta Platforms Inc.);Meta;Research, Facebook",
        "aff_domain": "fb.com;meta.com;research.facebook.com;facebook.com",
        "position": "Research Scientist;Postdoc;Researcher;Research Scientist",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LKEJPySnlt",
        "title": "Lory: Fully Differentiable Mixture-of-Experts for Autoregressive Language Model Pre-training",
        "track": "main",
        "status": "Accept",
        "keywords": "Mixture of Experts;Language Modeling;Language Model Pre-training",
        "primary_area": "",
        "author": "Zexuan Zhong;Mengzhou Xia;Danqi Chen;Mike Lewis",
        "authorids": "~Zexuan_Zhong1;~Mengzhou_Xia1;~Danqi_Chen1;~Mike_Lewis1",
        "aff": "Department of Computer Science, Princeton University;Facebook AI Research;Princeton University",
        "aff_domain": "cs.princeton.edu;princeton.edu;fb.com",
        "position": "Assistant Professor;PhD student;Research Scientist;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LWfDcI6txJ",
        "title": "Forklift: An Extensible Neural Lifter",
        "track": "main",
        "status": "Accept",
        "keywords": "Transformer;translation;transpilation;binary translation;compiler;software migration",
        "primary_area": "",
        "author": "Jordi Armengol-Estap\u00e9;Rodrigo C. O. Rocha;Jackson Woodruff;Pasquale Minervini;Michael O'Boyle",
        "authorids": "~Jordi_Armengol-Estap\u00e91;~Rodrigo_C._O._Rocha1;~Jackson_Woodruff1;~Pasquale_Minervini4;~Michael_O'Boyle1",
        "aff": "University of Edinburgh, University of Edinburgh;Bloomberg;Huawei Technologies Ltd.;Edinburgh University, University of Edinburgh",
        "aff_domain": "bloomberg.net;ed.ac.uk;huawei.com;inf.ed.ac.uk",
        "position": "PhD student;Intern;Full Professor;Researcher;Assistant Professor",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Lmjgl2n11u",
        "title": "Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models - A Survey",
        "track": "main",
        "status": "Accept",
        "keywords": "Reasoning in Large Language Models;Reasoning Behavior;Evaluating Reasoning;Logical Reasoning;Mathematical Reasoning;Causal Reasoning",
        "primary_area": "",
        "author": "Philipp Mondorf;Barbara Plank",
        "authorids": "~Philipp_Mondorf1;~Barbara_Plank2",
        "aff": "Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen;IT University of Copenhagen",
        "aff_domain": "itu.dk;lmu.de",
        "position": "Full Professor;PhD student",
        "rating": "",
        "confidence": "3;3;4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LzpaUxcNFK",
        "title": "From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples",
        "track": "main",
        "status": "Accept",
        "keywords": "regression;emergent capabilities",
        "primary_area": "",
        "author": "Robert Vacareanu;Vlad Andrei Negru;Vasile Suciu;Mihai Surdeanu",
        "authorids": "~Robert_Vacareanu1;~Vlad_Andrei_Negru1;~Vasile_Suciu1;~Mihai_Surdeanu1",
        "aff": "University of Arizona;Technical University of Cluj-Napoca",
        "aff_domain": "utcluj.ro;arizona.edu",
        "position": "Full Professor;PhD student;PhD student;MS student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MI52iXSSNy",
        "title": "Commonsense-T2I Challenge: Can Text-to-Image Generation Models Understand Commonsense?",
        "track": "main",
        "status": "Accept",
        "keywords": "text to image generation;alignment with reality;commonsense reasoning",
        "primary_area": "",
        "author": "Xingyu Fu;Muyu He;Yujie Lu;William Yang Wang;Dan Roth",
        "authorids": "~Xingyu_Fu1;~Muyu_He1;~Yujie_Lu1;~William_Yang_Wang2;~Dan_Roth3",
        "aff": "Amazon;UC Santa Barbara;University of Pennsylvania, University of Pennsylvania",
        "aff_domain": "seas.upenn.edu;ucsb.edu;amazon.com",
        "position": "VP and Distinguished Scientist;MS student;PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MLD1cwfjUb",
        "title": "Your Context Is Not an Array: Unveiling Random Access Limitations in Transformers",
        "track": "main",
        "status": "Accept",
        "keywords": "Transformers;Large Language Models;Length Generalization;Arithmetic Tasks;Context Addressing",
        "primary_area": "",
        "author": "MohammadReza Ebrahimi;Sunny Panchal;Roland Memisevic",
        "authorids": "~MohammadReza_Ebrahimi1;~Sunny_Panchal1;~Roland_Memisevic1",
        "aff": "Universit\u00e9 de Montr\u00e9al;Qualcomm Inc, QualComm",
        "aff_domain": "umontreal.ca;qti.qualcomm.com",
        "position": "Intern;Assistant Professor",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MNLAbfZwh2",
        "title": "ScenicNL: Generating Probabilistic Scenario Programs from Natural Language",
        "track": "main",
        "status": "Accept",
        "keywords": "probabilistic programming languages;cyber physical systems;autonomous vehicles;scenarios;domain specific languages;low resource languages",
        "primary_area": "",
        "author": "Karim Elmaaroufi;Devan Shanker;Ana Cismaru;Marcell Vazquez-Chanlatte;Alberto Sangiovanni-Vincentelli;Matei Zaharia;Sanjit A. Seshia",
        "authorids": "~Karim_Elmaaroufi1;~Devan_Shanker1;~Ana_Cismaru1;~Marcell_Vazquez-Chanlatte1;~Alberto_Sangiovanni-Vincentelli1;~Matei_Zaharia1;~Sanjit_A._Seshia1",
        "aff": "University of California, Berkeley;Stanford University;University of California Berkeley;Electrical Engineering & Computer Science Department, University of California, Berkeley",
        "aff_domain": "berkeley.edu;eecs.berkeley.edu;stanford.edu",
        "position": "Full Professor;Undergrad student;Undergrad student;PhD student;PhD student;Associate Professor;Full Professor",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MXLBXjQkmb",
        "title": "Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning",
        "track": "main",
        "status": "Accept",
        "keywords": "Unlearning;RLHF;preference optimization",
        "primary_area": "",
        "author": "Ruiqi Zhang;Licong Lin;Yu Bai;Song Mei",
        "authorids": "~Ruiqi_Zhang2;~Licong_Lin2;~Yu_Bai1;~Song_Mei1",
        "aff": "University of California, Berkeley;University of California Berkeley;Salesforce Research",
        "aff_domain": "berkeley.edu;salesforce.com",
        "position": "PhD student;PhD student;Assistant Professor;Research Scientist",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MkppMETE49",
        "title": "Information Guided Regularization for Fine-tuning Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "regularization;finetuning;loss landscape;information;transfer learning",
        "primary_area": "",
        "author": "Mandar Sharma;Nikhil Muralidhar;Shengzhe Xu;Raquib Bin Yousuf;Naren Ramakrishnan",
        "authorids": "~Mandar_Sharma1;~Nikhil_Muralidhar1;~Shengzhe_Xu1;~Raquib_Bin_Yousuf1;~Naren_Ramakrishnan1",
        "aff": "Virginia Polytechnic Institute and State University;Stevens Institute of Technology",
        "aff_domain": "stevens.edu;vt.edu",
        "position": "PhD student;Assistant Professor;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MmBQSNHKUl",
        "title": "Are Language Models Robust Coreference Resolvers?",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Models;Coreference Resolution;CoNLL 2012;Robustness",
        "primary_area": "",
        "author": "Nghia T. Le;Alan Ritter",
        "authorids": "~Nghia_T._Le2;~Alan_Ritter1",
        "aff": "Georgia Institute of Technology",
        "aff_domain": "gatech.edu",
        "position": "Associate Professor;PhD student",
        "rating": "",
        "confidence": "3;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MoitXWlXcS",
        "title": "Why do small language models underperform? Studying Language Model Saturation via the Softmax Bottleneck",
        "track": "main",
        "status": "Accept",
        "keywords": "saturation;softmax bottleneck;anisotropy;pretraining;small language models",
        "primary_area": "",
        "author": "Nathan Godey;\u00c9ric Villemonte de la Clergerie;Beno\u00eet Sagot",
        "authorids": "~Nathan_Godey1;~\u00c9ric_Villemonte_de_la_Clergerie1;~Beno\u00eet_Sagot1",
        "aff": "INRIA;Inria",
        "aff_domain": "inria.fr",
        "position": "Research Director;PhD student;Researcher",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "N5EYQSwW26",
        "title": "Building a Large Japanese Web Corpus for Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "corpus;web;Common Crawl;Japanese;continual pre-training;Llama 2;Mistral;Mixtral",
        "primary_area": "",
        "author": "Naoaki Okazaki;Kakeru Hattori;Hirai Shota;Hiroki Iida;Masanari Ohi;Kazuki Fujii;Taishi Nakamura;Mengsay Loem;Rio Yokota;Sakae Mizuki",
        "authorids": "~Naoaki_Okazaki2;~Kakeru_Hattori1;~Hirai_Shota1;~Hiroki_Iida1;~Masanari_Ohi1;~Kazuki_Fujii1;~Taishi_Nakamura1;~Mengsay_Loem1;~Rio_Yokota1;~Sakae_Mizuki1",
        "aff": "Tokyo Institute of Technology;Tokyo Institute of Technology, Tokyo Institute of Technology",
        "aff_domain": "titech.ac.jp",
        "position": "MS student;PhD student;Undergrad student;Undergrad student;Undergrad student;MS student;Full Professor;Full Professor;PhD student;Undergrad student",
        "rating": "",
        "confidence": "5;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NPAQ6FKSmK",
        "title": "Autonomous Evaluation and Refinement of Digital Agents",
        "track": "main",
        "status": "Accept",
        "keywords": "Language Agent;Autonomous Refinement;Automatic Evaluation",
        "primary_area": "",
        "author": "Jiayi Pan;Yichi Zhang;Nicholas Tomlin;Yifei Zhou;Sergey Levine;Alane Suhr",
        "authorids": "~Jiayi_Pan1;~Yichi_Zhang1;~Nicholas_Tomlin1;~Yifei_Zhou1;~Sergey_Levine1;~Alane_Suhr1",
        "aff": "University of Michigan;Department of Computer Science, Cornell University;Shanghai Jiaotong University;University of California Berkeley;Google;Department of Computer Science",
        "aff_domain": "cs.cornell.edu;google.com;berkeley.edu;cs.washington.edu;sjtu.edu.cn;umich.edu",
        "position": "Postdoc;Undergrad student;PhD student;Research Scientist;PhD student;Undergrad student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NV8yRJRET1",
        "title": "DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning",
        "track": "main",
        "status": "Accept",
        "keywords": "Text-to-Diagram Generation;Large Language Models;Vector Graphic Generation;Iterative Refinement;Human-in-the-Loop",
        "primary_area": "",
        "author": "Abhay Zala;Han Lin;Jaemin Cho;Mohit Bansal",
        "authorids": "~Abhay_Zala1;~Han_Lin1;~Jaemin_Cho1;~Mohit_Bansal2",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill;University of North Carolina at Chapel Hill;University of North Carolina, Chapel Hill",
        "aff_domain": "cs.unc.edu;unc.edu",
        "position": "MS student;PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "3;3;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Nd950RAcCW",
        "title": "Multi-hop Question Answering under Temporal Knowledge Editing",
        "track": "main",
        "status": "Accept",
        "keywords": "Knowledge Editing;Multi-hop QA",
        "primary_area": "",
        "author": "Keyuan Cheng;Gang Lin;Haoyang Fei;Yuxuan Zhai;Lu Yu;Muhammad Asif Ali;Lijie Hu;Di Wang",
        "authorids": "~Keyuan_Cheng2;~Gang_Lin2;~Haoyang_Fei1;~Yuxuan_Zhai1;~Lu_Yu1;~Muhammad_Asif_Ali1;~Lijie_Hu1;~Di_Wang1",
        "aff": "King Abdullah University of Science and Technology;South China University of Technology;KAUST",
        "aff_domain": "kaust.edu.sa;scut.edu.cn",
        "position": "Undergrad student;Undergrad student;Undergrad student;PhD student;Postdoc;Undergrad student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NikbrdtYvG",
        "title": "Let\u2019s Think Dot by Dot: Hidden computation in transformer language models",
        "track": "main",
        "status": "Accept",
        "keywords": "filler;filler tokens;chain of thought;cot;faithfulness;expressivity;synthetic data;synthetic;transformer;language model;lm",
        "primary_area": "",
        "author": "Jacob Pfau;William Merrill;Samuel R. Bowman",
        "authorids": "~Jacob_Pfau1;~William_Merrill1;~Samuel_R._Bowman1",
        "aff": "New York University",
        "aff_domain": "nyu.edu",
        "position": "PhD student;Graduate student",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OJaWBhh61C",
        "title": "Best Practices and Lessons Learned on Synthetic Data",
        "track": "main",
        "status": "Accept",
        "keywords": "synthetic data;survey",
        "primary_area": "",
        "author": "Ruibo Liu;Jerry Wei;Fangyu Liu;Chenglei Si;Yanzhe Zhang;Jinmeng Rao;Steven Zheng;Daiyi Peng;Diyi Yang;Denny Zhou;Andrew M. Dai",
        "authorids": "~Ruibo_Liu1;~Jerry_Wei1;~Fangyu_Liu1;~Chenglei_Si1;~Yanzhe_Zhang1;~Jinmeng_Rao1;~Steven_Zheng1;~Daiyi_Peng1;~Diyi_Yang2;~Denny_Zhou1;~Andrew_M._Dai1",
        "aff": "Stanford University;Georgia Institute of Technology;Google DeepMind;Google;University of Wisconsin - Madison;University of Cambridge",
        "aff_domain": "wisc.edu;cam.ac.uk;google.com;stanford.edu;gatech.edu",
        "position": "PhD student;Assistant Professor;PhD student;PhD student;Researcher;PhD student;Software Engineer;Research Scientist;Student Researcher;Software Engineer",
        "rating": "",
        "confidence": "4;3;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PEQFHRUFca",
        "title": "A Reparameterized Discrete Diffusion Model for Text Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "discrete diffusion;text generation;non-autoregressive generation",
        "primary_area": "",
        "author": "Lin Zheng;Jianbo Yuan;Lei Yu;Lingpeng Kong",
        "authorids": "~Lin_Zheng1;~Jianbo_Yuan1;~Lei_Yu4;~Lingpeng_Kong1",
        "aff": "Department of Computer Science, The University of Hong Kong;Bytedance;The University of Hong Kong;DeepMind",
        "aff_domain": "cs.hku.hk;bytedance.com;deepmind.com;hku.hk",
        "position": "Researcher;Research Scientist;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PKfAq8N4fK",
        "title": "AgentKit: Structured LLM Reasoning with Dynamic Graphs",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM Agents",
        "primary_area": "",
        "author": "Yue Wu;Yewen Fan;So Yeon Min;Shrimai Prabhumoye;Stephen Marcus McAleer;Ruslan Salakhutdinov;Yonatan Bisk;Yuanzhi Li;Tom Mitchell",
        "authorids": "~Yue_Wu17;~Yewen_Fan1;~So_Yeon_Min2;~Shrimai_Prabhumoye1;~Stephen_Marcus_McAleer1;~Ruslan_Salakhutdinov1;~Yonatan_Bisk1;~Yuanzhi_Li1;~Tom_Mitchell2",
        "aff": "CMU, Carnegie Mellon University;Research, Microsoft;Carnegie Mellon University;NVIDIA;School of Computer Science, Carnegie Mellon University",
        "aff_domain": "andrew.cmu.edu;cmu.edu;nvidia.com;cs.cmu.edu;research.microsoft.com",
        "position": "Researcher;PhD student;Postdoc;Full Professor;PhD student;Assistant Professor;Assistant Professor;Intern;Full Professor",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PPTrmvEnpW",
        "title": "Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "GPT;large language model;interpretability;world model",
        "primary_area": "",
        "author": "Adam Karvonen",
        "authorids": "~Adam_Karvonen1",
        "aff": "Southern New Hampshire University",
        "aff_domain": "snhu.edu",
        "position": "Undergrad student",
        "rating": "",
        "confidence": "4;5;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Pvn1dKreZW",
        "title": "\"Merge Conflicts!'\" Exploring the Impacts of External Knowledge Distractors to Parametric Knowledge Graphs",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model;Knowledge Conflict",
        "primary_area": "",
        "author": "Cheng Qian;Xinran Zhao;Tongshuang Wu",
        "authorids": "~Cheng_Qian4;~Xinran_Zhao1;~Tongshuang_Wu1",
        "aff": "Stanford University;School of Computer Science, Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;stanford.edu",
        "position": "Assistant Professor;MS student",
        "rating": "",
        "confidence": "5;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QJvfpWSpWm",
        "title": "The Larger the Better? Improved LLM Code-Generation via Budget Reallocation",
        "track": "main",
        "status": "Accept",
        "keywords": "code-generation;budget constraint;model size",
        "primary_area": "",
        "author": "Michael Hassid;Tal Remez;Jonas Gehring;Roy Schwartz;Yossi Adi",
        "authorids": "~Michael_Hassid1;~Tal_Remez2;~Jonas_Gehring1;~Roy_Schwartz1;~Yossi_Adi1",
        "aff": "Hebrew University, Hebrew University of Jerusalem;Meta;Hebrew University of Jerusalem;Facebook",
        "aff_domain": "cs.huji.ac.il;meta.com;fb.com;huji.ac.il",
        "position": "Software Engineer;PhD student;Assistant Professor;Researcher;Research Scientist",
        "rating": "",
        "confidence": "2;3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QbCHlIqbDJ",
        "title": "From Narratives to Numbers: Valid Inference Using Language Model Predictions from Verbal Autopsies",
        "track": "main",
        "status": "Accept",
        "keywords": "multiclass;inference;transportability;public health;verbal autopsy",
        "primary_area": "",
        "author": "Shuxian Fan;Adam Visokay;Kentaro Hoffman;Stephen Salerno;Li Liu;Jeffrey T. Leek;Tyler McCormick",
        "authorids": "~Shuxian_Fan1;~Adam_Visokay1;~Kentaro_Hoffman1;~Stephen_Salerno1;~Li_Liu18;~Jeffrey_T._Leek1;~Tyler_McCormick1",
        "aff": "University of Washington;Fred Hutchinson Cancer Research Center;University of Michigan - Ann Arbor;Johns Hopkins University",
        "aff_domain": "fredhutch.org;jh.edu;u.washington.edu;washington.edu;uw.edu;umich.edu",
        "position": "PhD student;Full Professor;Postdoc;Associate Professor;PhD student;PhD student;Associate Professor",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QdWhj0QZFw",
        "title": "LLM360: Towards Fully Transparent Open-Source LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "open-source LLMs;LLM360;open data;fully open LLMs;open source",
        "primary_area": "",
        "author": "Zhengzhong Liu;Aurick Qiao;Willie Neiswanger;Hongyi Wang;Bowen Tan;Tianhua Tao;Junbo Li;Yuqi Wang;Suqi Sun;Omkar Pangarkar;Richard Fan;Yi Gu;Victor Miller;Yonghao Zhuang;Guowei He;Haonan Li;Fajri Koto;Liping Tang;Nikhil Ranjan;Zhiqiang Shen;Roberto Iriondo;Cun Mu;Zhiting Hu;Mark Schulze;Preslav Nakov;Timothy Baldwin;Eric P. Xing",
        "authorids": "~Zhengzhong_Liu1;~Aurick_Qiao1;~Willie_Neiswanger2;~Hongyi_Wang1;~Bowen_Tan2;~Tianhua_Tao1;~Junbo_Li3;~Yuqi_Wang8;~Suqi_Sun1;~Omkar_Pangarkar1;~Richard_Fan1;~Yi_Gu4;~Victor_Miller1;~Yonghao_Zhuang1;~Guowei_He1;~Haonan_Li2;~Fajri_Koto1;~Liping_Tang2;~Nikhil_Ranjan2;~Zhiqiang_Shen1;~Roberto_Iriondo1;~Cun_Mu1;~Zhiting_Hu3;~Mark_Schulze2;~Preslav_Nakov2;~Timothy_Baldwin1;~Eric_Xing1",
        "aff": "Petuum Inc.;CMU, Carnegie Mellon University;Northeastern University;Stanford University;Amazon;Mohamed bin Zayed University of Artificial Intelligence;Petuum Inc;University of California, Santa Cruz;School of Computer Science, Carnegie Mellon University;The University of Melbourne;Petuum;Carnegie Mellon University;University of Illinois at Urbana-Champaign",
        "aff_domain": "andrew.cmu.edu;illinois.edu;amazon.com;cmu.edu;unimelb.edu.au;petuum.com;neu.edu;cs.cmu.edu;ucsc.edu;mbzuai.ac.ae;stanford.edu",
        "position": "Researcher;PhD student;MS student;Full Professor;Postdoc;Postdoc;Researcher;MS student;NLP Engineer;Researcher;Software Engineer;Full Professor;Software Engineer;Advisor;Engineer;MS student;Full Professor;Postdoc;Researcher;PhD student;software engineer;Researcher;Researcher",
        "rating": "",
        "confidence": "3;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Qmq4zqdnWh",
        "title": "Using Natural Language Explanations to Rescale Human Judgments",
        "track": "main",
        "status": "Accept",
        "keywords": "human evaluation;natural language explanation;likert ratings;question answering;LLM",
        "primary_area": "",
        "author": "Manya Wadhwa;Jifan Chen;Junyi Jessy Li;Greg Durrett",
        "authorids": "~Manya_Wadhwa1;~Jifan_Chen1;~Junyi_Jessy_Li2;~Greg_Durrett1",
        "aff": "University of Texas, Austin;University of Texas at Austin",
        "aff_domain": "utexas.edu",
        "position": "Assistant Professor;PhD student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "5;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RCdoMrg4I0",
        "title": "Chinese Tiny LLM: Pretraining a Chinese-Centered Large Language Model",
        "track": "main",
        "status": "Accept",
        "keywords": "Chinese LLM;pretrain;alignment",
        "primary_area": "",
        "author": "Xeron Du;Zhouliang Yu;Songyang Gao;Ding Pan;Cheng Yuyang;Ziyang Ma;Ruibin Yuan;Xingwei Qu;Jiaheng Liu;Tianyu Zheng;Xinchen Luo;Guorui Zhou;Wenhu Chen;Ge Zhang",
        "authorids": "~Xeron_Du1;~Zhouliang_Yu1;~Songyang_Gao1;~Ding_Pan1;~Cheng_Yuyang1;~Ziyang_Ma3;~Ruibin_Yuan1;~Xingwei_Qu1;~Jiaheng_Liu1;~Tianyu_Zheng1;~Xinchen_Luo1;~Guorui_Zhou1;~Wenhu_Chen3;~Ge_Zhang5",
        "aff": "Beijing Academy of Artificial Intelligence;The Chinese University of Hongkong, Shenzhen;Hong Kong University of Science and Technology;Fudan University;Shanghai Jiaotong University;Google;Peking University;Kuaishou- \u5feb\u624b\u79d1\u6280;Beihang University",
        "aff_domain": "baai.ac.cn;cuhk.edu.cn;ust.hk;google.com;pku.edu.cn;stu.pku.edu.cn;kuaishou.com;buaa.edu.cn;sjtu.edu.cn;fudan.edu.cn",
        "position": "MS student;MS student;Intern;PhD student;MS student;Researcher;Researcher;Undergrad student;PhD student;Researcher",
        "rating": "",
        "confidence": "5;5;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RLFca3arx7",
        "title": "CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias",
        "track": "main",
        "status": "Accept",
        "keywords": "bias;fairness;language models;evaluation",
        "primary_area": "",
        "author": "Vipul Gupta;Pranav Narayanan Venkit;Hugo Lauren\u00e7on;Shomir Wilson;Rebecca J. Passonneau",
        "authorids": "~Vipul_Gupta3;~Pranav_Narayanan_Venkit1;~Hugo_Lauren\u00e7on1;~Shomir_Wilson1;~Rebecca_J._Passonneau1",
        "aff": "Pennsylvania State University",
        "aff_domain": "psu.edu",
        "position": "PhD student;Full Professor;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rx3wC8sCTJ",
        "title": "LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM evaluation;behavioral economics;inequity aversion;risk aversion;loss aversion;time discounting;utility theory",
        "primary_area": "",
        "author": "Jillian Ross;Yoon Kim;Andrew Lo",
        "authorids": "~Jillian_Ross1;~Yoon_Kim1;~Andrew_Lo1",
        "aff": "Massachusetts Institute of Technology",
        "aff_domain": "mit.edu",
        "position": "Charles E. and Susan T. Harris Professor;Assistant Professor",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "S1XnUsqwr7",
        "title": "Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning",
        "track": "main",
        "status": "Accept",
        "keywords": "Deductive Reasoning;Large Language Models;Decoding Algorithm",
        "primary_area": "",
        "author": "Tinghui Zhu;Kai Zhang;Jian Xie;Yu Su",
        "authorids": "~Tinghui_Zhu1;~Kai_Zhang10;~Jian_Xie3;~Yu_Su2",
        "aff": "Microsoft;Google DeepMind;Fudan University",
        "aff_domain": "microsoft.com;google.com;fudan.edu.cn",
        "position": "MS student;Student Researcher;MS student;Senior Researcher",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "S4ZOkV1AHl",
        "title": "Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas",
        "track": "main",
        "status": "Accept",
        "keywords": "Computation and Language;Large Language Models;Human Simulation;Political Psychology;Populist Framing Effects",
        "primary_area": "",
        "author": "Louis Kwok;Michal Bravansky;Lewis Griffin",
        "authorids": "~Louis_Kwok2;~Michal_Bravansky1;~Lewis_Griffin1",
        "aff": "Charles University Prague;University College London, University of London",
        "aff_domain": "ucl.ac.uk;cuni.cz",
        "position": "Full Professor;Researcher;Undergrad student",
        "rating": "",
        "confidence": "5;3;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "S7NVVfuRv8",
        "title": "How Easily do Irrelevant Inputs Skew the Responses of Large Language Models?",
        "track": "main",
        "status": "Accept",
        "keywords": "Retrieval Augmented Generation; Irrelevant Information; Misleading Information",
        "primary_area": "",
        "author": "Siye Wu;Jian Xie;Jiangjie Chen;Tinghui Zhu;Kai Zhang;Yanghua Xiao",
        "authorids": "~Siye_Wu1;~Jian_Xie3;~Jiangjie_Chen1;~Tinghui_Zhu1;~Kai_Zhang10;~Yanghua_Xiao1",
        "aff": "Google DeepMind;Wuhan University;ByteDance;Fudan University",
        "aff_domain": "google.com;bytedance.com;whu.edu.cn;fudan.edu.cn",
        "position": "MS student;Intern;Student Researcher;Undergrad student;MS student;Full Professor",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SGoVIC0u0f",
        "title": "Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping",
        "track": "main",
        "status": "Accept",
        "keywords": "Planning;Sequential Decision Making;Reasoning",
        "primary_area": "",
        "author": "Lucas Lehnert;Sainbayar Sukhbaatar;DiJia Su;Qinqing Zheng;Paul McVay;Michael Rabbat;Yuandong Tian",
        "authorids": "~Lucas_Lehnert1;~Sainbayar_Sukhbaatar1;~DiJia_Su1;~Qinqing_Zheng1;~Paul_McVay2;~Michael_Rabbat1;~Yuandong_Tian1",
        "aff": "Meta;Meta AI (FAIR);Meta AI;Facebook;Mila;Meta FAIR",
        "aff_domain": "meta.com;fb.com;mila.quebec",
        "position": "Postdoc;Associate Member;Researcher;Researcher;Research Scientist;Research Scientist",
        "rating": "",
        "confidence": "4;4;5;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SHMj84U5SH",
        "title": "Compression Represents Intelligence Linearly",
        "track": "main",
        "status": "Accept",
        "keywords": "compression;language models;linear correlation",
        "primary_area": "",
        "author": "Yuzhen Huang;Jinghan Zhang;Zifei Shan;Junxian He",
        "authorids": "~Yuzhen_Huang2;~Jinghan_Zhang1;~Zifei_Shan1;~Junxian_He1",
        "aff": "Shanghai Jiaotong University;WeChat, Tencent;Southeast University;Hong Kong University of Science and Technology",
        "aff_domain": "ust.hk;tencent.com;sjtu.edu.cn;seu.edu.cn",
        "position": "Undergrad student;Assistant Professor;Undergrad student;Senior Applied Scientist",
        "rating": "",
        "confidence": "4;4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SwUsFTtM9h",
        "title": "Iteratively Prompting Multimodal LLMs to Reproduce Natural and AI-Generated Images",
        "track": "main",
        "status": "Accept",
        "keywords": "Trustworthy ML;Text-to-Image models",
        "primary_area": "",
        "author": "Ali Naseh;Katherine Thai;Mohit Iyyer;Amir Houmansadr",
        "authorids": "~Ali_Naseh1;~Katherine_Thai1;~Mohit_Iyyer1;~Amir_Houmansadr1",
        "aff": "University of Massachusetts at Amherst;University of Massachusetts, Amherst;University of Massachusetts Amherst",
        "aff_domain": "cs.umass.edu;umass.edu",
        "position": "PhD student;Associate Professor;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Szp33itD10",
        "title": "StyleTalker: Finetuning Audio Language Model and Style-Based Text-to-Speech Model for Fast Spoken Dialogue Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "large language model;text-to-speech;spoken dialog;speech synthesis;multimodal LM",
        "primary_area": "",
        "author": "Yinghao Aaron Li;Xilin Jiang;Jordan Darefsky;Ge Zhu;Nima Mesgarani",
        "authorids": "~Yinghao_Aaron_Li1;~Xilin_Jiang1;~Jordan_Darefsky1;~Ge_Zhu1;~Nima_Mesgarani1",
        "aff": "Columbia University;University of Rochester",
        "aff_domain": "rochester.edu;ee.columbia.edu;columbia.edu",
        "position": "PhD student;Undergrad student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T5pGDydMkS",
        "title": "Adaptive Quantization Error Reconstruction for LLMs with Mixed Precision",
        "track": "main",
        "status": "Accept",
        "keywords": "Quantization;Large Language Models;Mixed Precision;Error Reconstruction;Low-Rank Decomposition",
        "primary_area": "",
        "author": "Lin Ou;Jinpeng Xia;Yuewei Zhang;Chuzhan Hao;Hao Henry Wang",
        "authorids": "~Lin_Ou1;~Jinpeng_Xia1;~Yuewei_Zhang1;~Chuzhan_Hao1;~Hao_Henry_Wang1",
        "aff": "Tianjin University;Alibaba Group",
        "aff_domain": "alibaba-inc.com;tju.edu.cn",
        "position": "MS student;Researcher;Researcher;Researcher",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T9cOYH0wGF",
        "title": "Optimising Calls to Large Language Models with Uncertainty-Based Two-Tier Selection",
        "track": "main",
        "status": "Accept",
        "keywords": "API calls optimisation;uncertainty;calibration;cascading",
        "primary_area": "",
        "author": "Guillem Ram\u00edrez;Alexandra Birch;Ivan Titov",
        "authorids": "~Guillem_Ram\u00edrez1;~Alexandra_Birch1;~Ivan_Titov1",
        "aff": "University of Edinburgh;University of Amsterdam",
        "aff_domain": "edinburgh.org;ed.ac.uk;uva.nl",
        "position": "Associate Professor;PhD student;Associate Professor",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TBNYjdOazs",
        "title": "Decoupling Noise and Toxic Parameters for Language Model Detoxification by Task Vector Merging",
        "track": "main",
        "status": "Accept",
        "keywords": "detoxification;task vector;weight merging;unlearning",
        "primary_area": "",
        "author": "Yongmin Kim;Takeshi Kojima;Yusuke Iwasawa;Yutaka Matsuo",
        "authorids": "~Yongmin_Kim2;~Takeshi_Kojima1;~Yusuke_Iwasawa1;~Yutaka_Matsuo1",
        "aff": "Tokyo University, Tokyo Institute of Technology;The University of Tokyo",
        "aff_domain": "weblab.t.u-tokyo.ac.jp;u-tokyo.ac.jp;t.u-tokyo.ac.jp",
        "position": "PhD student;MS student;Lecturer;Associate Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TQdd1VhWbe",
        "title": "Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities",
        "track": "main",
        "status": "Accept",
        "keywords": "Japanese;Continual Pre-Training;Llama 2;cross-lingual LLM adaptation;vocabulary expansion;parallel corpus",
        "primary_area": "",
        "author": "Kazuki Fujii;Taishi Nakamura;Mengsay Loem;Hiroki Iida;Masanari Ohi;Kakeru Hattori;Hirai Shota;Sakae Mizuki;Rio Yokota;Naoaki Okazaki",
        "authorids": "~Kazuki_Fujii1;~Taishi_Nakamura1;~Mengsay_Loem1;~Hiroki_Iida1;~Masanari_Ohi1;~Kakeru_Hattori1;~Hirai_Shota1;~Sakae_Mizuki1;~Rio_Yokota1;~Naoaki_Okazaki2",
        "aff": "Tokyo Institute of Technology;Tokyo Institute of Technology, Tokyo Institute of Technology",
        "aff_domain": "titech.ac.jp",
        "position": "MS student;PhD student;Undergrad student;Undergrad student;Undergrad student;MS student;Full Professor;Full Professor;PhD student;Undergrad student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TRxQMpLUfD",
        "title": "Stronger Random Baselines for In-Context Learning",
        "track": "main",
        "status": "Accept",
        "keywords": "random baselines;order statistics;in-context learning;evaluation",
        "primary_area": "",
        "author": "Gregory Yauney;David Mimno",
        "authorids": "~Gregory_Yauney1;~David_Mimno1",
        "aff": "Cornell University",
        "aff_domain": "cornell.edu",
        "position": "Associate Professor;PhD student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TZ0CCGDcuT",
        "title": "Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms",
        "track": "main",
        "status": "Accept",
        "keywords": "interpretability;mechanistic interpretability;circuits",
        "primary_area": "",
        "author": "Michael Hanna;Sandro Pezzelle;Yonatan Belinkov",
        "authorids": "~Michael_Hanna1;~Sandro_Pezzelle1;~Yonatan_Belinkov1",
        "aff": "Technion, Technion;University of Amsterdam",
        "aff_domain": "technion.ac.il;uva.nl",
        "position": "PhD student;Assistant Professor;Assistant Professor",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ti67584b98",
        "title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
        "track": "main",
        "status": "Accept",
        "keywords": "benchmark;evaluation;dataset;scalable oversight;alignment",
        "primary_area": "",
        "author": "David Rein;Betty Li Hou;Asa Cooper Stickland;Jackson Petty;Richard Yuanzhe Pang;Julien Dirani;Julian Michael;Samuel R. Bowman",
        "authorids": "~David_Rein1;~Betty_Li_Hou1;~Asa_Cooper_Stickland1;~Jackson_Petty1;~Richard_Yuanzhe_Pang1;~Julien_Dirani1;~Julian_Michael1;~Samuel_R._Bowman1",
        "aff": "University of Edinburgh;New York University",
        "aff_domain": "nyu.edu;ed.ac.uk",
        "position": "PhD student;PhD student;Researcher;PhD student;Postdoc;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TrloAXEJ2B",
        "title": "LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition",
        "track": "main",
        "status": "Accept",
        "keywords": "Parameter Efficient Tuning;Cross-Task Generalization;Model Merging",
        "primary_area": "",
        "author": "Chengsong Huang;Qian Liu;Bill Yuchen Lin;Tianyu Pang;Chao Du;Min Lin",
        "authorids": "~Chengsong_Huang1;~Qian_Liu2;~Bill_Yuchen_Lin1;~Tianyu_Pang1;~Chao_Du1;~Min_Lin1",
        "aff": "Allen Institute for Artificial Intelligence;Sea AI Lab",
        "aff_domain": "sea.com;allenai.org",
        "position": "Researcher;Research Scientist;Principal Researcher;Researcher;Research Scientist",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "U5BUzSn4tD",
        "title": "Auxiliary task demands mask the capabilities of smaller language models",
        "track": "main",
        "status": "Accept",
        "keywords": "cognitive evaluation;task demands;benchmarking;emergence;reasoning;syntax;development",
        "primary_area": "",
        "author": "Jennifer Hu;Michael Frank",
        "authorids": "~Jennifer_Hu1;~Michael_Frank1",
        "aff": "Stanford University;Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;stanford.edu",
        "position": "PhD student;Full Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UPE6WYE8vg",
        "title": "A Language Agent for Autonomous Driving",
        "track": "main",
        "status": "Accept",
        "keywords": "Language Agent;Autonomous Driving",
        "primary_area": "",
        "author": "Jiageng Mao;Junjie Ye;Yuxi Qian;Marco Pavone;Yue Wang",
        "authorids": "~Jiageng_Mao1;~Junjie_Ye3;~Yuxi_Qian2;~Marco_Pavone1;~Yue_Wang2",
        "aff": "Tongji University;Stanford University;NVIDIA;University of Southern California",
        "aff_domain": "usc.edu;tongji.edu.cn;nvidia.com;stanford.edu",
        "position": "MS student;Associate Professor;Researcher;Undergrad student",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UPyWLwciYz",
        "title": "Source-Aware Training Enables Knowledge Attribution in Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "attribution;pretraining;citation generation;factuality",
        "primary_area": "",
        "author": "Muhammad Khalifa;David Wadden;Emma Strubell;Honglak Lee;Lu Wang;Iz Beltagy;Hao Peng",
        "authorids": "~Muhammad_Khalifa2;~David_Wadden1;~Emma_Strubell1;~Honglak_Lee2;~Lu_Wang9;~Iz_Beltagy1;~Hao_Peng4",
        "aff": "University of Michigan;University of Michigan - Ann Arbor;Allen Institute for Artificial Intelligence;Carnegie Mellon University",
        "aff_domain": "cmu.edu;allenai.org;umich.edu",
        "position": "Researcher;Assistant Professor;Research Scientist;Associate Professor;PhD student;Researcher;Associate Professor",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UfWwBaLuXV",
        "title": "List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "multimodal LLMs;Synthetic Data;Learning Paradigm",
        "primary_area": "",
        "author": "An Yan;Zhengyuan Yang;Junda Wu;Wanrong Zhu;Jianwei Yang;Linjie Li;Kevin Lin;Jianfeng Wang;Julian McAuley;Jianfeng Gao;Lijuan Wang",
        "authorids": "~An_Yan1;~Zhengyuan_Yang1;~Junda_Wu1;~Wanrong_Zhu1;~Jianwei_Yang1;~Linjie_Li1;~Kevin_Lin3;~Jianfeng_Wang4;~Julian_McAuley1;~Jianfeng_Gao1;~Lijuan_Wang1",
        "aff": "Microsoft;New York University;University of California, San Diego, University of California, San Diego;University of California, San Diego;Microsoft Research",
        "aff_domain": "nyu.edu;eng.ucsd.edu;ucsd.edu;microsoft.com",
        "position": "PhD student;Principal Researcher;Principal Researcher;Full Professor;MS student;Researcher;Principal Researcher;Researcher;Researcher;Researcher",
        "rating": "",
        "confidence": "4;4;5;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UfqzXg95I5",
        "title": "AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Models;Jailbreak Attack;Adversarial Attack",
        "primary_area": "",
        "author": "Zeyi Liao;Huan Sun",
        "authorids": "~Zeyi_Liao1;~Huan_Sun1",
        "aff": "The Ohio State University, Columbus;Ohio State University, Columbus",
        "aff_domain": "osu.edu",
        "position": "Associate Professor;PhD student",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Uhwze2LEwq",
        "title": "MileBench: Benchmarking MLLMs in Long Context",
        "track": "main",
        "status": "Accept",
        "keywords": "multi-modality;benchmark of long-context model;benchmark of vision-language model",
        "primary_area": "",
        "author": "Song Dingjie;Shunian Chen;Guiming Hardy Chen;Fei Yu;Xiang Wan;Benyou Wang",
        "authorids": "~Song_Dingjie1;~Shunian_Chen1;~Guiming_Hardy_Chen1;~Fei_Yu3;~Xiang_Wan1;~Benyou_Wang2",
        "aff": "Nanjing University;Shenzhen Research Institute of Big Data;The Chinese University of Hong Kong, Shenzhen;Duke University",
        "aff_domain": "link.cuhk.edu.cn;duke.edu;nju.edu.cn;cuhk.edu.cn;sribd.cn",
        "position": "Assistant Professor;PhD student;MS student;MS student;Principal Researcher",
        "rating": "",
        "confidence": "3;4;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ukf4301hXm",
        "title": "Unforgettable Generalization in Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "unlearning;forgetting;generalization",
        "primary_area": "",
        "author": "Eric Zhang;Leshem Choshen;Jacob Andreas",
        "authorids": "~Eric_Zhang2;~Leshem_Choshen1;~Jacob_Andreas1",
        "aff": "Microsoft;International Business Machines;Massachusetts Institute of Technology",
        "aff_domain": "ibm.com;mit.edu;microsoft.com",
        "position": "MS student;Researcher;Researcher",
        "rating": "",
        "confidence": "2;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UyNIH6CWHH",
        "title": "Efficient Parallelization Layouts for Large-Scale Distributed Model Training",
        "track": "main",
        "status": "Accept",
        "keywords": "model training efficiency;large models;parallelization;distributed",
        "primary_area": "",
        "author": "Johannes Hagemann;Samuel Weinbach;Konstantin Dobler;Maximilian Schall;Gerard de Melo",
        "authorids": "~Johannes_Hagemann1;~Samuel_Weinbach1;~Konstantin_Dobler1;~Maximilian_Schall1;~Gerard_de_Melo3",
        "aff": "Aleph Alpha GmbH;University of Potsdam;Hasso Plattner Institute",
        "aff_domain": "uni-potsdam.de;aleph-alpha.com;hpi.de",
        "position": "MS student;PhD student;PhD student;Researcher;Full Professor",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "V7HRrxXUhN",
        "title": "An In-Context Learning Agent for Formal Theorem-Proving",
        "track": "main",
        "status": "Accept",
        "keywords": "theorem proving;formal methods;large language models;agents",
        "primary_area": "",
        "author": "Amitayush Thakur;George Tsoukalas;Yeming Wen;Jimmy Xin;Swarat Chaudhuri",
        "authorids": "~Amitayush_Thakur1;~George_Tsoukalas1;~Yeming_Wen1;~Jimmy_Xin1;~Swarat_Chaudhuri1",
        "aff": "University of Texas, Austin;University of Texas at Austin;Rutgers University",
        "aff_domain": "rutgers.edu;utexas.edu",
        "position": "PhD student;Undergrad student;Undergrad student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VHhwhmtx3b",
        "title": "Does RoBERTa Perform Better than BERT in Continual Learning: An Attention Sink Perspective",
        "track": "main",
        "status": "Accept",
        "keywords": "Continual Learning;Attention Sink;Interference;Over-Smoothing;Pre-Scaling",
        "primary_area": "",
        "author": "Xueying Bai;Yifan Sun;Niranjan Balasubramanian",
        "authorids": "~Xueying_Bai1;~Yifan_Sun1;~Niranjan_Balasubramanian2",
        "aff": "State University of New York, Stony Brook",
        "aff_domain": "stonybrook.edu",
        "position": "Assistant Professor;Assistant Professor",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VWWzO3ewMS",
        "title": "Crowd-Calibrator: Can Annotator Disagreement Inform Calibration in Subjective Tasks?",
        "track": "main",
        "status": "Accept",
        "keywords": "calibration;human subjectivity;disagreement;hate speech detection",
        "primary_area": "",
        "author": "Urja Khurana;Eric Nalisnick;Antske Fokkens;Swabha Swayamdipta",
        "authorids": "~Urja_Khurana1;~Eric_Nalisnick1;~Antske_Fokkens1;~Swabha_Swayamdipta1",
        "aff": "University of Amsterdam;Vrije Universiteit Amsterdam;University of Southern California;VU University Amsterdam",
        "aff_domain": "usc.edu;vu.nl;uva.nl",
        "position": "Full Professor;Assistant Professor;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "5;3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Vd0KvChLXr",
        "title": "Generating Synthetic Datasets for Few-shot Prompt Tuning",
        "track": "main",
        "status": "Accept",
        "keywords": "Prompt Tuning;Few-shot Learning;Synthetic Data Generation",
        "primary_area": "",
        "author": "Xu Guo;Zilin Du;Boyang Li;Chunyan Miao",
        "authorids": "~Xu_Guo2;~Zilin_Du1;~Boyang_Li1;~Chunyan_Miao1",
        "aff": "Nanyang Technological University;School of Computer Science and  Engineering, Nanyang Technological University",
        "aff_domain": "ntu.edu.sg;scse.ntu.edu.sg",
        "position": "Associate Professor;Full Professor;PhD student",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "W8Rv1jVycX",
        "title": "Description-Based Text Similarity",
        "track": "main",
        "status": "Accept",
        "keywords": "semantics;similarity;description based similarity;retrieval",
        "primary_area": "",
        "author": "Shauli Ravfogel;Valentina Pyatkin;Amir David Nissan Cohen;Avshalom Manevich;Yoav Goldberg",
        "authorids": "~Shauli_Ravfogel1;~Valentina_Pyatkin1;~Amir_David_Nissan_Cohen1;~Avshalom_Manevich1;~Yoav_Goldberg1",
        "aff": "Bar Ilan University;Bar-Ilan University",
        "aff_domain": "biu.ac.il",
        "position": "PhD student;MS student;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X1xNsuKssb",
        "title": "MambaByte: Token-free Selective State Space Model",
        "track": "main",
        "status": "Accept",
        "keywords": "byte-level language model;state space model",
        "primary_area": "",
        "author": "Junxiong Wang;Tushaar Gangavarapu;Jing Nathan Yan;Alexander M Rush",
        "authorids": "~Junxiong_Wang1;~Tushaar_Gangavarapu1;~Jing_Nathan_Yan1;~Alexander_M_Rush1",
        "aff": "Cornell University;School of Engineering and Applied Sciences, Harvard University",
        "aff_domain": "cs.cornell.edu;seas.harvard.edu;cornell.edu",
        "position": "Assistant Professor;PhD student;MS student",
        "rating": "",
        "confidence": "3;2;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X9yV4lFHt4",
        "title": "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "Social biases;Stereotypes;Benchmark;Multilingual;Generative LLMs",
        "primary_area": "",
        "author": "Vera Neplenbroek;Arianna Bisazza;Raquel Fern\u00e1ndez",
        "authorids": "~Vera_Neplenbroek1;~Arianna_Bisazza1;~Raquel_Fern\u00e1ndez1",
        "aff": "University of Groningen;University of Amsterdam",
        "aff_domain": "rug.nl;uva.nl",
        "position": "Assistant Professor;Associate Professor;MS student",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XGJBEeziEb",
        "title": "Data Checklist: On Unit-Testing Datasets with Usable Information",
        "track": "main",
        "status": "Accept",
        "keywords": "data checklist;usable information;dataset artifact;preference alignment",
        "primary_area": "",
        "author": "Heidi Chenyu Zhang;Shabnam Behzad;Kawin Ethayarajh;Dan Jurafsky",
        "authorids": "~Heidi_Chenyu_Zhang1;~Shabnam_Behzad1;~Kawin_Ethayarajh1;~Dan_Jurafsky1",
        "aff": "Stanford University",
        "aff_domain": "stanford.edu",
        "position": "Full Professor;PhD student;MS student",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XII0Wp1XA9",
        "title": "A Dynamic LLM-Powered Agent Network for Task-Oriented Agent Collaboration",
        "track": "main",
        "status": "Accept",
        "keywords": "large language model;LLM-powered agent;multi-agent collaboration;team optimization",
        "primary_area": "",
        "author": "Zijun Liu;Yanzhe Zhang;Peng Li;Yang Liu;Diyi Yang",
        "authorids": "~Zijun_Liu2;~Yanzhe_Zhang1;~Peng_Li2;~Yang_Liu19;~Diyi_Yang2",
        "aff": "Stanford University;Georgia Institute of Technology;Computer Science Department, Stanford University;Tsinghua University",
        "aff_domain": "gatech.edu;tsinghua.edu.cn;cs.stanford.edu;stanford.edu",
        "position": "Assistant Professor;Associate Professor;Professor;PhD student;Intern",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Xh1B90iBSR",
        "title": "What Are Tools Anyway? A Survey from the Language Model Perspective",
        "track": "main",
        "status": "Accept",
        "keywords": "tool;agent;program",
        "primary_area": "",
        "author": "Zhiruo Wang;Zhoujun Cheng;Hao Zhu;Daniel Fried;Graham Neubig",
        "authorids": "~Zhiruo_Wang1;~Zhoujun_Cheng1;~Hao_Zhu1;~Daniel_Fried1;~Graham_Neubig1",
        "aff": "Carnegie Mellon University;Shanghai Jiao Tong University",
        "aff_domain": "cmu.edu;sjtu.edu.cn",
        "position": "Assistant Professor;Associate Professor;PhD student;MS student;MS student",
        "rating": "",
        "confidence": "4;2;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YDZ7GeFLxq",
        "title": "Scattered Mixture-of-Experts Implementation",
        "track": "main",
        "status": "Accept",
        "keywords": "triton;gpu;moe;mixture of experts;sparse mixture of experts",
        "primary_area": "",
        "author": "Shawn Tan;Yikang Shen;Rameswar Panda;Aaron Courville",
        "authorids": "~Shawn_Tan1;~Yikang_Shen1;~Rameswar_Panda1;~Aaron_Courville3",
        "aff": "MIT-IBM Watson AI Lab;University of Montreal;Universit\u00e9 de Montr\u00e9al",
        "aff_domain": "umontreal.ca; ;ibm.com",
        "position": "Assistant Professor;Research Scientist;PhD student;PhD student",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YX7QnhxESU",
        "title": "Mapping the Increasing Use of LLMs in Scientific Papers",
        "track": "main",
        "status": "Accept",
        "keywords": "Academic Writing;Computational Social Science;Science and Technology Studies;Societal Impact and LLM Adoption",
        "primary_area": "",
        "author": "Weixin Liang;Yaohui Zhang;Zhengxuan Wu;Haley Lepp;Wenlong Ji;Xuandong Zhao;Hancheng Cao;Sheng Liu;Siyu He;Zhi Huang;Diyi Yang;Christopher Potts;Christopher D Manning;James Y. Zou",
        "authorids": "~Weixin_Liang1;~Yaohui_Zhang2;~Zhengxuan_Wu1;~Haley_Lepp1;~Wenlong_Ji1;~Xuandong_Zhao1;~Hancheng_Cao1;~Sheng_Liu2;~Siyu_He3;~Zhi_Huang2;~Diyi_Yang2;~Christopher_Potts1;~Christopher_D_Manning1;~James_Y._Zou1",
        "aff": "Stanford University;Computer Science Department, Stanford University;New York University;Columbia University;UC Santa Barbara;Zhejiang University",
        "aff_domain": "nyu.edu;columbia.edu;cs.stanford.edu;zju.edu.cn;ucsb.edu;stanford.edu",
        "position": "Full Professor;Full Professor;Assistant Professor;PhD student;PhD student;PhD student;PhD student;PhD student;PhD student;Undergrad student;PhD student;Postdoc",
        "rating": "",
        "confidence": "4;3;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YfHxQSoaWU",
        "title": "FABLES: Evaluating faithfulness and content selection in book-length summarization",
        "track": "main",
        "status": "Accept",
        "keywords": "Faithfulness;Content Selection;Book-length Summarization;Human Evaluation",
        "primary_area": "",
        "author": "Yekyung Kim;Yapei Chang;Marzena Karpinska;Aparna Garimella;Varun Manjunatha;Kyle Lo;Tanya Goyal;Mohit Iyyer",
        "authorids": "~Yekyung_Kim1;~Yapei_Chang1;~Marzena_Karpinska1;~Aparna_Garimella1;~Varun_Manjunatha1;~Kyle_Lo1;~Tanya_Goyal1;~Mohit_Iyyer1",
        "aff": "University of Texas, Austin;Adobe Research;Hyundai Motors ;University of Massachusetts Amherst;University of Massachusetts at Amherst;Allen Institute for Artificial Intelligence;Adobe Systems",
        "aff_domain": "allenai.org;utexas.edu;hyundai.com;cs.umass.edu;adobe.com;umass.edu",
        "position": "Researcher;Researcher;Assistant Professor;PhD student;Research Scientist;PhD student;Researcher",
        "rating": "",
        "confidence": "3;4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.8,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YwrNePfb3E",
        "title": "Prompt Exploration with Prompt Regression",
        "track": "main",
        "status": "Accept",
        "keywords": "prompt engineering;prompt selection;large language models;regression",
        "primary_area": "",
        "author": "Michael Feffer;Ronald Xu;Yuekai Sun;Mikhail Yurochkin",
        "authorids": "~Michael_Feffer1;~Ronald_Xu1;~Yuekai_Sun1;~Mikhail_Yurochkin1",
        "aff": "University of Michigan;CMU, Carnegie Mellon University;International Business Machines;Massachusetts Institute of Technology",
        "aff_domain": "andrew.cmu.edu;ibm.com;mit.edu;umich.edu",
        "position": "PhD student;Research Staff Member;Undergrad student;Assistant Professor",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZDdLamBX4P",
        "title": "Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates",
        "track": "main",
        "status": "Accept",
        "keywords": "instruction-tuning;programmatic data;large language models;LLMs",
        "primary_area": "",
        "author": "Avanika Narayan;Mayee F Chen;Kush Bhatia;Christopher Re",
        "authorids": "~Avanika_Narayan1;~Mayee_F_Chen1;~Kush_Bhatia3;~Christopher_Re1",
        "aff": "Stanford University",
        "aff_domain": "stanford.edu",
        "position": "Postdoc;PhD student",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZZzXpyv65G",
        "title": "Language Models as Critical Thinking Tools: A Case Study of Philosophers",
        "track": "main",
        "status": "Accept",
        "keywords": "philosophy;critical thinking;human-computer interaction",
        "primary_area": "",
        "author": "Andre Ye;Jared Moore;Rose Novick;Amy X Zhang",
        "authorids": "~Andre_Ye1;~Jared_Moore1;~Rose_Novick1;~Amy_X_Zhang1",
        "aff": "University of Washington;Department of Computer Science",
        "aff_domain": "uw.edu;cs.washington.edu",
        "position": "Assistant Professor;Undergrad student;Assistant Professor",
        "rating": "",
        "confidence": "3;5;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zb0ajZ7vAt",
        "title": "Large Language Model Routing with Benchmark Datasets",
        "track": "main",
        "status": "Accept",
        "keywords": "Model selection;LLM routing;OOD Generalization",
        "primary_area": "",
        "author": "Tal Shnitzer;Anthony Ou;M\u00edrian Silva;Kate Soule;Yuekai Sun;Justin Solomon;Neil Thompson;Mikhail Yurochkin",
        "authorids": "~Tal_Shnitzer1;~Anthony_Ou1;~M\u00edrian_Silva1;~Kate_Soule1;~Yuekai_Sun1;~Justin_Solomon1;~Neil_Thompson1;~Mikhail_Yurochkin1",
        "aff": "University of Michigan;Computer Science and Artificial Intelligence Laboratory, Electrical Engineering & Computer Science;International Business Machines;IBM Research;Massachusetts Institute of Technology",
        "aff_domain": "csail.mit.edu;mit.edu;us.ibm.com;ibm.com;umich.edu",
        "position": "Undergrad student;Associate Professor;Researcher;Research Staff Member;Researcher;Principal Researcher;Postdoc;Assistant Professor",
        "rating": "",
        "confidence": "5;3;2;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zq9Dfj4nBo",
        "title": "Redesigning Information Markets in the Era of Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Language Model Agents;Information Economics",
        "primary_area": "",
        "author": "Martin Weiss;Nasim Rahaman;Manuel Wuthrich;Yoshua Bengio;Li Erran Li;Bernhard Sch\u00f6lkopf;Christopher Pal",
        "authorids": "~Martin_Weiss4;~Nasim_Rahaman1;~Manuel_Wuthrich1;~Yoshua_Bengio1;~Li_Erran_Li1;~Bernhard_Sch\u00f6lkopf1;~Christopher_Pal1",
        "aff": "Polytechnique Montreal;Max Planck Institute for Intelligent Systems;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Columbia University;University of Montreal;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal",
        "aff_domain": "mpg.tuebingen.de;polymtl.ca;umontreal.ca;mila.umontreal.ca;tuebingen.mpg.de;columbia.edu",
        "position": "Full Professor;Adjunct Professor;Postdoc;PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "2;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zt1dwG8xrK",
        "title": "Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability",
        "track": "main",
        "status": "Accept",
        "keywords": "Language models;Knowledge graph;Hallucination;Scaling",
        "primary_area": "",
        "author": "Jiri Hron;Laura A Culp;Gamaleldin Fathy Elsayed;Rosanne Liu;Jasper Snoek;Simon Kornblith;Alex Rizkowsky;Isabelle Simpson;Jascha Sohl-Dickstein;Noah Fiedel;Aaron T Parisi;Alexander A Alemi;Azade Nova;Ben Adlam;Bernd Bohnet;Gaurav Mishra;Hanie Sedghi;Izzeddin Gur;Jaehoon Lee;John D Co-Reyes;Kathleen Kenealy;Kelvin Xu;Kevin Swersky;Igor Mordatch;Lechao Xiao;Maxwell Bileschi;Peter J Liu;Roman Novak;Sharad Vikram;Tris Warkentin;Jeffrey Pennington",
        "authorids": "~Jiri_Hron1;~Laura_A_Culp1;~Gamaleldin_Fathy_Elsayed1;~Rosanne_Liu1;~Jasper_Snoek1;~Simon_Kornblith1;~Alex_Rizkowsky1;~Isabelle_Simpson1;~Jascha_Sohl-Dickstein2;~Noah_Fiedel1;~Aaron_T_Parisi1;~Alexander_A_Alemi1;~Azade_Nova1;~Ben_Adlam1;~Bernd_Bohnet1;~Gaurav_Mishra1;~Hanie_Sedghi1;~Izzeddin_Gur1;~Jaehoon_Lee2;~John_D_Co-Reyes1;~Kathleen_Kenealy1;~Kelvin_Xu2;~Kevin_Swersky1;~Igor_Mordatch4;~Lechao_Xiao2;~Maxwell_Bileschi1;~Peter_J_Liu1;~Roman_Novak2;~Sharad_Vikram1;~Tris_Warkentin1;~Jeffrey_Pennington1",
        "aff": "ML Collective;Google Research, Brain team;University of California Berkeley;Google DeepMind;Google;Google Research, Brain Team;Google Brain;OpenAI",
        "aff_domain": "openai.com;berkeley.edu;mlcollective.org;google.com",
        "position": "Research Scientist;Research Scientist;Researcher;Research Scientist;Senior Research Scientist;Research Scientist;Research Scientist;Research Scientist;Research Scientist;Researcher;Researcher;PhD student;Research Scientist;Software Engineer;Research Scientist;Researcher;Director, Research & Engineering;Research Scientist;Research Scientist;Researcher;Google;Research Scientist;PM;Research Scientist;Research Scientist",
        "rating": "",
        "confidence": "4;4;4;2",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zu8OWNUC0u",
        "title": "Nonparametric Variational Regularisation of Pretrained Transformers",
        "track": "main",
        "status": "Accept",
        "keywords": "Transformers;Nonparametric VIB;Reinterpretation;Post-training regularisation;Out-of-domain generalisation",
        "primary_area": "",
        "author": "Fabio James Fehr;James Henderson",
        "authorids": "~Fabio_James_Fehr1;~James_Henderson1",
        "aff": "Idiap Research Institute",
        "aff_domain": "idiap.ch",
        "position": "PhD student;Senior Researcher",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aKkAwZB6JV",
        "title": "Zephyr: Direct Distillation of LM Alignment",
        "track": "main",
        "status": "Accept",
        "keywords": "AI feedback;open LLMs;RLHF",
        "primary_area": "",
        "author": "Lewis Tunstall;Edward Emanuel Beeching;Nathan Lambert;Nazneen Rajani;Kashif Rasul;Younes Belkada;Shengyi Huang;Leandro Von Werra;Cl\u00e9mentine Fourrier;Nathan Habib;Nathan Sarrazin;Omar Sanseviero;Alexander M Rush;Thomas Wolf",
        "authorids": "~Lewis_Tunstall1;~Edward_Emanuel_Beeching2;~Nathan_Lambert1;~Nazneen_Rajani1;~Kashif_Rasul1;~Younes_Belkada1;~Shengyi_Huang1;~Leandro_Von_Werra1;~Cl\u00e9mentine_Fourrier1;~Nathan_Habib1;~Nathan_Sarrazin1;~Omar_Sanseviero1;~Alexander_M_Rush1;~Thomas_Wolf1",
        "aff": "HuggingFace;Collinear AI;Delft University of Technology;Hugging Face;Drexel University;Zalando SE;School of Engineering and Applied Sciences, Harvard University",
        "aff_domain": "drexel.edu;zalando.de;seas.harvard.edu;collinear.ai;student.tudelft.nl;huggingface.co",
        "position": "Assistant Professor;Researcher;Researcher;Researcher;Undergrad student;Researcher;PhD student;Researcher;Principal Researcher",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aKwQPRjdGa",
        "title": "Hummer: Towards Limited Competitive Preference Dataset",
        "track": "main",
        "status": "Accept",
        "keywords": "reinforcement learning from human feedback;RLHF;preference dataset;reward models;alignment",
        "primary_area": "",
        "author": "Yusen Wu;Li Jiang;Junwu Xiong;Jingqing Ruan;Yichuan Ding;Qingpei Guo;zujie wen;JUN ZHOU;Xiaotie Deng",
        "authorids": "~Yusen_Wu2;~Li_Jiang4;~Junwu_Xiong1;~Jingqing_Ruan1;~Yichuan_Ding1;~Qingpei_Guo1;~zujie_wen1;~JUN_ZHOU6;~Xiaotie_Deng1",
        "aff": "antgroup;Tsinghua University;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;McGill University;Peking University;Ant Group",
        "aff_domain": "tsinghua.edu.cn;mcgill.ca;pku.edu.cn;ia.ac.cn;antgroup.com",
        "position": "Researcher;PhD student;Researcher;MS student;Researcher;Full Professor;Associate Professor;Undergrad student",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aajyHYjjsk",
        "title": "The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets",
        "track": "main",
        "status": "Accept",
        "keywords": "Interpretability;world models;knowledge representations;causal mediation analysis",
        "primary_area": "",
        "author": "Samuel Marks;Max Tegmark",
        "authorids": "~Samuel_Marks1;~Max_Tegmark1",
        "aff": "Harvard University;Massachusetts Institute of Technology",
        "aff_domain": "g.harvard.edu;mit.edu",
        "position": "Full Professor;PhD student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "amhPBLFYWv",
        "title": "Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics",
        "track": "main",
        "status": "Accept",
        "keywords": "human language comprehension;human language processing;ERP;reading time;Mamba;transformer;psycholinguistics",
        "primary_area": "",
        "author": "James Michaelov;Catherine Arnett;Ben Bergen",
        "authorids": "~James_Michaelov1;~Catherine_Arnett1;~Ben_Bergen1",
        "aff": "University of California, San Diego",
        "aff_domain": "ucsd.edu",
        "position": "PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "av0D19pSkU",
        "title": "Do Membership Inference Attacks Work on Large Language Models?",
        "track": "main",
        "status": "Accept",
        "keywords": "privacy;membership inference",
        "primary_area": "",
        "author": "Michael Duan;Anshuman Suri;Niloofar Mireshghallah;Sewon Min;Weijia Shi;Luke Zettlemoyer;Yulia Tsvetkov;Yejin Choi;David Evans;Hannaneh Hajishirzi",
        "authorids": "~Michael_Duan1;~Anshuman_Suri1;~Niloofar_Mireshghallah1;~Sewon_Min1;~Weijia_Shi1;~Luke_Zettlemoyer1;~Yulia_Tsvetkov1;~Yejin_Choi1;~David_Evans1;~Hannaneh_Hajishirzi1",
        "aff": "Meta;University of Washington, Seattle;Facebook;University of Washington;Department of Computer Science, University of Washington;University of California, San Diego;University of Virginia",
        "aff_domain": "ucsd.edu;meta.com;cs.washington.edu;uw.edu;fb.com;virginia.edu",
        "position": "PhD student;Professor;Assistant Professor;Researcher;Undergrad student;PhD student;PhD student;Professor;Assistant Professor;PhD student",
        "rating": "",
        "confidence": "3;5;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "b0y6fbSUG0",
        "title": "LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Reasoning",
        "primary_area": "",
        "author": "Shibo Hao;Yi Gu;Haotian Luo;Tianyang Liu;Xiyan Shao;Xinyuan Wang;Shuhua Xie;Haodi Ma;Adithya Samavedhi;Qiyue Gao;Zhen Wang;Zhiting Hu",
        "authorids": "~Shibo_Hao1;~Yi_Gu4;~Haotian_Luo2;~Tianyang_Liu2;~Xiyan_Shao1;~Xinyuan_Wang3;~Shuhua_Xie1;~Haodi_Ma1;~Adithya_Samavedhi2;~Qiyue_Gao1;~Zhen_Wang6;~Zhiting_Hu3",
        "aff": "Shanghai Jiaotong University;Amazon;Mohamed bin Zayed University of Artificial Intelligence;University of California, San Diego;University of Florida",
        "aff_domain": "amazon.com;ucsd.edu;ufl.edu;mbzuai.ac.ae;sjtu.edu.cn",
        "position": "MS student;PhD student;Undergrad student;PhD student;PhD student;Undergrad student;PhD student;MS student;Undergrad student;Researcher;Postdoc;Researcher",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bkY8zEDdH9",
        "title": "O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model Agent;Sequential Decision-Making;Offline In-Context Learning",
        "primary_area": "",
        "author": "Yuchen Xiao;Yanchao Sun;Mengda Xu;Udari Madhushani Sehwag;Jared Vann;Deepeka Garg;Sumitra Ganesh",
        "authorids": "~Yuchen_Xiao1;~Yanchao_Sun1;~Mengda_Xu1;~Udari_Madhushani_Sehwag1;~Jared_Vann1;~Deepeka_Garg1;~Sumitra_Ganesh1",
        "aff": "Columbia University;J.P. Morgan Chase;University of Maryland, College Park;Princeton University",
        "aff_domain": "jpmorgan.com;umd.edu;princeton.edu;columbia.edu",
        "position": "Researcher;PhD student;Researcher;PhD student;Researcher;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bnscREWUuc",
        "title": "How Multilingual are Large Language Models Fine-tuned for Translation?",
        "track": "main",
        "status": "Accept",
        "keywords": "multilingual machine translation;large language models;translation fine-tuning;multilingual evaluation",
        "primary_area": "",
        "author": "Aquia Richburg;Marine Carpuat",
        "authorids": "~Aquia_Richburg1;~Marine_Carpuat1",
        "aff": "University of Maryland, College Park",
        "aff_domain": "umd.edu",
        "position": "PhD student;Associate Professor",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bo4pauxnIR",
        "title": "Tabular Transfer Learning via Prompting LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "Tabular learning;Transfer learning;In-context learning",
        "primary_area": "",
        "author": "Jaehyun Nam;Woomin Song;Seong Hyeon Park;Jihoon Tack;Sukmin Yun;Jaehyung Kim;Kyu Hwan Oh;Jinwoo Shin",
        "authorids": "~Jaehyun_Nam2;~Woomin_Song1;~Seong_Hyeon_Park2;~Jihoon_Tack1;~Sukmin_Yun1;~Jaehyung_Kim1;~Kyu_Hwan_Oh1;~Jinwoo_Shin1",
        "aff": "Korea Advanced Institute of Science & Technology;Hyundai Motor Company;Mohamed bin Zayed University of Artificial Intelligence;KAIST;Korea Advanced Institute of Science and Technology",
        "aff_domain": "mbzuai.ac.ae;kaist.ac.kr;hyundai.com;kaist.edu",
        "position": "MS student;PhD student;PhD student;Full Professor;Researcher;PhD student;Postdoc;MS student",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bttKwCZDkm",
        "title": "Benchmarks as Microscopes: A Call for Model Metrology",
        "track": "main",
        "status": "Accept",
        "keywords": "position paper;benchmarks;capabilities;measurement",
        "primary_area": "",
        "author": "Michael Saxon;Ari Holtzman;Peter West;William Yang Wang;Naomi Saphra",
        "authorids": "~Michael_Saxon1;~Ari_Holtzman1;~Peter_West1;~William_Yang_Wang2;~Naomi_Saphra1",
        "aff": "Allen Institute for Artificial Intelligence;UC Santa Barbara;New York University;Department of Computer Science, University of Washington",
        "aff_domain": "cs.was;nyu.edu;ucsb.edu;allenai.org",
        "position": "PhD student;PhD student;Postdoc;Intern;Full Professor",
        "rating": "",
        "confidence": "3;4;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bwo3GVsgOv",
        "title": "Personalized Collaborative Fine-Tuning for On-Device Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Collaborative fine-tuning;On-device LLMs;Personalized learning",
        "primary_area": "",
        "author": "Nicolas Wagner;Dongyang Fan;Martin Jaggi",
        "authorids": "~Nicolas_Wagner2;~Dongyang_Fan2;~Martin_Jaggi1",
        "aff": "School of Computer and Communication Sciences, EPFL - EPF Lausanne;EPFL",
        "aff_domain": "ic.epfl.ch;epfl.ch",
        "position": "PhD student;Associate Professor;MS student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "c30qeMg8dv",
        "title": "Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations",
        "track": "main",
        "status": "Accept",
        "keywords": "Large language models;hallucinations;warnings;perception;engagement",
        "primary_area": "",
        "author": "Mahjabin Nahar;Haeseung Seo;Eun-Ju Lee;Aiping Xiong;Dongwon Lee",
        "authorids": "~Mahjabin_Nahar1;~Haeseung_Seo2;~Eun-Ju_Lee1;~Aiping_Xiong1;~Dongwon_Lee1",
        "aff": "The Pennsylvania State University;Pennsylvania State University;Seoul National University",
        "aff_domain": "snu.ac.kr;psu.edu",
        "position": "Full Professor;Full Professor;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cG1EbmWiSs",
        "title": "Unified View of Grokking, Double Descent and Emergent Abilities: A Comprehensive Study on Algorithm Task",
        "track": "main",
        "status": "Accept",
        "keywords": "Deep Learning;Grokking;Double Descent;Emergent Abilities",
        "primary_area": "",
        "author": "Yufei Huang;Shengding Hu;Xu Han;Zhiyuan Liu;Maosong Sun",
        "authorids": "~Yufei_Huang3;~Shengding_Hu2;~Xu_Han2;~Zhiyuan_Liu1;~Maosong_Sun1",
        "aff": "Tsinghua University;Tsinghua University, Tsinghua University",
        "aff_domain": "tsinghua.edu.cn;mail.tsinghua.edu.cn",
        "position": "PhD student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cKBmZ2PZ6c",
        "title": "ORAG: Ontology-Guided Retrieval-Augmented Generation for Theme-Specific Entity Typing",
        "track": "main",
        "status": "Accept",
        "keywords": "Fine-grained entity typing;theme-specific entity typing;retrieval-augmented generation;ontology enrichment;ontology-based information retrieval",
        "primary_area": "",
        "author": "Jinfeng Xiao;Linyi Ding;James Barry;Mohab Elkaref;Geeth De Mel;Jiawei Han",
        "authorids": "~Jinfeng_Xiao1;~Linyi_Ding1;~James_Barry2;~Mohab_Elkaref1;~Geeth_De_Mel1;~Jiawei_Han1",
        "aff": "International Business Machines;University of Illinois at Urbana-Champaign",
        "aff_domain": "uiuc.edu;illinois.edu;ibm.com",
        "position": "PhD student;MS student;Researcher",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dJMTn3QOWO",
        "title": "Fine-grained Hallucination Detection and Editing for Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Hallucination;Retrieval-augmented LMs",
        "primary_area": "",
        "author": "Abhika Mishra;Akari Asai;Vidhisha Balachandran;Yizhong Wang;Graham Neubig;Yulia Tsvetkov;Hannaneh Hajishirzi",
        "authorids": "~Abhika_Mishra1;~Akari_Asai2;~Vidhisha_Balachandran1;~Yizhong_Wang2;~Graham_Neubig1;~Yulia_Tsvetkov1;~Hannaneh_Hajishirzi1",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington;University of Washington, Seattle;Department of Computer Science, University of Washington;University of Washington;Carnegie Mellon University",
        "aff_domain": "cmu.edu;uw.edu;cs.washington.edu;cs.uw",
        "position": "Undergrad student;PhD student;Associate Professor;Assistant Professor;PhD student;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "5;5;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dJfBejh478",
        "title": "Scalable Model Editing via Customized Expert Networks",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model;Model Editing;Continual Learning",
        "primary_area": "",
        "author": "Zihan Yao;Yu He;Tianyu Qi;Ming Li",
        "authorids": "~Zihan_Yao2;~Yu_He11;~Tianyu_Qi1;~Ming_Li38",
        "aff": "Tomorrow Advancing Life",
        "aff_domain": "tal.com",
        "position": "Principal Researcher;Researcher;Researcher",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dWYRjT501w",
        "title": "Unveiling LLMs: The Evolution of Latent Representations in a Dynamic Knowledge Graph",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Models;Latent Representations;Factual Knowledge;Activation Patching;Graphs;Knowledge Graphs",
        "primary_area": "",
        "author": "Marco Bronzini;Carlo Nicolini;Bruno Lepri;Jacopo Staiano;Andrea Passerini",
        "authorids": "~Marco_Bronzini1;~Carlo_Nicolini1;~Bruno_Lepri1;~Jacopo_Staiano2;~Andrea_Passerini2",
        "aff": "Ipazia Spa;University of Trento;Fondazione Bruno Kessler",
        "aff_domain": "fbk.eu;unitn.it;ipazia.com",
        "position": "Associate Professor;Principal Researcher;Researcher;Senior Assistant Professor;PhD student",
        "rating": "",
        "confidence": "2;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dcbNzhVVQj",
        "title": "Learning From Correctness Without Prompting Makes LLM Efficient Reasoner",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM;Reasoning;Self-refine",
        "primary_area": "",
        "author": "Yuxuan YAO;Han Wu;Zhijiang Guo;Zhou Biyan;Jiahui Gao;Sichun Luo;Hanxu Hou;Xiaojin Fu;Linqi Song",
        "authorids": "~Yuxuan_YAO1;~Han_Wu5;~Zhijiang_Guo2;~Zhou_Biyan1;~Jiahui_Gao2;~Sichun_Luo1;~Hanxu_Hou1;~Xiaojin_Fu1;~Linqi_Song1",
        "aff": "City University of Hong Kong;Dongguan University of Technology;University of Cambridge;Huawei Technologies Ltd.",
        "aff_domain": "cam.ac.uk;my.cityu.edu.hk;dgut.edu.cn;huawei.com;cityu.edu.hk",
        "position": "PhD student;Full Professor;Assistant Professor;Researcher;PhD student;Postdoc;PhD student",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "didvEO1can",
        "title": "CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text",
        "track": "main",
        "status": "Accept",
        "keywords": "Category Theory;LLM;Code;Evaluation",
        "primary_area": "",
        "author": "Zhenru Lin;Yiqun Yao;Yang Yuan",
        "authorids": "~Zhenru_Lin1;~Yiqun_Yao1;~Yang_Yuan4",
        "aff": "Tsinghua University, Tsinghua University;Beijing Academy of Artificial Intelligence;Massachusetts Institute of Technology",
        "aff_domain": "baai.ac.cn;tsinghua.edu.cn;mit.edu",
        "position": "Postdoc;Researcher;PhD student",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dj9x6JuiD5",
        "title": "With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "Inference-Time Training; Long Context;",
        "primary_area": "",
        "author": "Yan Wang;Dongyang Ma;Deng Cai",
        "authorids": "~Yan_Wang17;~Dongyang_Ma4;~Deng_Cai1",
        "aff": "Tencent AI Lab;Tencent;miHoYo",
        "aff_domain": "mihoyo.com;gmail.com;tencent.com",
        "position": "Research Scientist;Graduate;Research Scientist",
        "rating": "",
        "confidence": "5;3;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dkpeWQRmlc",
        "title": "HDT: Hierarchical Document Transformer",
        "track": "main",
        "status": "Accept",
        "keywords": "compute & memory efficient Transformer;sparse attention;encoder-only;encoder-decoder;long-text Transformer",
        "primary_area": "",
        "author": "Haoyu He;Markus Flicke;Jan Buchmann;Iryna Gurevych;Andreas Geiger",
        "authorids": "~Haoyu_He4;~Markus_Flicke1;~Jan_Buchmann1;~Iryna_Gurevych1;~Andreas_Geiger3",
        "aff": "University of Tuebingen;UKP (TU Darmstadt);Eberhard-Karls-Universit\u00e4t T\u00fcbingen",
        "aff_domain": "uni-tuebingen.de;ukp.informatik.tu-darmstadt.de",
        "position": "Professor;PhD student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dnwRScljXr",
        "title": "Evaluating LLMs at Detecting Errors in LLM Responses",
        "track": "main",
        "status": "Accept",
        "keywords": "error detection;evaluation",
        "primary_area": "",
        "author": "Ryo Kamoi;Sarkar Snigdha Sarathi Das;Renze Lou;Jihyun Janice Ahn;Yilun Zhao;Xiaoxin Lu;Nan Zhang;Yusen Zhang;Haoran Ranran Zhang;Sujeeth Reddy Vummanthala;Salika Dave;Shaobo Qin;Arman Cohan;Wenpeng Yin;Rui Zhang",
        "authorids": "~Ryo_Kamoi1;~Sarkar_Snigdha_Sarathi_Das1;~Renze_Lou1;~Jihyun_Janice_Ahn1;~Yilun_Zhao1;~Xiaoxin_Lu1;~Nan_Zhang9;~Yusen_Zhang1;~Haoran_Ranran_Zhang1;~Sujeeth_Reddy_Vummanthala1;~Salika_Dave1;~Shaobo_Qin1;~Arman_Cohan1;~Wenpeng_Yin1;~Rui_Zhang7",
        "aff": "Yale University;Pennsylvania State University;University of Wisconsin - Madison;Allen Institute for Artificial Intelligence;State University of New York at Stony Brook;Temple University",
        "aff_domain": "allenai.org;wisc.edu;yale.edu;stonybrook.edu;temple.edu;psu.edu",
        "position": "Research Scientist;PhD student;PhD student;Assistant Professor;PhD student;MS student;PhD student;PhD student;MS student;Assistant Professor;PhD student;PhD student;PhD student;Undergrad student;PhD student",
        "rating": "",
        "confidence": "3;5;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dribhnhm1i",
        "title": "Tuning Language Models by Proxy",
        "track": "main",
        "status": "Accept",
        "keywords": "LM adaptation;inference algorithms;instruction-tuning",
        "primary_area": "",
        "author": "Alisa Liu;Xiaochuang Han;Yizhong Wang;Yulia Tsvetkov;Yejin Choi;Noah A. Smith",
        "authorids": "~Alisa_Liu1;~Xiaochuang_Han1;~Yizhong_Wang2;~Yulia_Tsvetkov1;~Yejin_Choi1;~Noah_A._Smith2",
        "aff": "Allen Institute for Artificial Intelligence;Google;Department of Computer Science, University of Washington",
        "aff_domain": "allenai.org;cs.washington.edu;google.com",
        "position": "Intern;PhD student;Professor;PhD student;Assistant Professor;Senior Director of NLP Research",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eDWcNqiQWW",
        "title": "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "multi-modal large language models;nonverbal abstract reasoning;in-context learning;raven's progressive matrices",
        "primary_area": "",
        "author": "Kian Ahrabian;Zhivar Sourati;Kexuan Sun;Jiarui Zhang;Yifan Jiang;Fred Morstatter;Jay Pujara",
        "authorids": "~Kian_Ahrabian1;~Zhivar_Sourati1;~Kexuan_Sun1;~Jiarui_Zhang2;~Yifan_Jiang4;~Fred_Morstatter1;~Jay_Pujara1",
        "aff": "USC/ISI;University of Southern California",
        "aff_domain": "usc.edu;isi.edu",
        "position": "Research Scientist;Assistant Professor;PhD student;PhD student;PhD student;MS student;PhD student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eGCw1UVOhk",
        "title": "LMD3: Language Model Data Density Dependence",
        "track": "main",
        "status": "Accept",
        "keywords": "data attribution;retrieval;embeddings;training data;density estimation",
        "primary_area": "",
        "author": "John Kirchenbauer;Garrett Honke;Gowthami Somepalli;Jonas Geiping;Katherine Lee;Daphne Ippolito;Tom Goldstein;David Andre",
        "authorids": "~John_Kirchenbauer1;~Garrett_Honke1;~Gowthami_Somepalli1;~Jonas_Geiping1;~Katherine_Lee1;~Daphne_Ippolito1;~Tom_Goldstein1;~David_Andre2",
        "aff": "University of Maryland, College Park;Google",
        "aff_domain": "umd.edu;google.com",
        "position": "Principal Researcher;PhD student;PhD student;Postdoc;Researcher;Associate Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eJ3cHNu7ss",
        "title": "HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "domain adaption;one-stage training;data sampling strategy;specialized LLM",
        "primary_area": "",
        "author": "Junying Chen;Xidong Wang;Ke Ji;Anningzhe Gao;Feng Jiang;Shunian Chen;Hongbo Zhang;Song Dingjie;Wenya Xie;Chuyi Kong;Jianquan Li;Xiang Wan;Haizhou Li;Benyou Wang",
        "authorids": "~Junying_Chen2;~Xidong_Wang4;~Ke_Ji1;~Anningzhe_Gao1;~Feng_Jiang4;~Shunian_Chen1;~Hongbo_Zhang5;~Song_Dingjie1;~Wenya_Xie1;~Chuyi_Kong1;~Jianquan_Li1;~Xiang_Wan1;~Haizhou_Li3;~Benyou_Wang2",
        "aff": "Shenzhen Research Institute of Big Data;Southeast University;Harbin Institute of Technology, Shenzhen;National University of Singapore;The Chinese University of Hong Kong, Shenzhen;Duke University;ShenZhen research institute of big data;Beijing Institute of Technology;Nanjing University",
        "aff_domain": "duke.edu;nju.edu.cn;cuhk.edu.cn;bit.edu.cn;sribd.cn;hit.edu;nus.edu.sg;seu.edu.cn",
        "position": "Researcher;Assistant Professor;Postdoc;Full Professor;Researcher;MS student;MS student;MS student;MS student;Principal Researcher;Undergrad student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "egVSgtJJAx",
        "title": "VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?",
        "track": "main",
        "status": "Accept",
        "keywords": "multimodal large language model;evaluation;web understanding;grounding",
        "primary_area": "",
        "author": "Junpeng Liu;Yifan Song;Bill Yuchen Lin;Wai Lam;Graham Neubig;Yuanzhi Li;Xiang Yue",
        "authorids": "~Junpeng_Liu2;~Yifan_Song2;~Bill_Yuchen_Lin1;~Wai_Lam1;~Graham_Neubig1;~Yuanzhi_Li1;~Xiang_Yue1",
        "aff": "CMU, Carnegie Mellon University;The Chinese University of Hong Kong;Beijing University of Posts and Telecommunications;Allen Institute for Artificial Intelligence;Peking University;Carnegie Mellon University",
        "aff_domain": "andrew.cmu.edu;allenai.org;bupt.edu.cn;cmu.edu;pku.edu.cn;cuhk.edu.hk",
        "position": "Researcher;Associate Professor;MS student;Professor;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "4;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fib9qidCpY",
        "title": "Towards Verifiable Text Generation with Symbolic References",
        "track": "main",
        "status": "Accept",
        "keywords": "attribution;verification of llm generations;symbolic linking;placeholder;template generation",
        "primary_area": "",
        "author": "Lucas Torroba Hennigen;Zejiang Shen;Aniruddha Nrusimha;Bernhard Gapp;David Sontag;Yoon Kim",
        "authorids": "~Lucas_Torroba_Hennigen1;~Zejiang_Shen1;~Aniruddha_Nrusimha1;~Bernhard_Gapp1;~David_Sontag1;~Yoon_Kim1",
        "aff": "Good Data Initiative;International Business Machines;MIT;Massachusetts Institute of Technology",
        "aff_domain": "gooddatainitiative.com;ibm.com;mit.edu",
        "position": "Ph.D. candidate;Researcher;Assistant Professor;Intern;Assistant Professor",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gQAEGSGVnN",
        "title": "UniMem: Towards a Unified View of Long-Context Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "long-context;large language models",
        "primary_area": "",
        "author": "Junjie Fang;Likai Tang;Hongzhe Bi;Yujia Qin;Si Sun;Zhenyu Li;Haolun Li;Yongjian Li;Xin Cong;Yankai Lin;Yukun Yan;Xiaodong Shi;Sen Song;Zhiyuan Liu;Maosong Sun",
        "authorids": "~Junjie_Fang1;~Likai_Tang1;~Hongzhe_Bi2;~Yujia_Qin1;~Si_Sun1;~Zhenyu_Li5;~Haolun_Li2;~Yongjian_Li2;~Xin_Cong1;~Yankai_Lin1;~Yukun_Yan2;~Xiaodong_Shi2;~Sen_Song1;~Zhiyuan_Liu1;~Maosong_Sun1",
        "aff": "Xiamen University;Tsinghua University, Tsinghua University;Chinese Academy of Sciences;Tsinghua University;Xiamen University, Tsinghua University;Beijing University of Posts and Telecommunications;Renmin University of China",
        "aff_domain": "ruc.edu.cn;ac.cn;xmu.edu.cn;tsinghua.edu.cn;bupt.edu.cn;mails.tsinghua.edu.cn",
        "position": "MS student;PhD student;PhD student;Full Professor;PhD student;Assistant Professor;Undergrad student;PhD student;PhD student;PhD student;Associate Professor;Undergrad student",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gUNeyiLNxr",
        "title": "Uncovering Intermediate Variables in Transformers using Circuit Probing",
        "track": "main",
        "status": "Accept",
        "keywords": "Mechanistic Interpretability;Deep Learning",
        "primary_area": "",
        "author": "Michael A. Lepori;Thomas Serre;Ellie Pavlick",
        "authorids": "~Michael_A._Lepori1;~Thomas_Serre1;~Ellie_Pavlick1",
        "aff": "Brown University;Universit\u00e9 de Toulouse",
        "aff_domain": "univ-toulouse.fr;brown.edu",
        "position": "Assistant Professor;PhD student;Full Professor",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gpgMRWgv9Q",
        "title": "TarGEN: Targeted Data Generation with Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Synthetic Data Generation;Target Data Generation;Seedless Generation;Self Correction",
        "primary_area": "",
        "author": "Himanshu Gupta;Kevin Scaria;Ujjwala Anantheswaran;Shreyas Verma;Mihir Parmar;Saurabh Arjun Sawant;Chitta Baral;Swaroop Mishra",
        "authorids": "~Himanshu_Gupta5;~Kevin_Scaria1;~Ujjwala_Anantheswaran1;~Shreyas_Verma1;~Mihir_Parmar1;~Saurabh_Arjun_Sawant1;~Chitta_Baral1;~Swaroop_Mishra1",
        "aff": "Arizona State University;Georgia Institute of Technology;Google",
        "aff_domain": "asu.edu;google.com;gatech.edu",
        "position": "Full Professor;MS student;MS student;PhD student;MS student;MS student;Researcher",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "h5umhm6mzj",
        "title": "NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness",
        "track": "main",
        "status": "Accept",
        "keywords": "Code LMs;Non-Functional Requirements;Code Comprehension;Evaluation",
        "primary_area": "",
        "author": "Manav Singhal;Tushar Aggarwal;Abhijeet Awasthi;Nagarajan Natarajan;Aditya Kanade",
        "authorids": "~Manav_Singhal1;~Tushar_Aggarwal1;~Abhijeet_Awasthi1;~Nagarajan_Natarajan1;~Aditya_Kanade2",
        "aff": "Indian Institute of Technology Bombay, Indian Institute of Technology Bombay;Microsoft",
        "aff_domain": "cse.iitb.ac.in;microsoft.com",
        "position": "PhD student;Principal Researcher;Pre-Doctoral Research Fellow;Researcher;Principal Researcher",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hDoN0CAy5e",
        "title": "Characterizing Multimodal Long-form Summarization: A Case Study on Financial Reports",
        "track": "main",
        "status": "Accept",
        "keywords": "summarization;long-form;multimodal;extractiveness",
        "primary_area": "",
        "author": "Tianyu Cao;Natraj Raman;Danial Dervovic;Chenhao Tan",
        "authorids": "~Tianyu_Cao2;~Natraj_Raman3;~Danial_Dervovic1;~Chenhao_Tan1",
        "aff": "J.P. Morgan Chase;University of Chicago;Zhejiang University",
        "aff_domain": "jpmorgan.com;uchicago.edu;zju.edu.cn",
        "position": "Assistant Professor;Researcher;Undergrad student",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "i2oJjC0ESQ",
        "title": "Does In-Context Learning Really Learn? Rethinking How Large Language Models Respond and Solve Tasks via In-Context Learning",
        "track": "main",
        "status": "Accept",
        "keywords": "In-context learning",
        "primary_area": "",
        "author": "Quanyu Long;Yin Wu;Wenya Wang;Sinno Jialin Pan",
        "authorids": "~Quanyu_Long1;~Yin_Wu1;~Wenya_Wang1;~Sinno_Jialin_Pan1",
        "aff": "University of Washington;Nanyang Technological University;The Chinese University of Hong Kong",
        "aff_domain": "e.ntu.edu.sg;cuhk.edu.hk;ntu.edu.sg;cs.washington.edu",
        "position": "PhD student;Postdoc;PhD student;Full Professor",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iI1CzEhEMU",
        "title": "Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model; in-context learning; compositional ability",
        "primary_area": "",
        "author": "Zhuoyan Xu;Zhenmei Shi;Yingyu Liang",
        "authorids": "~Zhuoyan_Xu1;~Zhenmei_Shi1;~Yingyu_Liang1",
        "aff": "University of Wisconsin - Madison;University of Wisconsin, Madison",
        "aff_domain": "wisc.edu",
        "position": "Assistant Professor;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iMqJsQ4evS",
        "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model;Strategic Reasoning;Multi-Agent System;Decision-Making;Advanced Reasoning",
        "primary_area": "",
        "author": "Yadong Zhang;Shaoguang Mao;Tao Ge;Xun Wang;Yan Xia;Wenshan Wu;Ting Song;Man Lan;Furu Wei",
        "authorids": "~Yadong_Zhang1;~Shaoguang_Mao1;~Tao_Ge1;~Xun_Wang5;~Yan_Xia7;~Wenshan_Wu1;~Ting_Song2;~Man_Lan1;~Furu_Wei1",
        "aff": "Microsoft;Research, Microsoft;Microsoft Research;East China Normal University",
        "aff_domain": "ecnu.edu.cn;research.microsoft.com;microsoft.com",
        "position": "Partner Research Manager;Full Professor;Researcher;Principal Researcher;MS student;Researcher",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ig6NI9oPhD",
        "title": "LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification",
        "track": "main",
        "status": "Accept",
        "keywords": "ordinal classification;preference machines",
        "primary_area": "",
        "author": "Zhen Qin;Junru Wu;Jiaming Shen;Tianqi Liu;Xuanhui Wang",
        "authorids": "~Zhen_Qin5;~Junru_Wu2;~Jiaming_Shen1;~Tianqi_Liu1;~Xuanhui_Wang1",
        "aff": "Google;Google DeepMind;Google Research",
        "aff_domain": "google.com",
        "position": "Research Scientist;Researcher;Software Engineer;Software Engineer;Software Engineer",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "j3AAkO5xgr",
        "title": "Understanding Retrieval Augmentation for Long-Form Question Answering",
        "track": "main",
        "status": "Accept",
        "keywords": "retrieval augmentation;retrieval-augmented generation;long-form question answering;question answering;attribution",
        "primary_area": "",
        "author": "Hung-Ting Chen;Fangyuan Xu;Shane Arora;Eunsol Choi",
        "authorids": "~Hung-Ting_Chen1;~Fangyuan_Xu1;~Shane_Arora1;~Eunsol_Choi1",
        "aff": "University of Texas, Austin;University of Texas at Austin",
        "aff_domain": "cs.utexas.edu;utexas.edu",
        "position": "Assistant Professor;Research Assistant;MS student;MS student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jq2kNXigPP",
        "title": "DeStein: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion",
        "track": "main",
        "status": "Accept",
        "keywords": "detoxification; controllable text generation; language models",
        "primary_area": "",
        "author": "Yu Li;Han Jiang;Chuanyang Gong;Zhihua Wei",
        "authorids": "~Yu_Li32;~Han_Jiang2;~Chuanyang_Gong1;~Zhihua_Wei1",
        "aff": "Tongji University;University of Electronic Science and Technology of China",
        "aff_domain": "tongji.edu.cn;uestc.edu.cn",
        "position": "PhD student;MS student;Undergrad student;Full Professor",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jt0R50d5nk",
        "title": "Can MLLMs Perform Text-to-Image In-Context Learning?",
        "track": "main",
        "status": "Accept",
        "keywords": "MLLMs;In-Context Learning;Multimodal In-Context Learning;Text-to-Image Generation;multimodal large language models;large language models",
        "primary_area": "",
        "author": "Yuchen Zeng;Wonjun Kang;Yicong Chen;Hyung Il Koo;Kangwook Lee",
        "authorids": "~Yuchen_Zeng1;~Wonjun_Kang1;~Yicong_Chen1;~Hyung_Il_Koo1;~Kangwook_Lee1",
        "aff": "KRAFTON;University of Wisconsin - Madison;University of Wisconsin, Madison;Furiosa AI",
        "aff_domain": "furiosa.ai;krafton.com;wisc.edu",
        "position": "Researcher;Researcher;PhD student;Undergrad student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "k2xZYPZo34",
        "title": "Bring Your Own Data! Self-Sensitivity Evaluation for Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Evaluations",
        "primary_area": "",
        "author": "Neel Jain;Khalid Saifullah;Yuxin Wen;John Kirchenbauer;Manli Shu;Aniruddha Saha;Micah Goldblum;Jonas Geiping;Tom Goldstein",
        "authorids": "~Neel_Jain1;~Khalid_Saifullah1;~Yuxin_Wen2;~John_Kirchenbauer1;~Manli_Shu1;~Aniruddha_Saha1;~Micah_Goldblum1;~Jonas_Geiping1;~Tom_Goldstein1",
        "aff": "University of Maryland, College Park;Department of Computer Science, University of Maryland, College Park;New York University",
        "aff_domain": "umd.edu;nyu.edu;cs.umd.edu",
        "position": "Postdoc;PhD student;Postdoc;PhD student;PhD student;Postdoc;PhD student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "k8KS9Ps71d",
        "title": "PRobELM: Plausibility Ranking Evaluation for Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "plausibility;benchmark;evaluation",
        "primary_area": "",
        "author": "Moy Yuan;Eric Chamoun;Rami Aly;Chenxi Whitehouse;Andreas Vlachos",
        "authorids": "~Moy_Yuan1;~Eric_Chamoun1;~Rami_Aly1;~Chenxi_Whitehouse1;~Andreas_Vlachos1",
        "aff": "City, University of London;Amazon (AWS);University of Cambridge",
        "aff_domain": "amazon.com;city.ac.uk;cam.ac.uk",
        "position": "Full Professor;PhD student;PhD student;Intern;PhD student",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kEVcNxtqXk",
        "title": "From $r$ to $Q^*$: Your Language Model is Secretly a Q-Function",
        "track": "main",
        "status": "Accept",
        "keywords": "RLHF;Alignment;Direct Preference Optimization",
        "primary_area": "",
        "author": "Rafael Rafailov;Joey Hejna;Ryan Park;Chelsea Finn",
        "authorids": "~Rafael_Rafailov1;~Joey_Hejna1;~Ryan_Park1;~Chelsea_Finn1",
        "aff": "Stanford University;Google",
        "aff_domain": "stanford.edu;google.com",
        "position": "Research Scientist;PhD student;Undergrad student;PhD student",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kGa4fMtP9l",
        "title": "Can Language Models Solve Olympiad Programming?",
        "track": "main",
        "status": "Accept",
        "keywords": "coding;LLM;memory;retrieval",
        "primary_area": "",
        "author": "Ben Shi;Michael Tang;Karthik R Narasimhan;Shunyu Yao",
        "authorids": "~Ben_Shi1;~Michael_Tang3;~Karthik_R_Narasimhan1;~Shunyu_Yao1",
        "aff": "Princeton University",
        "aff_domain": "princeton.edu",
        "position": "Undergrad student;Assistant Professor;Undergrad student;PhD student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kHO2ZTa8e3",
        "title": "The N+ Implementation Details of RLHF with PPO: A Case Study on TL;DR Summarization",
        "track": "main",
        "status": "Accept",
        "keywords": "Reinforcement Learning from Human Feedback;RLHF",
        "primary_area": "",
        "author": "Shengyi Huang;Michael Noukhovitch;Arian Hosseini;Kashif Rasul;Weixun Wang;Lewis Tunstall",
        "authorids": "~Shengyi_Huang1;~Michael_Noukhovitch1;~Arian_Hosseini1;~Kashif_Rasul1;~Weixun_Wang1;~Lewis_Tunstall1",
        "aff": "Tianjin University;University of Montreal;Drexel University;Zalando SE;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal",
        "aff_domain": "drexel.edu;zalando.de;tju.edu.cn;umontreal.ca;mila.umontreal.ca",
        "position": "PhD student;Researcher;PhD student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;5;4;5;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.2,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kIoBbc76Sy",
        "title": "RULER: What\u2019s the Real Context Size of Your Long-Context Language Models?",
        "track": "main",
        "status": "Accept",
        "keywords": "Long-context;Evaluation;Benchmark;Synthetic",
        "primary_area": "",
        "author": "Cheng-Ping Hsieh;Simeng Sun;Samuel Kriman;Shantanu Acharya;Dima Rekesh;Fei Jia;Boris Ginsburg",
        "authorids": "~Cheng-Ping_Hsieh1;~Simeng_Sun2;~Samuel_Kriman1;~Shantanu_Acharya1;~Dima_Rekesh1;~Fei_Jia1;~Boris_Ginsburg1",
        "aff": "University of Massachusetts, Amherst;University of California Berkeley;NVIDIA;New York University",
        "aff_domain": "berkeley.edu;nvidia.com;umass.edu;nyu.edu",
        "position": "Deep Learning Prinicipal Engineer;Researcher;Lecturer;Researcher;Researcher;MS student;PhD student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kLH4ccaL21",
        "title": "GeniL: A Multilingual Dataset on Generalizing Language",
        "track": "main",
        "status": "Accept",
        "keywords": "Stereotype;Evaluation;Generalization;Social Group Bias;Representation",
        "primary_area": "",
        "author": "Aida Mostafazadeh Davani;Sagar Gubbi Venkatesh;Sunipa Dev;Shachi Dave;Vinodkumar Prabhakaran",
        "authorids": "~Aida_Mostafazadeh_Davani1;~Sagar_Gubbi_Venkatesh1;~Sunipa_Dev1;~Shachi_Dave1;~Vinodkumar_Prabhakaran2",
        "aff": "Google;Research, Google",
        "aff_domain": "research.google.com;google.com",
        "position": "Researcher;Postdoc;Researcher;Research Scientist;Research Scientist",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kWnlCVcp6o",
        "title": "Crystal: Illuminating LLM Abilities on Language and Code",
        "track": "main",
        "status": "Accept",
        "keywords": "LM Pretraining;Language and Code;Transparency and Reproducibility;Multi-stage Pretraining;Open Science",
        "primary_area": "",
        "author": "Tianhua Tao;Junbo Li;Bowen Tan;Hongyi Wang;William Marshall;Bhargav M Kanakiya;Joel Hestness;Natalia Vassilieva;Zhiqiang Shen;Eric P. Xing;Zhengzhong Liu",
        "authorids": "~Tianhua_Tao1;~Junbo_Li3;~Bowen_Tan2;~Hongyi_Wang1;~William_Marshall2;~Bhargav_M_Kanakiya1;~Joel_Hestness2;~Natalia_Vassilieva1;~Zhiqiang_Shen1;~Eric_Xing1;~Zhengzhong_Liu1",
        "aff": "CMU, Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;Carnegie Mellon University;Cerebras Systems, Inc;University of California, Santa Cruz;School of Computer Science, Carnegie Mellon University;University of Illinois at Urbana-Champaign",
        "aff_domain": "andrew.cmu.edu;illinois.edu;cerebras.net;cmu.edu;cs.cmu.edu;ucsc.edu;mbzuai.ac.ae",
        "position": "Researcher;PhD student;Full Professor;Researcher;MS student;MS student;Researcher;Researcher;Research Scientist",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kh9Zt2Ldmn",
        "title": "Don't throw away your value model! Generating more preferable text with Value-Guided Monte-Carlo Tree Search decoding",
        "track": "main",
        "status": "Accept",
        "keywords": "text generation;decoding;search;reinforcement learning;ppo;monte-carlo tree search",
        "primary_area": "",
        "author": "Jiacheng Liu;Andrew Cohen;Ramakanth Pasunuru;Yejin Choi;Hannaneh Hajishirzi;Asli Celikyilmaz",
        "authorids": "~Jiacheng_Liu2;~Andrew_Cohen4;~Ramakanth_Pasunuru2;~Yejin_Choi1;~Hannaneh_Hajishirzi1;~Asli_Celikyilmaz1",
        "aff": "Meta Platforms Inc;University of Washington, Seattle;Facebook;Department of Computer Science, University of Washington;Meta Platforms;FAIR ",
        "aff_domain": "meta.com;uw.edu;cs.washington.edu",
        "position": "Researcher;Principal Researcher;Assistant Professor;Intern;Researcher;Professor",
        "rating": "",
        "confidence": "2;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kpf7UbnSAm",
        "title": "CA-LoRA: Adapting Existing LoRA for Compressed LLMs to Enable Efficient Multi-Tasking on Personal Devices",
        "track": "main",
        "status": "Accept",
        "keywords": "Model compression;Parameter-efficient tuning;Low-Resource Methods for NLP",
        "primary_area": "",
        "author": "Weilin Zhao;Yuxiang Huang;Xu Han;Zhiyuan Liu;Zhengyan Zhang;Kuai Li;Chen Chen;TAO YANG;Maosong Sun",
        "authorids": "~Weilin_Zhao1;~Yuxiang_Huang3;~Xu_Han2;~Zhiyuan_Liu1;~Zhengyan_Zhang1;~Kuai_Li1;~Chen_Chen48;~TAO_YANG11;~Maosong_Sun1",
        "aff": "Apple;Tsinghua University;Tsinghua University, Tsinghua University",
        "aff_domain": "tsinghua.edu.cn;apple.com",
        "position": "Researcher;Undergrad student;Undergrad student;PhD student;Associate Professor",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kzzwTrt04Z",
        "title": "AI-generated text boundary detection with RoFT",
        "track": "main",
        "status": "Accept",
        "keywords": "artificial text detection;cross-model detection;cross-domain detection;boundary detection;interpretability;analysis",
        "primary_area": "",
        "author": "Laida Kushnareva;Tatiana Gaintseva;Dmitry Abulkhanov;Kristian Kuznetsov;German Magai;Eduard Tulchinskii;Serguei Barannikov;Sergey Nikolenko;Irina Piontkovskaya",
        "authorids": "~Laida_Kushnareva1;~Tatiana_Gaintseva2;~Dmitry_Abulkhanov1;~Kristian_Kuznetsov1;~German_Magai1;~Eduard_Tulchinskii1;~Serguei_Barannikov1;~Sergey_Nikolenko1;~Irina_Piontkovskaya2",
        "aff": "Higher School of Economics;Huawei;Huawei Technologies Ltd.;Skolkovo Institute of Science and Technology;Steklov Institute of Mathematics at St. Petersburg;Queen Mary University of London;CNRS, Institut Mathematiques de Jussieu, Paris Diderot University",
        "aff_domain": "skoltech.ru;imj-prg.fr;hse.ru;qmul.ac.uk;huawei.com;huawei-partners.com;pdmi.ras.ru",
        "position": "PhD student;PhD student;Researcher;MS student;Assistant Professor;Researcher;PhD student;Senior Academic Consultant",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lJMioZBoR8",
        "title": "Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback",
        "track": "main",
        "status": "Accept",
        "keywords": "hallucination;alignment;RLKF",
        "primary_area": "",
        "author": "Hongshen Xu;Zichen Zhu;Situo Zhang;Da Ma;Shuai Fan;Lu Chen;Kai Yu",
        "authorids": "~Hongshen_Xu1;~Zichen_Zhu2;~Situo_Zhang1;~Da_Ma2;~Shuai_Fan1;~Lu_Chen3;~Kai_Yu3",
        "aff": "AISpeech Ltd;Shanghai Jiaotong University;Shanghai Jiao Tong University",
        "aff_domain": "aispeech.com;sjtu.edu.cn",
        "position": "PhD student;PhD student;Full Professor;Assistant Professor;Researcher;PhD student;Undergrad student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lVOw78nYXS",
        "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "Interaction;Communication Efficiency;LLM;In-context learning;Linguistic Convention",
        "primary_area": "",
        "author": "Yilun Hua;Yoav Artzi",
        "authorids": "~Yilun_Hua1;~Yoav_Artzi1",
        "aff": "",
        "aff_domain": "",
        "position": "",
        "rating": "",
        "confidence": "4;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lY6XTF9tPv",
        "title": "LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset",
        "track": "main",
        "status": "Accept",
        "keywords": "chemistry;LLMs;fine-tuning;instruction tuning;dataset;molecule",
        "primary_area": "",
        "author": "Botao Yu;Frazier N. Baker;Ziqi Chen;Xia Ning;Huan Sun",
        "authorids": "~Botao_Yu1;~Frazier_N._Baker1;~Ziqi_Chen1;~Xia_Ning1;~Huan_Sun1",
        "aff": "Ohio State University;The Ohio State University, Columbus;Nanjing University;Ohio State University, Columbus",
        "aff_domain": "osu.edu;nju.edu.cn",
        "position": "MS student;PhD student;Associate Professor;Associate Professor;PhD student",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ljFgX6A8NL",
        "title": "Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "safety alignment;false refusals;pseudo-harmful prompts;controllable text generation;usability-safety trade-off;LLM",
        "primary_area": "",
        "author": "Bang An;Sicheng Zhu;Ruiyi Zhang;Michael-Andrei Panaitescu-Liess;Yuancheng Xu;Furong Huang",
        "authorids": "~Bang_An1;~Sicheng_Zhu1;~Ruiyi_Zhang3;~Michael-Andrei_Panaitescu-Liess1;~Yuancheng_Xu1;~Furong_Huang1",
        "aff": "University of Maryland;Capital One;Adobe Systems;University of Maryland, College Park",
        "aff_domain": "umd.edu;capitalone.com;adobe.com;cs.umd.edu",
        "position": "Intern;Assistant Professor;PhD student;PhD student;PhD student;Research Scientist",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lkrH6ovzsj",
        "title": "Multi-FAct: Assessing Factuality of Multilingual LLMs using FActScore",
        "track": "main",
        "status": "Accept",
        "keywords": "multilinguality;factuality;knowledge representation",
        "primary_area": "",
        "author": "Sheikh Shafayat;Eunsu Kim;Juhyun Oh;Alice Oh",
        "authorids": "~Sheikh_Shafayat1;~Eunsu_Kim1;~Juhyun_Oh2;~Alice_Oh1",
        "aff": "Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology;KAIST",
        "aff_domain": "kaist.ac.kr;cs.kaist.ac.kr;kaist.edu",
        "position": "Full Professor;MS student;PhD student;Undergrad student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mUlLf50Y6H",
        "title": "Is ChatGPT a Good Sentiment Analyzer?",
        "track": "main",
        "status": "Accept",
        "keywords": "sentiment analysis;chatgpt;aspect-based sentiment analysis;emotion analysis;large language models",
        "primary_area": "",
        "author": "Zengzhi Wang;Qiming Xie;Yi Feng;Zixiang Ding;Zinong Yang;Rui Xia",
        "authorids": "~Zengzhi_Wang1;~Qiming_Xie1;~Yi_Feng8;~Zixiang_Ding1;~Zinong_Yang1;~Rui_Xia1",
        "aff": "Nanjing University of Science and Technology",
        "aff_domain": "njust.edu.cn",
        "position": "PhD student;Full Professor;Undergrad student;MS student;PhD student",
        "rating": "",
        "confidence": "3;5;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mkYCfO822n",
        "title": "AmbigDocs: Reasoning across Documents on Different Entities under the Same Name",
        "track": "main",
        "status": "Accept",
        "keywords": "multi-document reasoning;entity disambiguation;ambiguous QA",
        "primary_area": "",
        "author": "Yoonsang Lee;Xi Ye;Eunsol Choi",
        "authorids": "~Yoonsang_Lee1;~Xi_Ye2;~Eunsol_Choi1",
        "aff": "University of Texas, Austin;UT Austin;Seoul National University",
        "aff_domain": "cs.utexas.edu;snu.ac.kr",
        "position": "Assistant Professor;PhD student;Undergrad student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nGCMLATBit",
        "title": "Eliciting Latent Knowledge from \"Quirky\" Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Eliciting Latent Knowledge;Scalable Oversight;Honesty;Generalization",
        "primary_area": "",
        "author": "Alex Troy Mallen;Madeline Brumley;Julia Kharchenko;Nora Belrose",
        "authorids": "~Alex_Troy_Mallen1;~Madeline_Brumley1;~Julia_Kharchenko1;~Nora_Belrose1",
        "aff": "University of Washington;FAR AI;University of Washington, Seattle",
        "aff_domain": "far.ai;uw.edu",
        "position": "Undergrad student;Undergrad student;Undergrad student;Researcher",
        "rating": "",
        "confidence": "4;3;3;2",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nI6JyFSnyV",
        "title": "SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "quantization;KVCache compression;model compression",
        "primary_area": "",
        "author": "Haojie Duanmu;Zhihang Yuan;Xiuhong Li;Jiangfei Duan;Xingcheng ZHANG;Dahua Lin",
        "authorids": "~Haojie_Duanmu1;~Zhihang_Yuan1;~Xiuhong_Li1;~Jiangfei_Duan1;~Xingcheng_ZHANG2;~Dahua_Lin1",
        "aff": "Houmo AI;Shanghai Jiaotong University;The Chinese University of Hong Kong;Sensetime;SenseTime",
        "aff_domain": "houmo.ai;cuhk.edu.hk;sensetime.com;sjtu.edu.cn",
        "position": "Associate Professor;PhD student;PhD student;Researcher;Researcher;Researcher",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nMAaCsCTCI",
        "title": "Impact of Preference Noise on the Alignment Performance of Generative Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "LM Alignment;Noisy Data;Preference Learning",
        "primary_area": "",
        "author": "Yang Gao;Dana Alon;Donald Metzler",
        "authorids": "~Yang_Gao6;~Dana_Alon1;~Donald_Metzler1",
        "aff": "Google;Research, Google",
        "aff_domain": "research.google.com;google.com",
        "position": "Researcher;Research Scientist;Researcher",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nT6fQIidrQ",
        "title": "Learning to Plan for Language Modeling from Unlabeled Data",
        "track": "main",
        "status": "Accept",
        "keywords": "planning;representation learning;hierarchical models",
        "primary_area": "",
        "author": "Nathan Cornille;Marie-Francine Moens;Florian Mai",
        "authorids": "~Nathan_Cornille1;~Marie-Francine_Moens1;~Florian_Mai1",
        "aff": "KU Leuven, KU Leuven;Idiap Research Institute;KU Leuven",
        "aff_domain": "idiap.ch;cs.kuleuven.be;kuleuven.be",
        "position": "PhD student;Full Professor;PhD student",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nUNbjMDBWC",
        "title": "An Incomplete Loop: Instruction Inference, Instruction Following, and In-Context Learning in Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "inductive reasoning;deductive reasoning;abductive reasoning;self-guided reasoning;hypothesis proposal",
        "primary_area": "",
        "author": "Emmy Liu;Graham Neubig;Jacob Andreas",
        "authorids": "~Emmy_Liu1;~Graham_Neubig1;~Jacob_Andreas1",
        "aff": "Microsoft;School of Computer Science, Carnegie Mellon University;Carnegie Mellon University",
        "aff_domain": "cmu.edu;cs.cmu.edu;microsoft.com",
        "position": "PhD student;Associate Professor;Researcher",
        "rating": "",
        "confidence": "4;4;2;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nXNN0x4wbl",
        "title": "Instruction-tuning Aligns LLMs to the Human Brain",
        "track": "main",
        "status": "Accept",
        "keywords": "fMRI;brain;neuroscience;neuroAI;large language models",
        "primary_area": "",
        "author": "Khai Loong Aw;Syrielle Montariol;Badr AlKhamissi;Martin Schrimpf;Antoine Bosselut",
        "authorids": "~Khai_Loong_Aw1;~Syrielle_Montariol1;~Badr_AlKhamissi1;~Martin_Schrimpf1;~Antoine_Bosselut1",
        "aff": "EPFL - EPF Lausanne;Swiss Federal Institute of Technology Lausanne;Facebook;Singapore Management University;Massachusetts Institute of Technology",
        "aff_domain": "smu.edu.sg;epfl.ch;fb.com;mit.edu",
        "position": "Assistant Professor;Researcher;Undergrad student;Researcher;Postdoc",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ndY9qFf9Sa",
        "title": "AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts",
        "track": "main",
        "status": "Accept",
        "keywords": "Low-Rank Adaptation;Mixture of Experts;Adaptive Expert Selection;Parameter-Efficient Fine-Tuning;Large Language Models",
        "primary_area": "",
        "author": "Zefang Liu;Jiahua Luo",
        "authorids": "~Zefang_Liu1;~Jiahua_Luo1",
        "aff": "Georgia Institute of Technology;University of Macau",
        "aff_domain": "umac.mo;gatech.edu",
        "position": "Principal Researcher;Researcher",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nqLAuMOF6n",
        "title": "Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM",
        "track": "main",
        "status": "Accept",
        "keywords": "mixture of experts;continued pretraining",
        "primary_area": "",
        "author": "Sainbayar Sukhbaatar;Olga Golovneva;Vasu Sharma;Hu Xu;Xi Victoria Lin;Baptiste Roziere;Jacob Kahn;Shang-Wen Li;Wen-tau Yih;Jason E Weston;Xian Li",
        "authorids": "~Sainbayar_Sukhbaatar1;~Olga_Golovneva1;~Vasu_Sharma1;~Hu_Xu1;~Xi_Victoria_Lin1;~Baptiste_Roziere1;~Jacob_Kahn1;~Shang-Wen_Li1;~Wen-tau_Yih1;~Jason_E_Weston1;~Xian_Li1",
        "aff": "Meta AI;Department of Computer Science, University of Washington;Facebook;Meta Platforms, Inc.;FAIR, Multimodal Foundation;Facebook AI",
        "aff_domain": "cs.washington.edu;meta.com;fb.com",
        "position": "Researcher;Research Scientist;Research Engineer;Researcher;Research Scientist;Research Manager;Researcher;Research Scientist;PhD student;Principal Researcher",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oRXPiSOGH9",
        "title": "Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking",
        "track": "main",
        "status": "Accept",
        "keywords": "reasoning;internal monologue",
        "primary_area": "",
        "author": "Eric Zelikman;Georges Raif Harik;Yijia Shao;Varuna Jayasiri;Nick Haber;Noah Goodman",
        "authorids": "~Eric_Zelikman1;~Georges_Raif_Harik1;~Yijia_Shao1;~Varuna_Jayasiri1;~Nick_Haber1;~Noah_Goodman1",
        "aff": "Peking University;Stanford University;Google",
        "aff_domain": "pku.edu.cn;stanford.edu;google.com",
        "position": "Research Intern;Assistant Professor;Associate Professor;Undergrad student",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oRcYFm8vyB",
        "title": "Logits of API-Protected LLMs Leak Proprietary Information",
        "track": "main",
        "status": "Accept",
        "keywords": "softmax bottleneck;model stealing;API;language models;large language models",
        "primary_area": "",
        "author": "Matthew Finlayson;Xiang Ren;Swabha Swayamdipta",
        "authorids": "~Matthew_Finlayson1;~Xiang_Ren1;~Swabha_Swayamdipta1",
        "aff": "Allen Institute for Artificial Intelligence;University of Southern California",
        "aff_domain": "usc.edu;allenai.org",
        "position": "Researcher;Assistant Professor;Associate Professor",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oSG6qGkt1I",
        "title": "Reasoning about concepts with LLMs: Inconsistencies abound",
        "track": "main",
        "status": "Accept",
        "keywords": "KG reasoning in LLMs;LLM consistency;Synthetic data generation for LLM evaluation;RAG;prompt engineering;",
        "primary_area": "",
        "author": "Rosario Uceda Sosa;Karthikeyan Natesan Ramamurthy;Maria Chang;Moninder Singh",
        "authorids": "~Rosario_Uceda_Sosa1;~Karthikeyan_Natesan_Ramamurthy1;~Maria_Chang1;~Moninder_Singh1",
        "aff": "International Business Machines",
        "aff_domain": "ibm.com",
        "position": "Research Staff Member;Researcher;Software Engineer;Research Staff Member",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ootI3ZO6TJ",
        "title": "PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "toxicity;evaluation;multilingual;large language models",
        "primary_area": "",
        "author": "Devansh Jain;Priyanshu Kumar;Samuel Gehman;Xuhui Zhou;Thomas Hartvigsen;Maarten Sap",
        "authorids": "~Devansh_Jain1;~Priyanshu_Kumar1;~Samuel_Gehman1;~Xuhui_Zhou1;~Thomas_Hartvigsen1;~Maarten_Sap1",
        "aff": "BITS Pilani, BITS Pilani;CMU, Carnegie Mellon University;Independent;Carnegie Mellon University;Massachusetts Institute of Technology",
        "aff_domain": "andrew.cmu.edu;pilani.bits-pilani.ac.in;mit.edu;cmu.edu;samgehman.com",
        "position": "Assistant Professor;MS student;Researcher;Postdoc;PhD student;Undergrad student",
        "rating": "",
        "confidence": "2;4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.4,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oqYiYG8PtY",
        "title": "Stop Reasoning! When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image",
        "track": "main",
        "status": "Accept",
        "keywords": "Multimodal LLMs;Adversarial Robustness;Vision Language Models;Chain-of-thought",
        "primary_area": "",
        "author": "Zefeng Wang;Zhen Han;Shuo Chen;Fan Xue;Zifeng Ding;Xun Xiao;Volker Tresp;Philip Torr;Jindong Gu",
        "authorids": "~Zefeng_Wang1;~Zhen_Han3;~Shuo_Chen12;~Fan_Xue1;~Zifeng_Ding1;~Xun_Xiao1;~Volker_Tresp1;~Philip_Torr1;~Jindong_Gu1",
        "aff": "University of Oxford;Technische Universit\u00e4t M\u00fcnchen;Amazon;University of Munich, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen;LMU Munich;Siemens Corporate Research",
        "aff_domain": "amazon.com;siemens.com;ox.ac.uk;campus.lmu.de;lmu.de;tum.edu;tum.de",
        "position": "MS student;Full Professor;MS student;Principal Researcher;MS student;Researcher;PhD student",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "otKo4zFKmH",
        "title": "Task Success is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors",
        "track": "main",
        "status": "Accept",
        "keywords": "Vision language model;VLMs;LLMs;embodied AI;AI agent;AI critiques;robotics",
        "primary_area": "",
        "author": "Lin Guan;Yifan Zhou;Denis Liu;Yantian Zha;Heni Ben Amor;Subbarao Kambhampati",
        "authorids": "~Lin_Guan1;~Yifan_Zhou4;~Denis_Liu1;~Yantian_Zha1;~Heni_Ben_Amor4;~Subbarao_Kambhampati1",
        "aff": "Arizona State University",
        "aff_domain": "asu.edu",
        "position": "Undergrad student;PhD student;Full Professor;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "5;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pKMxO0wBYZ",
        "title": "Web Retrieval Agents for Evidence-Based Misinformation Detection",
        "track": "main",
        "status": "Accept",
        "keywords": "Retrieval Augmented Generation;Information Retrieval;Misinformation Detection;LLM;Web-Browsing Agents",
        "primary_area": "",
        "author": "Jacob-Junqi Tian;Hao Yu;Yury Orlovskiy;Tyler Vergho;Mauricio Rivera;Mayank Goel;Zachary Yang;Jean-Fran\u00e7ois Godbout;Reihaneh Rabbany;Kellin Pelrine",
        "authorids": "~Jacob-Junqi_Tian1;~Hao_Yu15;~Yury_Orlovskiy1;~Tyler_Vergho1;~Mauricio_Rivera1;~Mayank_Goel3;~Zachary_Yang1;~Jean-Fran\u00e7ois_Godbout1;~Reihaneh_Rabbany1;~Kellin_Pelrine1",
        "aff": "Universit\u00e9 de Montr\u00e9al;Department of Computer Science, Dartmouth College;University of California, Berkeley;International Institute of Information Technology, Hyderabad, International Institute of Information Technology Hyderabad;McGill University;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal;McGill University, McGill University",
        "aff_domain": "mail.mcgill.ca;mcgill.ca;cs.dartmouth.edu;berkeley.edu;umontreal.ca;research.iiit.ac.in;mila.umontreal.ca;cs.mcgill.ca",
        "position": "Undergrad student;Full Professor;PhD student;Undergrad student;Undergrad student;Assistant Professor;MS student;Undergrad student;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pUEDkZyPDl",
        "title": "DISTFLASHATTN: Distributed Memory-efficient Attention for Long-context LLMs Training",
        "track": "main",
        "status": "Accept",
        "keywords": "Distributed system;memory efficient exact attention;long context;large language model",
        "primary_area": "",
        "author": "Dacheng Li;Rulin Shao;Anze Xie;Eric P. Xing;Xuezhe Ma;Ion Stoica;Joseph E. Gonzalez;Hao Zhang",
        "authorids": "~Dacheng_Li1;~Rulin_Shao1;~Anze_Xie1;~Eric_Xing1;~Xuezhe_Ma1;~Ion_Stoica1;~Joseph_E._Gonzalez1;~Hao_Zhang2",
        "aff": "UC Berkeley, University of California Berkeley;University of Washington;University of California, Berkeley;USC/ISI;School of Computer Science, Carnegie Mellon University",
        "aff_domain": "berkeley.edu;cs.berkeley.edu;isi.edu;cs.cmu.edu;uw.edu",
        "position": "Full Professor;Postdoc;Full Professor;Assistant Professor;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pYEnhZ6NAv",
        "title": "How Far Are We from Intelligent Visual Deductive Reasoning?",
        "track": "main",
        "status": "Accept",
        "keywords": "Vision Language Model;Reasoning",
        "primary_area": "",
        "author": "Yizhe Zhang;Richard He Bai;Ruixiang ZHANG;Jiatao Gu;Shuangfei Zhai;Joshua M. Susskind;Navdeep Jaitly",
        "authorids": "~Yizhe_Zhang2;~Richard_He_Bai1;~Ruixiang_ZHANG1;~Jiatao_Gu1;~Shuangfei_Zhai3;~Joshua_M._Susskind1;~Navdeep_Jaitly1",
        "aff": "Apple;University of Waterloo;Mila, UdeM;Apple (MLR)",
        "aff_domain": "mila.qubec;uwaterloo.ca;apple.com",
        "position": "Machine Learning Researcher;Research Scientist;Researcher;PhD student;Research Scientist;Researcher;PhD student",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ptvV5HGTNN",
        "title": "Resolving Knowledge Conflicts in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "knowledge conflict;parametric knowledge;external knowledge",
        "primary_area": "",
        "author": "Yike Wang;Shangbin Feng;Heng Wang;Weijia Shi;Vidhisha Balachandran;Tianxing He;Yulia Tsvetkov",
        "authorids": "~Yike_Wang1;~Shangbin_Feng1;~Heng_Wang10;~Weijia_Shi1;~Vidhisha_Balachandran1;~Tianxing_He1;~Yulia_Tsvetkov1",
        "aff": "University of Washington, Seattle;Department of Computer Science, University of Washington;University of Washington;University of California, Berkeley;Xi'an Jiaotong University;Carnegie Mellon University",
        "aff_domain": "cmu.edu;berkeley.edu;xjtu.edu.cn;cs.washington.edu;uw.edu",
        "position": "Undergrad student;PhD student;Postdoc;PhD student;PhD student;Undergrad student;Assistant Professor",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "q36rpGlG9X",
        "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation",
        "track": "main",
        "status": "Accept",
        "keywords": "large language models;biomedicine;scientific discovery;zero-shot;multi-agent",
        "primary_area": "",
        "author": "Biqing Qi;Kaiyan Zhang;Kai Tian;Haoxiang Li;Zhang-Ren Chen;Sihang Zeng;Ermo Hua;Hu Jinfang;Bowen Zhou",
        "authorids": "~Biqing_Qi1;~Kaiyan_Zhang1;~Kai_Tian3;~Haoxiang_Li3;~Zhang-Ren_Chen1;~Sihang_Zeng1;~Ermo_Hua1;~Hu_Jinfang1;~Bowen_Zhou8",
        "aff": "Tsinghua University, Tsinghua University;Electronic Engineering, Tsinghua University;Nanchang University;Harbin Institute of Technology;Tsinghua University;Electronic Engineering, Tsinghua University, Tsinghua University",
        "aff_domain": "hit.edu.cn;tsinghua.edu.cn;ncu.edu.cn;mails.tsinghua.edu.cn;mail.tsinghua.edu.cn",
        "position": "PhD student;Full Professor;PhD student;Undergrad student;Full Professor;MS student;PhD student;Undergrad student;Researcher",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "q5Ft9ZJtHm",
        "title": "ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs",
        "track": "main",
        "status": "Accept",
        "keywords": "large language models;social bias;synthetic data generation;debiasing",
        "primary_area": "",
        "author": "Pengrui Han;Rafal Dariusz Kocielnik;Adhithya Prakash Saravanan;Roy Luoyao Jiang;Or Sharir;Anima Anandkumar",
        "authorids": "~Pengrui_Han1;~Rafal_Dariusz_Kocielnik1;~Adhithya_Prakash_Saravanan1;~Roy_Luoyao_Jiang1;~Or_Sharir1;~Anima_Anandkumar1",
        "aff": "Carleton College;University of California, Irvine;University of Cambridge;California Institute of Technology",
        "aff_domain": "carleton.edu;uci.edu;caltech.edu;cam.ac.uk",
        "position": "MS student;Postdoc;Undergrad student;Postdoc;Undergrad student;Associate Professor",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qHdSA85GyZ",
        "title": "Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think",
        "track": "main",
        "status": "Accept",
        "keywords": "Robustness;LLM Evaluation;Multiple-Choice Question",
        "primary_area": "",
        "author": "Xinpeng Wang;Chengzhi Hu;Bolei Ma;Paul Rottger;Barbara Plank",
        "authorids": "~Xinpeng_Wang3;~Chengzhi_Hu1;~Bolei_Ma1;~Paul_Rottger1;~Barbara_Plank2",
        "aff": "Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen;IT University of Copenhagen;University of Oxford",
        "aff_domain": "itu.dk;ox.ac.uk;lmu.de",
        "position": "Full Professor;MS student;Undergrad student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qyilOnIRHI",
        "title": "Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns to Model Representations",
        "track": "main",
        "status": "Accept",
        "keywords": "language models;neural embeddings;optimization;implicit regularization;low-rank matrix factorization;support-vector machines",
        "primary_area": "",
        "author": "Yize Zhao;Tina Behnia;Vala Vakilian;Christos Thrampoulidis",
        "authorids": "~Yize_Zhao2;~Tina_Behnia1;~Vala_Vakilian2;~Christos_Thrampoulidis1",
        "aff": "University of British Columbia",
        "aff_domain": "ubc.ca",
        "position": "Assistant Professor;MS student;MS student;MS student",
        "rating": "",
        "confidence": "3;2;1;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 2.4,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rXEwxmnGQs",
        "title": "PhonATe: Impact of Type-Written Phonological Features of African American Language on Generative Language Modeling Tasks",
        "track": "main",
        "status": "Accept",
        "keywords": "data augmentation;african american language;bias and fairness;language generation",
        "primary_area": "",
        "author": "Nicholas Deas;Jessica A Grieser;Xinmeng Hou;Shana Kleiner;Tajh Martin;Sreya Nandanampati;Desmond U. Patton;Kathleen McKeown",
        "authorids": "~Nicholas_Deas1;~Jessica_A_Grieser1;~Xinmeng_Hou1;~Shana_Kleiner1;~Tajh_Martin1;~Sreya_Nandanampati1;~Desmond_U._Patton1;~Kathleen_McKeown1",
        "aff": "Columbia University;University of Michigan - Ann Arbor;University of Pennsylvania, University of Pennsylvania",
        "aff_domain": "upenn.edu;columbia.edu;umich.edu",
        "position": "Associate Professor;PhD student;Researcher;Undergrad student;MS student",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rzQGHXNReU",
        "title": "RAFT: Adapting Language Model to Domain Specific RAG",
        "track": "main",
        "status": "Accept",
        "keywords": "Retriever; Finetuning",
        "primary_area": "",
        "author": "Tianjun Zhang;Shishir G Patil;Naman Jain;Sheng Shen;Matei Zaharia;Ion Stoica;Joseph E. Gonzalez",
        "authorids": "~Tianjun_Zhang1;~Shishir_G_Patil1;~Naman_Jain2;~Sheng_Shen2;~Matei_Zaharia1;~Ion_Stoica1;~Joseph_E._Gonzalez1",
        "aff": "University of California, Berkeley;Stanford University;University of California Berkeley;UC Berkeley, University of California Berkeley",
        "aff_domain": "berkeley.edu;cs.berkeley.edu;stanford.edu",
        "position": "Full Professor;Assistant Professor;Associate Professor;PhD student;PhD student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;5;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sBxvoDhvao",
        "title": "Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP",
        "track": "main",
        "status": "Accept",
        "keywords": "vocabulary transfer;transfer learning;cross-lingual;low-resource languages;large language models",
        "primary_area": "",
        "author": "Fran\u00e7ois Remy;Pieter Delobelle;Hayastan Avetisyan;Alfiya Khabibullina;Miryam de Lhoneux;Thomas Demeester",
        "authorids": "~Fran\u00e7ois_Remy1;~Pieter_Delobelle1;~Hayastan_Avetisyan1;~Alfiya_Khabibullina1;~Miryam_de_Lhoneux1;~Thomas_Demeester1",
        "aff": "Ghent University - imec;German Centre for Higher Education Research and Science Studies (DZHW);Universiteit Gent;KU Leuven",
        "aff_domain": "dzhw.eu;cs.kuleuven.be;ugent.be;kuleuven.be",
        "position": "MS student;PhD student;PhD student;Assistant Professor;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sJvhwDtFhQ",
        "title": "TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance",
        "track": "main",
        "status": "Accept",
        "keywords": "Principle discovery;Teacher-student framework;Reasoning",
        "primary_area": "",
        "author": "Haorui Wang;Rongzhi Zhang;Yinghao Li;Lingkai Kong;Yuchen Zhuang;Xiusi Chen;Chao Zhang",
        "authorids": "~Haorui_Wang1;~Rongzhi_Zhang2;~Yinghao_Li3;~Lingkai_Kong1;~Yuchen_Zhuang1;~Xiusi_Chen1;~Chao_Zhang15",
        "aff": "Adobe Systems;Georgia Institute of Technology;University of California, Los Angeles;Zhejiang University",
        "aff_domain": "zju.edu.cn;ucla.edu;adobe.com;gatech.edu",
        "position": "Assistant Professor;PhD student;PhD student;Undergrad student;PhD student;PhD student;Intern",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sKATR2O1Y0",
        "title": "OpenAgents: An Open Platform for Language Agents in the Wild",
        "track": "main",
        "status": "Accept",
        "keywords": "Language Agents; Large Language Models (LLMs); Data Analysis; Web Browsing Automation; API Tools",
        "primary_area": "",
        "author": "Tianbao Xie;Fan Zhou;Zhoujun Cheng;Peng Shi;Luoxuan Weng;Yitao Liu;Toh Jing Hua;Junning Zhao;Qian Liu;Che Liu;Zeyu Liu;Yiheng Xu;Hongjin SU;Dongchan Shin;Caiming Xiong;Tao Yu",
        "authorids": "~Tianbao_Xie1;~Fan_Zhou6;~Zhoujun_Cheng1;~Peng_Shi2;~Luoxuan_Weng1;~Yitao_Liu2;~Toh_Jing_Hua1;~Junning_Zhao1;~Qian_Liu2;~Che_Liu7;~Zeyu_Liu1;~Yiheng_Xu1;~Hongjin_SU1;~Dongchan_Shin1;~Caiming_Xiong1;~Tao_Yu5",
        "aff": "Salesforce Research;University of Washington, Seattle;Shanghai Jiaotong University;Tokyo Institute of Technology, Tokyo Institute of Technology;Sea AI Lab;The University of Hong Kong;Nanyang Technological University;the University of Hong Kong, University of Hong Kong;Zhejiang University;Shanghai Jiao Tong University;University of Waterloo;University of Hong Kong",
        "aff_domain": "sea.com;hku.hk;ntu.edu.sg;salesforce.com;uwaterloo.ca;titech.ac.jp;cs.hku.hk;uw.edu;sjtu.edu.cn;zju.edu.cn",
        "position": "Research Scientist;Undergrad student;Undergrad student;MS student;PhD student;Undergrad student;PhD student;PhD student;Researcher;Assistant Professor;PhD student;Undergrad student;Undergrad student;MS student;MS student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sKNIjS2brr",
        "title": "VideoDirectorGPT: Consistent Multi-Scene Video Generation via LLM-Guided Planning",
        "track": "main",
        "status": "Accept",
        "keywords": "Text-to-Video Generation;Large Language Models;Layout-Guided Video Generation;Temporal Consistency;Multi-Scene Video Generation;Layout Control",
        "primary_area": "",
        "author": "Han Lin;Abhay Zala;Jaemin Cho;Mohit Bansal",
        "authorids": "~Han_Lin1;~Abhay_Zala1;~Jaemin_Cho1;~Mohit_Bansal2",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill;University of North Carolina at Chapel Hill;University of North Carolina, Chapel Hill",
        "aff_domain": "cs.unc.edu;unc.edu",
        "position": "MS student;PhD student;PhD student;Full Professor",
        "rating": "",
        "confidence": "3;2;5;3;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "soGxskHGox",
        "title": "Linearizing Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "linear attention;efficient attention;RNN",
        "primary_area": "",
        "author": "Jean Mercat;Igor Vasiljevic;Sedrick Scott Keh;Kushal Arora;Achal Dave;Adrien Gaidon;Thomas Kollar",
        "authorids": "~Jean_Mercat1;~Igor_Vasiljevic1;~Sedrick_Scott_Keh1;~Kushal_Arora1;~Achal_Dave1;~Adrien_Gaidon1;~Thomas_Kollar1",
        "aff": "Amazon;McGill University;Toyota Research Institute;Toyota Research Institute (TRI)",
        "aff_domain": "tri.global;mcgill.ca;amazon.com",
        "position": "Researcher;Senior Manager;Research Scientist;Researcher;PhD student;AI Resident;Principal Researcher",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "soz1SEiPeq",
        "title": "Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence",
        "track": "main",
        "status": "Accept",
        "keywords": "large language model;scaling laws;open source;pretraining;RNN",
        "primary_area": "",
        "author": "Bo Peng;Daniel Goldstein;Quentin Gregory Anthony;Alon Albalak;Eric Alcaide;Stella Biderman;Eugene Cheah;Teddy Ferdinan;Kranthi Kiran GV;Haowen Hou;Satyapriya Krishna;Ronald McClelland Jr.;Niklas Muennighoff;Fares Obeid;Atsushi Saito;Guangyu Song;Haoqin Tu;Ruichong Zhang;Bingchen Zhao;Qihang Zhao;Jian Zhu;Rui-Jie Zhu",
        "authorids": "~Bo_Peng21;~Daniel_Goldstein2;~Quentin_Gregory_Anthony1;~Alon_Albalak1;~Eric_Alcaide2;~Stella_Biderman1;~Eugene_Cheah1;~Teddy_Ferdinan1;~Kranthi_Kiran_GV1;~Haowen_Hou1;~Satyapriya_Krishna2;~Ronald_McClelland_Jr.1;~Niklas_Muennighoff1;~Fares_Obeid1;~Atsushi_Saito1;~Guangyu_Song1;~Haoqin_Tu1;~Ruichong_Zhang1;~Bingchen_Zhao1;~Qihang_Zhao2;~Jian_Zhu2;~Rui-Jie_Zhu2",
        "aff": "University of Edinburgh, University of Edinburgh;Grand Canyon University;Technical University of Wroclaw;University of Chinese Academy of Sciences;New York University;Tsinghua University, Tsinghua University;Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ);Harvard University;Hugging Face;Ohio State University, Columbus;University of California, Santa Barbara;Booz Allen Hamilton;University of British Columbia;University of Hong Kong;University of Electronic Science and Technology of China",
        "aff_domain": "nyu.edu;uestc.edu.cn;pwr.edu.pl;tsinghua.edu.cn;osu.edu;boozallen.com;ubc.ca;gml.ac.cn;gcu.edu;ed.ac.uk;gmail.com;ucas.ac.cn;ucsb.edu;hku.hk;harvard.edu",
        "position": "PhD student;PhD student;Undergrad student;MS student;Assistant Professor;MS student;Researcher;PhD student;Undergrad student;Undergrad student;Undergrad student;PhD student;Industry researcher;MS student;Associate Research Scientist",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "stmqBSW2dV",
        "title": "V-STaR: Training Verifiers for Self-Taught Reasoners",
        "track": "main",
        "status": "Accept",
        "keywords": "Large Language Model;Self-improvement;Reasoning;verifier",
        "primary_area": "",
        "author": "Arian Hosseini;Xingdi Yuan;Nikolay Malkin;Aaron Courville;Alessandro Sordoni;Rishabh Agarwal",
        "authorids": "~Arian_Hosseini1;~Xingdi_Yuan2;~Nikolay_Malkin1;~Aaron_Courville3;~Alessandro_Sordoni2;~Rishabh_Agarwal2",
        "aff": "Microsoft;Universit\u00e9 de Montr\u00e9al;Google DeepMind;Microsoft Research;Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal",
        "aff_domain": "microsoft.com; ;mila.umontreal.ca;google.com",
        "position": "Assistant Professor;PhD student;Research Scientist;Researcher;Senior Researcher",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "t3z6UlV09o",
        "title": "How bad is training on synthetic data? A statistical analysis of language model collapse",
        "track": "main",
        "status": "Accept",
        "keywords": "model collapse;recursive training;generative models",
        "primary_area": "",
        "author": "Mohamed El Amine Seddik;Suei-Wen Chen;Soufiane Hayou;Pierre Youssef;Merouane Abdelkader DEBBAH",
        "authorids": "~Mohamed_El_Amine_Seddik1;~Suei-Wen_Chen1;~Soufiane_Hayou1;~Pierre_Youssef1;~Merouane_Abdelkader_DEBBAH1",
        "aff": "Technology Innovation Institute;New York University;Huawei Technologies Ltd.;National University of Singapore;New York University, Abu Dhabi",
        "aff_domain": "nyu.edu;tii.ae;nus.edu.sg;huawei.com;nyuad.nyu.edu",
        "position": "Full Professor;Researcher;Associate Professor;Assistant Professor;Undergrad student",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "t4eB3zYWBK",
        "title": "MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries",
        "track": "main",
        "status": "Accept",
        "keywords": "Retrieval-Augmented Generation; Benchmark; Multi-Hop Reasoning",
        "primary_area": "",
        "author": "Yixuan Tang;Yi Yang",
        "authorids": "~Yixuan_Tang2;~Yi_Yang7",
        "aff": "Hong Kong University of Science and Technology",
        "aff_domain": "ust.hk",
        "position": "Assistant Professor",
        "rating": "",
        "confidence": "5;3;5;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tEYskw1VY2",
        "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
        "track": "main",
        "status": "Accept",
        "keywords": "sequence model;deep learning;state space model;S4;Mamba",
        "primary_area": "",
        "author": "Albert Gu;Tri Dao",
        "authorids": "~Albert_Gu1;~Tri_Dao1",
        "aff": "Stanford University;Carnegie Mellon University",
        "aff_domain": "cmu.edu;stanford.edu",
        "position": "Assistant Professor;PhD student",
        "rating": "",
        "confidence": "5;5;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tIpWtMYkzU",
        "title": "Trust No Bot: Discovering Personal Disclosures in Human-LLM Conversations in the Wild",
        "track": "main",
        "status": "Accept",
        "keywords": "privacy;trust;human-computer interaction;data",
        "primary_area": "",
        "author": "Niloofar Mireshghallah;Maria Antoniak;Yash More;Yejin Choi;Golnoosh Farnadi",
        "authorids": "~Niloofar_Mireshghallah1;~Maria_Antoniak1;~Yash_More1;~Yejin_Choi1;~Golnoosh_Farnadi1",
        "aff": "University of California, San Diego;Department of Computer Science, University of Washington;Allen Institute for Artificial Intelligence;Montreal Institute for Learning Algorithms, University of Montreal, Universit\u00e9 de Montr\u00e9al",
        "aff_domain": "cs.washington.edu;allenai.org;mila.umontreal.ca;ucsd.edu",
        "position": "Postdoc;MS student;Professor;PhD student",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tRxIB7y3wF",
        "title": "LalaEval: A Holistic Human Evaluation Framework for Domain-Specific Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "Domain-Specific Large Language Model;Human Evaluation;Holistic Framework;End-to-end Protocol;Logistic Industry",
        "primary_area": "",
        "author": "Chongyan Sun;Ken Lin;Shiwei Wang;Hulong Wu;Chengfei Fu;Zhen Wang",
        "authorids": "~Chongyan_Sun1;~Ken_Lin2;~Shiwei_Wang5;~Hulong_Wu1;~Chengfei_Fu1;~Zhen_Wang34",
        "aff": "Tencent;Huolala;The Chinese University of Hong Kong",
        "aff_domain": "tencent.cn;cuhk.edu.hk;huolala.cn",
        "position": "Researcher;PhD student;Researcher;Researcher;Researcher;Researcher",
        "rating": "",
        "confidence": "4;3;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.4,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "taThoOlDNQ",
        "title": "Exploring the Mystery of Influential Data for Mathematical Reasoning",
        "track": "main",
        "status": "Accept",
        "keywords": "Influential Data Composition;Mathematical Reasoning",
        "primary_area": "",
        "author": "Xinzhe Ni;Yeyun Gong;Zhibin Gou;yelong shen;Yujiu Yang;Nan Duan;Weizhu Chen",
        "authorids": "~Xinzhe_Ni1;~Yeyun_Gong2;~Zhibin_Gou1;~yelong_shen1;~Yujiu_Yang2;~Nan_Duan1;~Weizhu_Chen1",
        "aff": "Microsoft;Microsoft Research Asia;Tsinghua University;Graduate School at Shenzhen,Tsinghua University;Microsoft GenAI",
        "aff_domain": "tsinghua.edu.cn;microsoft.com",
        "position": "Principal Researcher;Vice President;MS student;Associate Professor;Intern",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tzE7VqsaJ4",
        "title": "RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation",
        "track": "main",
        "status": "Accept",
        "keywords": "retrieval augmented generation;tool learning",
        "primary_area": "",
        "author": "Chi-Min Chan;Chunpu Xu;Ruibin Yuan;Hongyin Luo;Wei Xue;Yike Guo;Jie Fu",
        "authorids": "~Chi-Min_Chan1;~Chunpu_Xu2;~Ruibin_Yuan1;~Hongyin_Luo1;~Wei_Xue5;~Yike_Guo1;~Jie_Fu2",
        "aff": "Beijing Academy of Artificial Intelligence;Hong Kong University of Science and Technology;Imperial College London;Hong Kong Baptist University;Massachusetts Institute of Technology",
        "aff_domain": "baai.ac.cn;mit.edu;ust.hk;hkbu.edu.hk;imperial.ac.uk",
        "position": "Postdoc;Assistant Professor;Full Professor;PhD student;Researcher",
        "rating": "",
        "confidence": "4;5;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "u2vAyMeLMm",
        "title": "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens",
        "track": "main",
        "status": "Accept",
        "keywords": "infini-gram;n-gram;language model;suffix array",
        "primary_area": "",
        "author": "Jiacheng Liu;Sewon Min;Luke Zettlemoyer;Yejin Choi;Hannaneh Hajishirzi",
        "authorids": "~Jiacheng_Liu2;~Sewon_Min1;~Luke_Zettlemoyer1;~Yejin_Choi1;~Hannaneh_Hajishirzi1",
        "aff": "Meta;University of Washington, Seattle;Department of Computer Science, University of Washington;Facebook",
        "aff_domain": "cs.washington.edu;meta.com;uw.edu;fb.com",
        "position": "Assistant Professor;Intern;Researcher;PhD student;Professor",
        "rating": "",
        "confidence": "3;5;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uILyEJGKWw",
        "title": "Does Collaborative Human\u2013LM Dialogue Generation Help Information Extraction from Human\u2013Human Dialogues?",
        "track": "main",
        "status": "Accept",
        "keywords": "Data Synthesis;Data Annotation;Human\u2013LM Collaboration",
        "primary_area": "",
        "author": "Bo-Ru Lu;Nikita Haduong;Chia-Hsuan Lee;Zeqiu Wu;Hao Cheng;Paul Koester;Jean Utke;Tao Yu;Noah A. Smith;Mari Ostendorf",
        "authorids": "~Bo-Ru_Lu1;~Nikita_Haduong1;~Chia-Hsuan_Lee1;~Zeqiu_Wu1;~Hao_Cheng4;~Paul_Koester1;~Jean_Utke1;~Tao_Yu5;~Noah_A._Smith2;~Mari_Ostendorf1",
        "aff": "University of Washington, Seattle;Department of Computer Science, University of Washington;University of Washington;The University of Hong Kong;Allstate;Allstate Insurance;Allen Institute for Artificial Intelligence;Microsoft Research",
        "aff_domain": "allenai.org;u.washington.edu;uw.edu;cs.washington.edu;microsoft.com;allstate.com;hku.hk",
        "position": "PhD student;PhD student;Researcher;Data Scientist / Technical Director;Full Professor;PhD student;Researcher;Assistant Professor;PhD student;Senior Director of NLP Research",
        "rating": "",
        "confidence": "3;4;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uUIFTjBREk",
        "title": "Efficient Hybrid Long Sequence Modeling with State Space Augmented Transformers",
        "track": "main",
        "status": "Accept",
        "keywords": "long sequence;language model",
        "primary_area": "",
        "author": "Simiao Zuo;Xiaodong Liu;Jian Jiao;Denis X Charles;Eren Manavoglu;Tuo Zhao;Jianfeng Gao",
        "authorids": "~Simiao_Zuo1;~Xiaodong_Liu1;~Jian_Jiao2;~Denis_X_Charles1;~Eren_Manavoglu1;~Tuo_Zhao2;~Jianfeng_Gao1",
        "aff": "Microsoft;Microsoft Research;Georgia Institute of Technology",
        "aff_domain": "gatech.edu;microsoft.com",
        "position": "Principal Researcher;Principal Researcher;PhD student;Researcher;Associate Professor",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v3w2a7EInO",
        "title": "CATS: Context-Aware Thresholding for Sparsity in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "efficient inference;sparsity;context-aware inference",
        "primary_area": "",
        "author": "Donghyun Lee;Jaeyong Lee;Genghan Zhang;Mo Tiwari;Azalia Mirhoseini",
        "authorids": "~Donghyun_Lee2;~Jaeyong_Lee1;~Genghan_Zhang1;~Mo_Tiwari1;~Azalia_Mirhoseini1",
        "aff": "University of Oxford;Electronic Engineering, Tsinghua University, Tsinghua University;University College London, University of London",
        "aff_domain": "mails.tsinghua.edu.cn;ucl.ac.uk;oxford.ac.uk",
        "position": "Undergrad student;Undergrad student;Undergrad student",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v74mJURD1L",
        "title": "Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data",
        "track": "main",
        "status": "Accept",
        "keywords": "RLHF;Reward Modeling;Data Poisoning;Safety",
        "primary_area": "",
        "author": "Tim Baumg\u00e4rtner;Yang Gao;Dana Alon;Donald Metzler",
        "authorids": "~Tim_Baumg\u00e4rtner1;~Yang_Gao6;~Dana_Alon1;~Donald_Metzler1",
        "aff": "Google;Research, Google",
        "aff_domain": "research.google.com;google.com",
        "position": "Researcher;Research Scientist;Intern;Researcher",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vL8BIGuFTF",
        "title": "Predicting Emergent Capabilities by Finetuning",
        "track": "main",
        "status": "Accept",
        "keywords": "Capability Prediction;Scaling Laws;Emergence",
        "primary_area": "",
        "author": "Charlie Victor Snell;Eric Wallace;Dan Klein;Sergey Levine",
        "authorids": "~Charlie_Victor_Snell1;~Eric_Wallace1;~Dan_Klein1;~Sergey_Levine1",
        "aff": "University of California, Berkeley;University of California Berkeley;Google",
        "aff_domain": "berkeley.edu;google.com",
        "position": "PhD student;Full Professor;PhD student;Research Scientist",
        "rating": "",
        "confidence": "4;5;2;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vwIIAot0ff",
        "title": "Does your data spark joy? Performance gains from domain upsampling at the end of training",
        "track": "main",
        "status": "Accept",
        "keywords": "pretraining data;data mix;data interventions",
        "primary_area": "",
        "author": "Cody Blakeney;Mansheej Paul;Brett W. Larsen;Sean Owen;Jonathan Frankle",
        "authorids": "~Cody_Blakeney1;~Mansheej_Paul1;~Brett_W._Larsen1;~Sean_Owen1;~Jonathan_Frankle1",
        "aff": "Stanford University;Databricks, Databricks;Texas State University;Flatiron Institute;Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;cs.txstate.edu;flatironinstitute.org;stanford.edu;databricks.com",
        "position": "PhD student;PhD student;PhD student;Researcher;Postdoc",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wF6k0aWjAu",
        "title": "Instruction Mining: Instruction Data Selection for Tuning Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "data-centric machine learning;large language models;generative models;language model finetuning",
        "primary_area": "",
        "author": "Yihan Cao;Yanbin Kang;Chi Wang;Lichao Sun",
        "authorids": "~Yihan_Cao1;~Yanbin_Kang1;~Chi_Wang3;~Lichao_Sun1",
        "aff": "CMU, Carnegie Mellon University;Microsoft Research;Lehigh University;LinkedIn",
        "aff_domain": "lehigh.edu;andrew.cmu.edu;linkedin.com;microsoft.com",
        "position": "Principal Researcher;Assistant Professor;Machine Learning Engineer;MS student",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wLQ3I0F1oj",
        "title": "Large Language Model is not a (Multilingual) Compositional Relation Reasoner",
        "track": "main",
        "status": "Accept",
        "keywords": "Benchmarks;Composition Relation",
        "primary_area": "",
        "author": "Jinman Zhao;Xueyan Zhang",
        "authorids": "~Jinman_Zhao2;~Xueyan_Zhang1",
        "aff": "University of Waterloo;Department of Computer Science, University of Toronto",
        "aff_domain": "cs.toronto.edu;uwaterloo.ca",
        "position": "PhD student;MS student",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wS7PxDjy6m",
        "title": "Dated Data: Tracing Knowledge Cutoffs in Large Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "knowledge cutoffs;training data;temporal alignment",
        "primary_area": "",
        "author": "Jeffrey Cheng;Marc Marone;Orion Weller;Dawn Lawrie;Daniel Khashabi;Benjamin Van Durme",
        "authorids": "~Jeffrey_Cheng2;~Marc_Marone1;~Orion_Weller1;~Dawn_Lawrie1;~Daniel_Khashabi2;~Benjamin_Van_Durme2",
        "aff": "Johns Hopkins University;Duke University",
        "aff_domain": "duke.edu;jhu.edu",
        "position": "Assistant Professor;Researcher;Undergrad student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wi9IffRhVM",
        "title": "Guiding Language Model Reasoning with Planning Tokens",
        "track": "main",
        "status": "Accept",
        "keywords": "chain-of-thought reasoning;fine-tuning",
        "primary_area": "",
        "author": "Xinyi Wang;Lucas Caccia;Oleksiy Ostapenko;Xingdi Yuan;William Yang Wang;Alessandro Sordoni",
        "authorids": "~Xinyi_Wang2;~Lucas_Caccia1;~Oleksiy_Ostapenko1;~Xingdi_Yuan2;~William_Yang_Wang2;~Alessandro_Sordoni2",
        "aff": "Microsoft;McGill University;UC Santa Barbara;University of Montreal;Microsoft Research",
        "aff_domain": "umontreal.ca;mcgill.ca;ucsb.edu;microsoft.com",
        "position": "PhD student;PhD student;PhD student;Researcher;Full Professor;Senior Researcher",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wps3p2cqrA",
        "title": "How Well Do LLMs Identify Cultural Unity in Diversity?",
        "track": "main",
        "status": "Accept",
        "keywords": "Cultural Unity;LLM Evaluation;Cross-cultural Association;Benchmark",
        "primary_area": "",
        "author": "Jialin Li;Junli Wang;Junjie Hu;Ming Jiang",
        "authorids": "~Jialin_Li4;~Junli_Wang1;~Junjie_Hu2;~Ming_Jiang6",
        "aff": "Tongji University;University of Wisconsin, Madison",
        "aff_domain": "tongji.edu.cn;wisc.edu",
        "position": "MS student;Associate Professor;Assistant Professor",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xI8C7sfN1H",
        "title": "Factual and Tailored Recommendation Endorsements using Language Models and Reinforcement Learning",
        "track": "main",
        "status": "Accept",
        "keywords": "Large language model;reinforcement learning;conversational recommender systems;recommender systems",
        "primary_area": "",
        "author": "Jihwan Jeong;Yinlam Chow;Guy Tennenholtz;ChihWei Hsu;Mohammad Ghavamzadeh;Craig Boutilier",
        "authorids": "~Jihwan_Jeong1;~Yinlam_Chow1;~Guy_Tennenholtz4;~ChihWei_Hsu2;~Mohammad_Ghavamzadeh2;~Craig_Boutilier2",
        "aff": "Google AI;Google;Google Research",
        "aff_domain": "google.com",
        "position": "Software Engineer;Principal Researcher;Intern;Research Scientist;Researcher;Senior Staff Research Scientist",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xMt9kCv5YR",
        "title": "Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game",
        "track": "main",
        "status": "Accept",
        "keywords": "Opinion Leadership;Large Language Models;Werewolf Game;Simulation;Human-AI Interaction",
        "primary_area": "",
        "author": "Silin Du;Xiaowei Zhang",
        "authorids": "~Silin_Du1;~Xiaowei_Zhang8",
        "aff": "Tsinghua University, Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn",
        "position": "PhD student;PhD student",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xS6zx1aBI9",
        "title": "CLIN: A Continually Learning Language Agent for Rapid Task Adaptation and Generalization",
        "track": "main",
        "status": "Accept",
        "keywords": "Language Agents;Memory;Causal Abstraction;Continual Learning;Memory-augmented Agents;Task Adaptation;Text-based Simulator;Virtual Environment",
        "primary_area": "",
        "author": "Bodhisattwa Prasad Majumder;Bhavana Dalvi Mishra;Peter Jansen;Oyvind Tafjord;Niket Tandon;Li Zhang;Chris Callison-Burch;Peter Clark",
        "authorids": "~Bodhisattwa_Prasad_Majumder1;~Bhavana_Dalvi_Mishra2;~Peter_Jansen1;~Oyvind_Tafjord2;~Niket_Tandon2;~Li_Zhang22;~Chris_Callison-Burch1;~Peter_Clark1",
        "aff": "University of California, San Diego;University of Arizona;Allen Institute for Artificial Intelligence;University of Pennsylvania",
        "aff_domain": "upenn.edu;allenai.org;ucsd.edu;arizona.edu",
        "position": "PhD student;Associate Professor;PhD student;Researcher;Researcher;Senior Research Manager;Assistant Professor;Lead Reserarch Scientist",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xWYRL1eR74",
        "title": "FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers",
        "track": "main",
        "status": "Accept",
        "keywords": "prompt optimization;zero-shot methods;prompt discovery;knowledge transfer;textual embeddings;embedding alignment",
        "primary_area": "",
        "author": "Joshua Nathaniel Williams;J Zico Kolter",
        "authorids": "~Joshua_Nathaniel_Williams1;~J_Zico_Kolter1",
        "aff": "Bosch;Carnegie Mellon University",
        "aff_domain": "cmu.edu;bosch.com",
        "position": "PhD student;Chief Scientist of AI Research",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xdg4CS5mkl",
        "title": "Investigating Instruction Tuning Large Language Models on Graphs",
        "track": "main",
        "status": "Accept",
        "keywords": "instruction tuning;graph understanding;dataset;graph representation",
        "primary_area": "",
        "author": "Kerui Zhu;Bo-Wei Huang;Bowen Jin;Yizhu Jiao;Ming Zhong;Kevin Chang;Shou-De Lin;Jiawei Han",
        "authorids": "~Kerui_Zhu1;~Bo-Wei_Huang1;~Bowen_Jin1;~Yizhu_Jiao1;~Ming_Zhong2;~Kevin_Chang1;~Shou-De_Lin1;~Jiawei_Han1",
        "aff": "University of Illinois Urbana Champaign;Department of computer science and informational engineering, National Taiwan University;National Taiwan University;UIUC;University of Illinois, Urbana Champaign;University of Illinois at Urbana-Champaign",
        "aff_domain": "ntu.edu.tw;illinois.edu;csie.ntu.edu.tw",
        "position": "MS student;PhD student;MS student;Full Professor;PhD student;Full Professor;PhD student",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xm8zYRfrqE",
        "title": "Studying Large Language Model Behaviors Under Context-Memory Conflicts With Real Documents",
        "track": "main",
        "status": "Accept",
        "keywords": "large language model;retrieval augmentation;knowledge conflict",
        "primary_area": "",
        "author": "Evgenii Kortukov;Alexander Rubinstein;Elisa Nguyen;Seong Joon Oh",
        "authorids": "~Evgenii_Kortukov1;~Alexander_Rubinstein1;~Elisa_Nguyen1;~Seong_Joon_Oh1",
        "aff": "Eberhard-Karls-Universit\u00e4t T\u00fcbingen",
        "aff_domain": "uni-tuebingen.de",
        "position": "PhD student;PhD student;MS student;Assistant Professor",
        "rating": "",
        "confidence": "5;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y6SqbJfCSk",
        "title": "HGRN2: Gated Linear RNNs with State Expansion",
        "track": "main",
        "status": "Accept",
        "keywords": "linear attention;long convolution;linear RNN;Efficient LM;Linear complexity",
        "primary_area": "",
        "author": "Zhen Qin;Songlin Yang;Weixuan Sun;Xuyang Shen;Dong Li;Weigao Sun;Yiran Zhong",
        "authorids": "~Zhen_Qin6;~Songlin_Yang1;~Weixuan_Sun1;~Xuyang_Shen1;~Dong_Li11;~Weigao_Sun1;~Yiran_Zhong1",
        "aff": "Shanghai Artificial Intelligence Laboratory;Australian National University;ShanghaiTech University;Sensetime;Sensetime Research;Shanghai AI Lab",
        "aff_domain": "org.cn;shlab.org.cn;shanghaitech.edu.cn;anu.edu.au;sensetime.com;pjlab.org.cn",
        "position": "Researcher;MS student;Researcher;PhD student;Researcher;PI;Researcher",
        "rating": "",
        "confidence": "2;3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y6aGT625Lk",
        "title": "PairEval: Open-domain Dialogue Evaluation Metric with Pairwise Comparisons",
        "track": "main",
        "status": "Accept",
        "keywords": "Open-domain dialogue;Dialogue evaluation;Evaluation metric",
        "primary_area": "",
        "author": "ChaeHun Park;Minseok Choi;Dohyun Lee;Jaegul Choo",
        "authorids": "~ChaeHun_Park1;~Minseok_Choi2;~Dohyun_Lee1;~Jaegul_Choo1",
        "aff": "Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science & Technology;KAIST",
        "aff_domain": "kaist.ac.kr",
        "position": "PhD student;MS student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y7JnjDcIQa",
        "title": "How Susceptible are LLMs to Influence in Prompts?",
        "track": "main",
        "status": "Accept",
        "keywords": "Assistance;scalable oversight;sycophancy",
        "primary_area": "",
        "author": "Sotiris Anagnostidis;Jannis Bulian",
        "authorids": "~Sotiris_Anagnostidis1;~Jannis_Bulian1",
        "aff": "ETH Zurich;Google",
        "aff_domain": "inf.ethz.ch;google.com",
        "position": "Researcher;PhD student",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yIEyHP7AvH",
        "title": "Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian Language?",
        "track": "main",
        "status": "Accept",
        "keywords": "LLM;Evaluation;Multitask;Persian Language Understanding",
        "primary_area": "",
        "author": "Omid Ghahroodi;Marzia Nouri;Mohammad Vali Sanian;Alireza Sahebi;Doratossadat Dastgheib;Ehsaneddin Asgari;Mahdieh Soleymani Baghshah;Mohammad Hossein Rohban",
        "authorids": "~Omid_Ghahroodi1;~Marzia_Nouri1;~Mohammad_Vali_Sanian1;~Alireza_Sahebi1;~Doratossadat_Dastgheib1;~Ehsaneddin_Asgari1;~Mahdieh_Soleymani_Baghshah1;~Mohammad_Hossein_Rohban1",
        "aff": "Sharif University of Technology;Helmholtz Center for Infection Research;Shahid Beheshti University;Sharif University of Technology, Sharif University of Technology",
        "aff_domain": "sbu.ac.ir;helmholtz-hzi.de;ce.sharif.edu;sharif.edu",
        "position": "MS student;PhD student;Postdoc;Researcher;Assistant Professor;MS student;MS student;Associate Professor",
        "rating": "",
        "confidence": "4;5;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yK2eGE8QVW",
        "title": "NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment",
        "track": "main",
        "status": "Accept",
        "keywords": "Model Alignment;RLHF;LLM;Helpfulness;Toolkit;Scalable System",
        "primary_area": "",
        "author": "Gerald Shen;Zhilin Wang;Olivier Delalleau;Jiaqi Zeng;Yi Dong;Daniel Egert;Shengyang Sun;Jimmy J. Zhang;Sahil Jain;Ali Taghibakhshi;Markel Sanz Ausin;Ashwath Aithal;Oleksii Kuchaiev",
        "authorids": "~Gerald_Shen1;~Zhilin_Wang2;~Olivier_Delalleau1;~Jiaqi_Zeng1;~Yi_Dong4;~Daniel_Egert1;~Shengyang_Sun4;~Jimmy_J._Zhang1;~Sahil_Jain2;~Ali_Taghibakhshi1;~Markel_Sanz_Ausin1;~Ashwath_Aithal1;~Oleksii_Kuchaiev1",
        "aff": "Meta AI (FAIR);Computer Science Department, Stanford University;Amazon;Georgia Institute of Technology;NVIDIA;University of Illinois at Urbana-Champaign",
        "aff_domain": "illinois.edu;amazon.com;cs.stanford.edu;nvidia.com;fb.com;gatech.edu",
        "position": "PhD student;Researcher;MS student;Researcher;Researcher;Senior Applied Scientist;Research Engineering Manager;MS student;Researcher;Researcher;Applied Scientist",
        "rating": "",
        "confidence": "3;3;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yK8MT91dQY",
        "title": "Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided",
        "track": "main",
        "status": "Accept",
        "keywords": "Cognitive Reappraisal;Emotional Support;Psychology",
        "primary_area": "",
        "author": "Hongli Zhan;Allen Zheng;Yoon Kyung Lee;Jina Suh;Junyi Jessy Li;Desmond Ong",
        "authorids": "~Hongli_Zhan1;~Allen_Zheng1;~Yoon_Kyung_Lee1;~Jina_Suh1;~Junyi_Jessy_Li2;~Desmond_Ong1",
        "aff": "University of Texas, Austin;Seoul National University;University of Texas at Austin;Department of Computer Science, University of Washington",
        "aff_domain": "snu.ac.kr;cs.washington.edu;utexas.edu",
        "position": "Undergrad student;Assistant Professor;PhD student;PhD student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ybaK4asBT2",
        "title": "LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play",
        "track": "main",
        "status": "Accept",
        "keywords": "multi-agent discussion;creativity;role-play;large language models",
        "primary_area": "",
        "author": "Li-Chun Lu;Shou-Jen Chen;Tsung-Min Pai;Chan-Hung Yu;Hung-yi Lee;Shao-Hua Sun",
        "authorids": "~Li-Chun_Lu1;~Shou-Jen_Chen1;~Tsung-Min_Pai1;~Chan-Hung_Yu2;~Hung-yi_Lee1;~Shao-Hua_Sun1",
        "aff": "National Taiwan University;Academia Sinica",
        "aff_domain": "ntu.edu.tw;iis.sinica.edu.tw",
        "position": "Undergrad student;Assistant Professor;Undergrad student;Intern;MS student;Associate Professor",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yfyHxvVzZT",
        "title": "Does Incomplete Syntax Influence Korean Language Model? Focusing on Word Order and Case Markers",
        "track": "main",
        "status": "Accept",
        "keywords": "syntax;word order;postposition;case marker;syntactically-incomplete data",
        "primary_area": "",
        "author": "Jong Myoung Kim;Young-Jun Lee;Yong-Jin Han;Ho-Jin Choi;Sangkeun Jung",
        "authorids": "~Jong_Myoung_Kim1;~Young-Jun_Lee1;~Yong-Jin_Han1;~Ho-Jin_Choi1;~Sangkeun_Jung1",
        "aff": "SK telecom;Chungnam National University;Korea Advanced Institute of Science & Technology;SKTelecom",
        "aff_domain": "cnu.ac.kr;kaist.ac.kr;sk.com;sktelecom.com",
        "position": "Full Professor;Researcher;Associate Professor;Researcher;PhD student",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yoVRyrEgix",
        "title": "Locating and Editing Factual Associations in Mamba",
        "track": "main",
        "status": "Accept",
        "keywords": "language models;state space models;factual associations;model editing;interpretability",
        "primary_area": "",
        "author": "Arnab Sen Sharma;David Atkinson;David Bau",
        "authorids": "~Arnab_Sen_Sharma1;~David_Atkinson2;~David_Bau1",
        "aff": "Northeastern University",
        "aff_domain": "northeastern.edu;northeasterd.edu",
        "position": "PhD student;PhD student;Assistant Professor",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "z7FvXbyyrM",
        "title": "Long-Form Answers to Visual Questions from Blind and Low Vision People",
        "track": "main",
        "status": "Accept",
        "keywords": "Visual Question Answering;Long-form Question Answering;Vision Language Models;Accessibility",
        "primary_area": "",
        "author": "Mina Huh;Fangyuan Xu;Yi-Hao Peng;Chongyan Chen;Hansika Murugu;Danna Gurari;Eunsol Choi;Amy Pavel",
        "authorids": "~Mina_Huh1;~Fangyuan_Xu1;~Yi-Hao_Peng1;~Chongyan_Chen1;~Hansika_Murugu1;~Danna_Gurari2;~Eunsol_Choi1;~Amy_Pavel1",
        "aff": "University of Texas, Austin;University of Texas at Austin;, University of Texas at Austin;University of Colorado at Boulder;School of Computer Science, Carnegie Mellon University;The Hong Kong University of Science and Technology",
        "aff_domain": "hkust.edu.hk;utexas.edu;cs.utexas.edu;cs.cmu.edu;colorado.edu",
        "position": "Assistant Professor;PhD student;Assistant Professor;Assistant Professor;Research Assistant;Undergrad student;PhD student;PhD student",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zSf8PJyQb2",
        "title": "Transformer Circuit Evaluation Metrics Are Not Robust",
        "track": "main",
        "status": "Accept",
        "keywords": "mechanistic interpretability;interpretability;circuits",
        "primary_area": "",
        "author": "Joseph Miller;Bilal Chughtai;William Saunders",
        "authorids": "~Joseph_Miller3;~Bilal_Chughtai1;~William_Saunders1",
        "aff": "OpenAI",
        "aff_domain": "openai.com",
        "position": "Researcher",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.5,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zZa7Ke7WAJ",
        "title": "Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval: Evolving Coding Benchmarks via LLM",
        "track": "main",
        "status": "Accept",
        "keywords": "Program Synthesis;Evaluation;Dataset;LLM4Code",
        "primary_area": "",
        "author": "Chunqiu Steven Xia;Yinlin Deng;LINGMING ZHANG",
        "authorids": "~Chunqiu_Steven_Xia1;~Yinlin_Deng1;~LINGMING_ZHANG2",
        "aff": "University of Illinois Urbana-Champaign;University of Illinois at Urbana-Champaign",
        "aff_domain": "illinois.edu;cs.illinois.edu",
        "position": "PhD student;Associate Professor;PhD student",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zl16jLb91v",
        "title": "Towards Measuring the Representation of Subjective Global Opinions in Language Models",
        "track": "main",
        "status": "Accept",
        "keywords": "opinions on global issues;cultural representation;subjectivity in LLMs;evaluation;societal impact",
        "primary_area": "",
        "author": "Esin DURMUS;Karina Nguyen;Thomas Liao;Nicholas Schiefer;Amanda Askell;Anton Bakhtin;Carol Chen;Zac Hatfield-Dodds;Danny Hernandez;Nicholas Joseph;Liane Lovitt;Sam McCandlish;Orowa Sikder;Alex Tamkin;Janel Thamkul;Jared Kaplan;Jack Clark;Deep Ganguli",
        "authorids": "~Esin_DURMUS2;~Karina_Nguyen2;~Thomas_Liao1;~Nicholas_Schiefer1;~Amanda_Askell2;~Anton_Bakhtin1;~Carol_Chen2;~Zac_Hatfield-Dodds1;~Danny_Hernandez1;~Nicholas_Joseph1;~Liane_Lovitt1;~Sam_McCandlish1;~Orowa_Sikder1;~Alex_Tamkin1;~Janel_Thamkul1;~Jared_Kaplan2;~Jack_Clark1;~Deep_Ganguli2",
        "aff": "Stanford University;Anthropic AI;Facebook;Australian National University;Anthropic PBC;Anthropic",
        "aff_domain": "anu.edu.au;stanford.edu;anthropic.com;facebook.com",
        "position": "Researcher;Researcher;Researcher;Postdoc;Head of Policy ;Researcher;Researcher;Researcher;Researcher;Researcher;PhD student",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.25,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zlw6AHwukB",
        "title": "A Survey on Deep Learning for Theorem Proving",
        "track": "main",
        "status": "Accept",
        "keywords": "Deep Learning;Theorem Proving;Automated Reasoning",
        "primary_area": "",
        "author": "Zhaoyu Li;Jialiang Sun;Logan Murphy;Qidong Su;Zenan Li;Xian Zhang;Kaiyu Yang;Xujie Si",
        "authorids": "~Zhaoyu_Li3;~Jialiang_Sun2;~Logan_Murphy1;~Qidong_Su1;~Zenan_Li3;~Xian_Zhang4;~Kaiyu_Yang1;~Xujie_Si1",
        "aff": "Microsoft;Department of Computer Science, University of Toronto;University of Toronto;McGill University;Nanjing University;California Institute of Technology",
        "aff_domain": "cs.toronto;nju.edu.cn;caltech.edu;toronto.edu;cs.toronto.edu;microsoft.com;cs.mcgill.ca",
        "position": "Undergrad student;Postdoc;PhD student;Researcher;Assistant Professor;PhD student;PhD student",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.75,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    }
]
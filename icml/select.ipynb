{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2387/2387 [01:00<00:00, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功保存到 RAG_eccv2024.xlsx 文件中。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "client = OpenAI(api_key=\"sk-e5041bba86ab45389e42f916e15f80e4\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "\n",
    "\n",
    "def filter_(title,abs,key_words,exclude_keywords):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"deepseek-coder\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful paper assistant, always udge whether it meets my requirements.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\" \n",
    "         Please carefully read the title and abstract of this paper, and consider how it relates to the keywords I need.\n",
    "\n",
    "         If the abstract and title of this paper only about my requirement keywords and are not in an area I don't require, give me true.\n",
    "        \n",
    "         Please return false or true in `match_result to me, where match_result mean whether macth my requestment.      \n",
    "         \n",
    "          Follow the example below:\n",
    "            User: \n",
    "            The title of this paper is: example title\n",
    "            The abstract of this paper is: example abstract\n",
    "            My requirement keywords: example keywords\n",
    "            I don't require: example exclude_keywords\n",
    "         \n",
    "            Assistant return: {\n",
    "            \"match_result\": false,\n",
    "            }\n",
    "         \n",
    "            \"\"\"\n",
    "         +f\"\"\" \n",
    "            My Input:\n",
    "            [\n",
    "            The title of this paper is: {title}\n",
    "            The abstract of this paper is: {abs}\n",
    "            My requirement keywords: {key_words}\n",
    "            I don't require: {exclude_keywords}\n",
    "            ]\n",
    "        \"\"\"},\n",
    "    ],\n",
    "    stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel('eccv24.xlsx')\n",
    "\n",
    "\n",
    "include_keywords = ['Retrieval-Augmented']  # 替换为实际关键词\n",
    "exclude_keywords = ['3D','Human Rendering','Diffusion','diffusion']  # 替换为实际关键词\n",
    "keywords=\",\".join(include_keywords)\n",
    "exclude_keyword=\",\".join(exclude_keywords)\n",
    "print(f\"Total number of rows: {len(df)}\")\n",
    "def filter_row(row):\n",
    "    resp=filter_(row['title'],row['abstract'],keywords,exclude_keyword)\n",
    "\n",
    "    return ('True' in resp) or ('true' in resp)\n",
    "    \n",
    "\n",
    "filtered_rows = []\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "    futures = {executor.submit(filter_row, row): index for index, row in df.iterrows()}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "        index = futures[future]\n",
    "        try:\n",
    "            if future.result():\n",
    "                filtered_rows.append(df.iloc[index][['title', 'abstract']])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "# Create a new DataFrame from the filtered rows\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "\n",
    "filtered_df.to_excel('RAG_eccv2024.xlsx', index=False)\n",
    "\n",
    "print(\"数据已成功保存到 RAG_eccv2024.xlsx 文件中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2610/2610 [08:34<00:00,  5.08it/s]\n",
      "Processing: 100%|██████████| 2610/2610 [00:57<00:00, 45.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-e5041bba86ab45389e42f916e15f80e4\", base_url=\"https://api.deepseek.com\")\n",
    "def translate(query):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"deepseek-coder\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful translate assistant , always tranlate en to cn\"},\n",
    "        {\"role\": \"user\", \"content\": f\"请翻译为中文:{query}\"},\n",
    "    ],\n",
    "    stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    # Show response\n",
    "\n",
    "\n",
    "df_filter = pd.read_excel('icml24.xlsx')\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply the translate function with a progress bar\n",
    "def parallel_apply(series, func, num_threads=64):\n",
    "    results = [None] * len(series)\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = {executor.submit(func, text): idx for idx, text in enumerate(series)}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "            idx = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results[idx] = result\n",
    "            except Exception as exc:\n",
    "                print(f\"Generated an exception: {exc}\")\n",
    "                results[idx] = None\n",
    "                \n",
    "    return results\n",
    "# Apply the translate function with multithreading and a progress bar\n",
    "df_filter['abstract0'] = parallel_apply(df_filter['abstract'], translate)\n",
    "df_filter['title0'] = parallel_apply(df_filter['title'], translate)\n",
    "df_filter.to_excel('icml24_translated.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel('deepseek_coder_cvpr2024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "client = OpenAI(api_key=\"sk-e5041bba86ab45389e42f916e15f80e4\", base_url=\"https://api.deepseek.com\")\n",
    "include_keywords = ['Efficie','efficien','RAG','Video',]  # 替换为实际关键词\n",
    "exclude_keywords = ['3D','Human Rendering','Diffusion','diffusion']  # 替换为实际关键词\n",
    "keywords=\";\".join(include_keywords)\n",
    "exclude_keyword=\";\".join(exclude_keywords)\n",
    "\n",
    "\n",
    "def filter_(title,abs,key_words,exclude_keywords):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful paper assistant, always udge whether it meets my requirements.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\" \n",
    "            Please judge whether this paper meets my requirements and return the result in the specified format.\n",
    "            Please return false or true in`match_result to me, where match_result mean whether macth my requestment. Follow the example below:\n",
    "            User: \n",
    "            The title of this paper is: example title\n",
    "            The abstract of this paper is: example abstract\n",
    "            My requirement keywords: example keywords\n",
    "            Do not contain this content: example exclude_keywords\n",
    "         \n",
    "            Assistant return: {\n",
    "            \"match_result\": false,\n",
    "            }\n",
    "         \n",
    "            \"\"\"\n",
    "         +f\"\"\" \n",
    "            My Input:\n",
    "            [\n",
    "            The title of this paper is: {title}\n",
    "            The abstract of this paper is: {abs}\n",
    "            My requirement keywords: {key_words}\n",
    "            Do not contain this content: {exclude_keywords}\n",
    "            ]\n",
    "        \"\"\"},\n",
    "    ],\n",
    "    stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep=filter_('General Object Foundation Model for Images and Videos at Scale',\"We present GLEE in this work an object-level foundation model for locating and identifying objects in images and videos. Through a unified framework GLEEaccomplishes detection segmentation tracking grounding and identification of arbitrary objects in the open world scenario for various object perception tasks. Adopting a cohesive learning strategy GLEE acquires knowledge from diverse data sources with varying supervision levels to formulate general object representations excelling in zero-shot transfer to new data and tasks. Specifically we employ an image encoder text encoder and visual prompter to handle multi-modal inputs enabling to simultaneously solve various object-centric downstream tasks while maintaining state-of-the-art performance. Demonstrated through extensive training on over five million images from diverse benchmarks GLEE exhibits remarkable versatility and improved generalization performance efficiently tackling downstream tasks without the need for task-specific adaptation. By integrating large volumes of automatically labeled data we further enhance its zero-shot generalization capabilities. Additionally GLEE is capable of being integrated into Large Language Models serving as a foundational model to provide universal object-level information for multi-modal tasks. We hope that the versatility and universality of our method will mark a significant step in the development of efficient visual foundation models for AGI systems. The models and code are released at https://github.com/FoundationVision/GLEE.\",keywords,exclude_keyword)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"match_result\": true,\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "rere=rep.replace('json','')\n",
    "rere=rere.replace('```','')\n",
    "rere=rere.replace('\\n','')\n",
    "rere=rere.replace(' ','')\n",
    "data = json.loads(rere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'match_result': True, 'match_score': 8.5}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
